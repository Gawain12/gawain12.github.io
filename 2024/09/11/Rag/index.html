

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Gawain">
  <meta name="keywords" content="Share">
  
    <meta name="description" content="RAG 技术概要：从入门到进阶，打造你的智能知识引擎引言你是否曾幻想过拥有一个无所不知的 AI 助手，它不仅能像搜索引擎一样快速找到信息，还能像人类专家一样理解并解答你的复杂问题？检索增强生成 (Retrieval-Augmented Generation, RAG) 技术，正是实现这一梦想的关键一步。 RAG 技术巧妙地结合了大型语言模型 (LLM) 的强大生成能力和外部知识库的海量信息，让 A">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG 技术概要">
<meta property="og:url" content="https://gawain12.github.io/2024/09/11/Rag/index.html">
<meta property="og:site_name" content="Gawain&#39;s notes">
<meta property="og:description" content="RAG 技术概要：从入门到进阶，打造你的智能知识引擎引言你是否曾幻想过拥有一个无所不知的 AI 助手，它不仅能像搜索引擎一样快速找到信息，还能像人类专家一样理解并解答你的复杂问题？检索增强生成 (Retrieval-Augmented Generation, RAG) 技术，正是实现这一梦想的关键一步。 RAG 技术巧妙地结合了大型语言模型 (LLM) 的强大生成能力和外部知识库的海量信息，让 A">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-09-10T17:29:04.000Z">
<meta property="article:modified_time" content="2025-03-17T17:56:19.823Z">
<meta property="article:author" content="Gawain">
<meta property="article:tag" content="Share">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>RAG 技术概要 - Gawain&#39;s notes</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"gawain12.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"FeJdeqy6cDDAySGfsLP8g1bl-MdYXbMMI","app_key":"Hj6SxzGjyvHq8tHLJTqtcyHZ","server_url":"https://fejdeqy6.api.lncldglobal.com","path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Gawain&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-category-fill"></i>
                <span>书影音记录</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/books/" target="_self">
                    <i class="icofont-abc"></i>
                    <span>📖文学</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/movies/" target="_self">
                    <i class="icofont-love"></i>
                    <span>🎬电影</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/songs/" target="_self">
                    <i class="icofont-notebook"></i>
                    <span>🎵音乐</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/remark/" target="_self">
                
                <span>留言板</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="RAG 技术概要"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-09-11 01:29" pubdate>
          2024年9月11日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.2k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          52 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">RAG 技术概要</h1>
            
              <p id="updated-time" class="note note-info" style="">
                
                  
                    本文最后更新于 2025年3月18日 凌晨
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="RAG-技术概要：从入门到进阶，打造你的智能知识引擎"><a href="#RAG-技术概要：从入门到进阶，打造你的智能知识引擎" class="headerlink" title="RAG 技术概要：从入门到进阶，打造你的智能知识引擎"></a>RAG 技术概要：从入门到进阶，打造你的智能知识引擎</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>你是否曾幻想过拥有一个无所不知的 AI 助手，它不仅能像搜索引擎一样快速找到信息，还能像人类专家一样理解并解答你的复杂问题？检索增强生成 (Retrieval-Augmented Generation, RAG) 技术，正是实现这一梦想的关键一步。</p>
<p>RAG 技术巧妙地结合了大型语言模型 (LLM) 的强大生成能力和外部知识库的海量信息，让 AI 助手在回答问题时，不再只是“鹦鹉学舌”般地复述训练数据，而是能够<strong>像一个研究者一样，先查阅资料，再组织答案</strong>。这不仅显著提升了 LLM 在知识密集型任务中的表现，更让 AI 生成的内容<strong>更准确、更可靠，并且能够根据最新的知识动态更新</strong>。</p>
<p>本文将带你深入了解 RAG 技术的方方面面，从基本原理到核心组件，再到最新的研究进展和实际应用挑战，让你全面掌握 RAG 技术，打造属于你自己的智能知识引擎。</p>
<h3 id="一、RAG-的工作原理：像-AI-一样“先检索，后生成”"><a href="#一、RAG-的工作原理：像-AI-一样“先检索，后生成”" class="headerlink" title="一、RAG 的工作原理：像 AI 一样“先检索，后生成”"></a>一、RAG 的工作原理：像 AI 一样“先检索，后生成”</h3><p>想象一下，你要回答一个复杂的问题，比如“最新的新冠疫苗有哪些副作用，针对老年人群体有什么特殊注意事项？” 你会怎么做？</p>
<ol>
<li><strong>检索信息</strong>：你可能会先打开搜索引擎，输入关键词，查找权威的医学网站、新闻报道、研究论文等相关资料。</li>
<li><strong>理解和整合</strong>：阅读检索到的资料，理解疫苗的副作用和老年人群体的特殊性，提取关键信息。</li>
<li><strong>组织答案</strong>：根据问题，结合你理解的信息，用清晰易懂的语言组织成最终的答案。</li>
</ol>
<p>RAG 的工作流程与此类似，它让 LLM 在生成答案之前，先进行“信息检索”这一步，从而获得更可靠的知识来源。</p>
<h4 id="1-1-RAG-核心思想：公式背后的直观理解"><a href="#1-1-RAG-核心思想：公式背后的直观理解" class="headerlink" title="1.1 RAG 核心思想：公式背后的直观理解"></a>1.1 RAG 核心思想：公式背后的直观理解</h4><p>虽然技术文章中常常会出现公式，但 RAG 的核心思想其实非常直观。我们可以用一个简单的公式来表示 RAG 的目标：</p>
<p><strong>目标： 生成最佳答案 (y)  &#x3D;  检索相关知识 (z)  +  利用 LLM 的生成能力 (M)</strong></p>
<p>更具体地说，RAG 模型的目标是，在给定一个问题 (q) 的情况下，找到最相关的知识 (z)，并利用大型语言模型 (M) 将这些知识融入到答案 (y) 中。</p>
<h4 id="1-2-RAG-的关键组件：打造智能知识引擎的基石"><a href="#1-2-RAG-的关键组件：打造智能知识引擎的基石" class="headerlink" title="1.2 RAG 的关键组件：打造智能知识引擎的基石"></a>1.2 RAG 的关键组件：打造智能知识引擎的基石</h4><p>一个完整的 RAG 系统就像一个精密的机器，由以下几个关键组件协同工作：</p>
<ol>
<li><p><strong>嵌入模型 (Embedding Model)：文本的“数字化”专家</strong></p>
<ul>
<li><p><strong>作用</strong>： 嵌入模型就像一位“翻译专家”，它能将我们输入的文字 (问题和知识库里的文档) 转换成计算机更容易理解的“数字向量”。 这种向量可以捕捉文本的语义信息，也就是说，意思相近的文字，转换成的向量在“空间”中会更接近。</p>
</li>
<li><p><strong>通俗解释</strong>： 想象一下，你想比较两篇文章是否相似。嵌入模型就像把每篇文章都变成一个“指纹”，相似的文章指纹也更接近。这样，计算机就可以通过比较“指纹”来判断文章的相似度。</p>
</li>
</ul>
</li>
<li><p><strong>向量存储 (Vector Store)：知识的“图书馆”</strong></p>
<ul>
<li><p><strong>作用</strong>： 向量存储就像一个专门存放 “数字指纹”（向量）的“图书馆”。它高效地存储着知识库中所有文档的向量表示，并支持快速查找与用户问题 “指纹” 最相似的 “图书”（文档向量）。</p>
</li>
<li><p><strong>通俗解释</strong>： 当你问一个问题时，向量存储能迅速在这个“图书馆”里找到最相关的 “图书”（文档），提供给 LLM 作为参考资料。常用的 “图书馆” 管理系统有 Faiss、Annoy、ScaNN 等，它们各有特点，就像不同类型的图书馆，有的擅长快速查找，有的擅长处理大规模数据。</p>
</li>
</ul>
</li>
<li><p><strong>向量存储检索器 (Vector Store Retriever)：高效的“图书管理员”</strong></p>
<ul>
<li><p><strong>作用</strong>： 检索器就像 “图书馆” 里专业的 “图书管理员”，它的任务是根据用户提出的问题 (也转换成向量 “指纹”)，在向量存储这个 “图书馆” 中快速检索，找到最相关的 <em>k</em> 个文档向量。这里的 <em>k</em>  值就像你希望 “图书管理员” 给你推荐多少本相关的书。</p>
</li>
<li><p><strong>通俗解释</strong>：  “图书管理员” 使用高效的检索算法，比如 “近似最近邻搜索”（ANN），就像在图书馆里使用智能索引系统，快速定位到你需要的 “图书”，而不是一本本地翻阅。</p>
</li>
</ul>
</li>
<li><p><strong>大型语言模型 (LLM)：知识的“整合者”和“答案生成器”</strong></p>
<ul>
<li><p><strong>作用</strong>： LLM 是 RAG 系统的 “大脑”，它接收用户的问题和检索器找到的相关文档，然后像人类一样，理解问题和背景知识，最终生成流畅、自然的答案。</p>
</li>
<li><p><strong>通俗解释</strong>： LLM 就像一位知识渊博的专家，它不仅能理解你的问题，还能结合 “图书管理员” 提供的参考资料，组织语言，给出高质量的解答。</p>
</li>
</ul>
</li>
<li><p><strong>查询改写 (Query Rewrite) (可选)：优化提问技巧的“助手”</strong></p>
<ul>
<li><p><strong>作用</strong>：  有时候，我们提出的问题可能不够精确，或者过于复杂，不利于检索到最佳的答案。 “查询改写” 组件就像一个 “提问技巧助手”，它可以帮助我们优化问题，使其更适合知识库的检索。</p>
</li>
<li><p><strong>通俗解释</strong>：  例如，当你的问题比较复杂时，“查询改写” 可以将大问题拆分成几个小问题，或者将问题改写成更简洁、更关键词化的形式，从而提高检索的准确率。</p>
</li>
</ul>
</li>
</ol>
<h4 id="1-3-RAG-工作流程图解：一图胜千言"><a href="#1-3-RAG-工作流程图解：一图胜千言" class="headerlink" title="1.3 RAG 工作流程图解：一图胜千言"></a>1.3 RAG 工作流程图解：一图胜千言</h4><p>为了更清晰地展示 RAG 的工作流程，我们用一张图来概括：</p>
<pre><code class=" mermaid">graph LR
    A[用户问题 (Query)] --&gt; B(嵌入模型 Embedding Model：将问题转化为“指纹”);
    B --&gt; C&#123;向量存储 Vector Store：“知识图书馆”，存储文档“指纹”&#125;;
    C --&gt; D[向量存储检索器 Retriever：“图书管理员”，检索相关“图书”];
    D --&gt; E[检索到的文档 (Retrieved Documents)：相关知识“图书”];
    A --&gt; F(LLM：“知识专家”，负责理解问题和生成答案);
    E --&gt; F;
    F --&gt; G[生成答案 (Generated Answer)：最终答案];
    style B fill:#f9f,stroke:#333,stroke-width:2px
    style C fill:#ccf,stroke:#333,stroke-width:2px
    style D fill:#fcf,stroke:#333,stroke-width:2px
    style F fill:#cff,stroke:#333,stroke-width:2px
</code></pre>

<h3 id="二、RAG-的核心技术点：精雕细琢，打造卓越性能"><a href="#二、RAG-的核心技术点：精雕细琢，打造卓越性能" class="headerlink" title="二、RAG 的核心技术点：精雕细琢，打造卓越性能**"></a>二、RAG 的核心技术点：精雕细琢，打造卓越性能**</h3><p>RAG 系统的性能优劣，很大程度上取决于各个组件的技术细节。下面我们深入探讨 RAG 的几个关键技术点：</p>
<h4 id="2-1-文本切分-Text-Splitting-：知识颗粒度的艺术"><a href="#2-1-文本切分-Text-Splitting-：知识颗粒度的艺术" class="headerlink" title="2.1 文本切分 (Text Splitting)：知识颗粒度的艺术"></a>2.1 文本切分 (Text Splitting)：知识颗粒度的艺术</h4><ul>
<li><p><strong>为什么需要文本切分？</strong>  知识库中的文档通常很长，如果直接将整篇文档放入向量库，可能会导致：</p>
<ul>
<li><strong>检索效率降低</strong>： 长文档包含的信息过多，与用户问题的相关性可能不高，影响检索精度。</li>
<li><strong>LLM 处理限制</strong>： LLM 的输入长度有限制，过长的文本会超出处理能力。</li>
</ul>
</li>
<li><p><strong>文本切分的策略：</strong>  文本切分就像把一篇长文章分成若干个段落，方便检索和理解。常见的切分策略包括：</p>
<ul>
<li><p>**固定长度分割 (Fixed-size Chunking)**： 简单粗暴，按照固定的字符数或 token 数将文本切分成块。 就像把一根绳子剪成等长的几段。</p>
</li>
<li><p>**句子分割 (Sentence Splitting)**： 按照句子的边界切分文本，更符合语义的完整性。 就像把文章按照句子分成小块，每个小块意思更完整。</p>
</li>
<li><p>**段落分割 (Paragraph Splitting)**： 按照段落的边界切分，适用于结构化的文档。 就像把文章按照自然段分块，更符合文章的结构。</p>
</li>
<li><p>**递归分割 (Recursive Splitting)**：  更智能的切分方式，它会尝试按照不同的层级结构 (如标题、段落、句子) 递归地切分文本，尽可能保留文本的结构信息和语义连贯性。 就像先按章节分，再按段落分，再按句子分，更有层次感。</p>
</li>
<li><p>**特殊标记分割 (Special Token Splitting)**：  对于 Markdown、LaTeX 等格式的文档，可以利用其结构化标记 (如标题、代码块、列表等) 进行分割，更好地保留文档的原有结构。 就像针对 Markdown 文档的特殊分割方法，能识别标题、列表等结构。</p>
</li>
</ul>
</li>
<li><p><strong>Chunk Size 和 Chunk Overlap：平衡语义完整性和上下文连贯性</strong></p>
<ul>
<li><p>**Chunk Size (文本块大小)**：  文本块的大小直接影响到检索的粒度和 LLM 的输入长度。</p>
<ul>
<li><strong>太小</strong>： 可能导致语义信息不完整，检索到的文本片段缺乏上下文，LLM 难以理解。</li>
<li><strong>太大</strong>： 可能包含过多无关信息，降低检索精度，超出 LLM 的输入长度限制。</li>
</ul>
</li>
<li><p>**Chunk Overlap (文本块重叠)**：  为了保持文本块之间的上下文连贯性，可以设置一定的重叠区域。 就像滑动窗口一样，相邻的文本块之间有一部分内容是重复的，保证上下文的衔接。</p>
</li>
<li><p><strong>选择合适的切分策略：</strong>  需要根据知识库文档的类型、LLM 的输入长度限制、以及任务的具体需求来选择合适的切分策略，并调整 Chunk Size 和 Chunk Overlap 参数。 Langchain 等工具提供了丰富的文本分割器，方便我们进行选择和定制。</p>
</li>
</ul>
</li>
</ul>
<h4 id="2-2-嵌入模型-Embedding-Model-：选择合适的“语义指纹”"><a href="#2-2-嵌入模型-Embedding-Model-：选择合适的“语义指纹”" class="headerlink" title="2.2 嵌入模型 (Embedding Model)：选择合适的“语义指纹”"></a>2.2 嵌入模型 (Embedding Model)：选择合适的“语义指纹”</h4><ul>
<li><p><strong>好的嵌入模型：RAG 成功的关键</strong>：  嵌入模型的好坏，直接决定了 RAG 系统能否检索到真正相关的知识。一个优秀的嵌入模型应该能够：</p>
<ul>
<li><strong>准确捕捉文本的语义信息</strong>： 相似的文本应该有相似的向量表示。</li>
<li><strong>区分不同文本的语义差异</strong>： 不相似的文本应该有明显的向量差异。</li>
<li>**支持多种语言 (Multilingual)**： 能够处理不同语言的文本。</li>
<li><strong>高效的向量计算</strong>：  能够快速地将文本转换为向量表示。</li>
</ul>
</li>
<li><p><strong>主流的嵌入模型：各有所长，按需选择</strong>  目前有很多优秀的开源嵌入模型，例如：</p>
<ul>
<li><p>**BGE (BAAI General Embedding)**： 智源研究院出品，通用性强，中英文表现出色，在多个评测榜单上名列前茅。 就像一位 “全能选手”，各种任务都能胜任。</p>
</li>
<li><p>**GTE (General Text Embeddings)**： 阿里巴巴达摩院出品，针对多领域语料训练，适用场景广泛，性能优异。 就像一位 “经验丰富的老将”，见过各种场面，应对自如。</p>
</li>
<li><p>**E5 (EmbEddings from bidirEctional Encoder rEpresentations)**： intfloat 团队出品，采用创新训练方法，注重高质量文本表示，效果突出。 就像一位 “技术流专家”，在算法和模型设计上有独到之处。</p>
</li>
<li><p><strong>Jina Embeddings</strong>： Jina AI 出品，基于大规模数据集训练，推理速度快，多个大小版本可选。 就像一位 “效率专家”，追求速度和性能的平衡。</p>
</li>
<li><p><strong>Instructor</strong>： 香港大学 NLP 实验室出品，支持指令微调，可以根据任务指导生成特定任务的 Embedding。 就像一位 “定制化大师”，可以根据你的需求量身打造。</p>
</li>
<li><p><strong>XLM-Roberta</strong>： Facebook AI 出品，多语言支持，跨语言任务表现出色。 就像一位 “语言通”，精通多国语言，擅长跨文化交流。</p>
</li>
<li><p><strong>text-embedding-ada-002</strong>:  OpenAI 的 embedding 模型，性能强大，Hugging Face 社区也提供了兼容版本。 就像一位 “明星选手”，出自名门，备受瞩目。</p>
</li>
</ul>
</li>
<li><p><strong>增强 Embedding 质量：更上一层楼的技巧</strong>  除了选择合适的模型，还可以通过一些技巧来进一步提升 Embedding 的质量：</p>
<ul>
<li><p>**微调 (Fine-tuning)**：  使用特定领域的数据对预训练的 Embedding 模型进行微调，使其更适应特定任务和数据分布。 就像针对特定考试进行强化训练，提高应试能力。</p>
</li>
<li><p>**数据增强 (Data Augmentation)**：  通过同义词替换、回译等方法，增加训练数据的多样性，提升模型的泛化能力。 就像多做练习题，见多识广，提高解题能力。</p>
</li>
<li><p>**对比学习 (Contrastive Learning)**：  通过构建正负样本对，让模型学习区分相似和不相似的文本，提高语义表示的区分度。 就像通过 “找不同” 的游戏，提高辨别能力。</p>
</li>
</ul>
</li>
</ul>
<h4 id="2-3-向量存储与检索：高效查找“知识宝藏”"><a href="#2-3-向量存储与检索：高效查找“知识宝藏”" class="headerlink" title="2.3 向量存储与检索：高效查找“知识宝藏”"></a>2.3 向量存储与检索：高效查找“知识宝藏”</h4><ul>
<li><p><strong>向量存储 (Vector Store)：知识的 “仓库”</strong>  选择合适的向量存储，直接影响到 RAG 系统的检索效率和扩展性。 常用的向量数据库包括：</p>
<ul>
<li><p>**Faiss (Facebook AI Similarity Search)**： Facebook AI 开源的向量相似性搜索库，速度快，支持多种索引类型，适合大规模向量检索。 就像一个 “高效仓库”，查找速度快，存储容量大。</p>
</li>
<li><p>**Annoy (Approximate Nearest Neighbors Oh Yeah)**： Spotify 开源的近似最近邻搜索库，简单易用，性能良好，适合中小型应用。 就像一个 “便捷仓库”，使用简单，性能可靠。</p>
</li>
<li><p>**ScaNN (Scalable Nearest Neighbors)**： Google 开源的可扩展最近邻搜索库，针对大规模数据集优化，性能强大。 就像一个 “超级仓库”，专为海量数据设计，性能卓越。</p>
</li>
<li><p><strong>Milvus</strong>：  开源的向量数据库，功能完善，支持分布式部署、多种索引类型、以及数据管理功能，适合构建复杂的 RAG 系统。 就像一个 “智能仓库”，功能齐全，管理方便。</p>
</li>
<li><p><strong>Chroma</strong>：  开源的嵌入式向量数据库，轻量级，易于集成，适合快速原型开发和小型应用。 就像一个 “迷你仓库”，轻巧灵活，方便快捷。</p>
</li>
</ul>
</li>
<li><p><strong>检索算法 (Retrieval Algorithm)： “寻宝的指南针”</strong>  检索算法决定了如何在向量存储中快速找到最相关的文档。 常见的检索算法包括：</p>
<ul>
<li><p>**暴力搜索 (Brute-Force Search)**：  最简单直接的方法，计算查询向量与所有文档向量的距离，返回距离最近的 <em>k</em> 个文档。 就像 “地毯式搜索”，遍历所有可能的目标，保证找到最精确的结果，但效率较低。</p>
</li>
<li><p>**近似最近邻搜索 (Approximate Nearest Neighbor Search, ANN)**：  通过构建索引结构 (如倒排索引、局部敏感哈希、乘积量化等) 来加速搜索，牺牲一定的精度换取速度。 就像 “捷径搜索”，通过预先建立好的索引，快速找到近似的结果，效率高，但可能牺牲一定的精度。</p>
</li>
<li><p>**混合搜索 (Hybrid Search)**：  结合多种检索方法，例如先使用向量检索，再使用关键词检索进行过滤，或者结合多种 ANN 算法，提高检索的准确率和召回率。 就像 “组合拳”，结合多种搜索策略，扬长避短，提高整体效果。</p>
</li>
</ul>
</li>
</ul>
<h4 id="2-4-查询改写-Query-Rewriting-：让提问更精准"><a href="#2-4-查询改写-Query-Rewriting-：让提问更精准" class="headerlink" title="2.4 查询改写 (Query Rewriting)：让提问更精准"></a>2.4 查询改写 (Query Rewriting)：让提问更精准</h4><ul>
<li><p><strong>为什么需要查询改写？</strong>  用户提出的问题，有时候可能存在以下问题：</p>
<ul>
<li><strong>表达不够清晰</strong>：  问题描述模糊，关键词不明确。</li>
<li><strong>过于复杂</strong>：  一个问题包含多个子问题，难以一次性检索到位。</li>
<li><strong>不符合检索系统的 “口味”</strong>：  例如，用户习惯自然语言提问，但检索系统更擅长关键词匹配。</li>
</ul>
</li>
<li><p><strong>查询改写的技巧：优化提问，提升检索效果</strong>  常见的查询改写技巧包括：</p>
<ul>
<li><p>**关键词扩展 (Keyword Expansion)**：  为问题添加更多相关的关键词，扩大检索范围，提高召回率。 例如，将 “感冒药” 改写为 “感冒药  发烧  咳嗽  流鼻涕”。</p>
</li>
<li><p>**问题分解 (Question Decomposition)**：  将复杂问题分解成多个简单的子问题，分别进行检索，提高检索精度。 例如，将 “新冠疫苗的副作用和老年人注意事项” 分解为 “新冠疫苗副作用” 和 “老年人接种新冠疫苗注意事项”。</p>
</li>
<li><p>**意图识别 (Intent Recognition)**：  识别用户问题的意图，根据意图调整查询策略。 例如，如果用户询问 “北京天气”，意图可能是获取 “北京今天的天气预报”，而不是关于 “北京天气历史数据” 的信息。</p>
</li>
<li><p>**同义词替换 (Synonym Replacement)**：  使用同义词替换问题中的关键词，避免因用词不当而错过相关文档。 例如，将 “人工智能” 替换为 “AI” 或 “机器学习”。</p>
</li>
<li><p>**问题改写为更适合检索的风格 (Query Reformulation)**：  例如，将自然语言问题改写为更简洁的关键词搜索形式，或者将问题改写为更结构化的查询语句。</p>
</li>
</ul>
</li>
</ul>
<h3 id="三、RAG-的评测：衡量智能水平的标尺"><a href="#三、RAG-的评测：衡量智能水平的标尺" class="headerlink" title="三、RAG 的评测：衡量智能水平的标尺"></a>三、RAG 的评测：衡量智能水平的标尺</h3><p>如何评价一个 RAG 系统的好坏？我们需要一套科学的评测指标，从不同维度衡量 RAG 系统的性能。</p>
<h4 id="3-1-检索质量评测：-“找得准”-吗？检索质量是-RAG-的基础，如果检索不到相关的知识，后续的生成就无从谈起。-常见的检索质量评测指标包括："><a href="#3-1-检索质量评测：-“找得准”-吗？检索质量是-RAG-的基础，如果检索不到相关的知识，后续的生成就无从谈起。-常见的检索质量评测指标包括：" class="headerlink" title="3.1 检索质量评测： “找得准” 吗？检索质量是 RAG 的基础，如果检索不到相关的知识，后续的生成就无从谈起。 常见的检索质量评测指标包括："></a>3.1 检索质量评测： “找得准” 吗？检索质量是 RAG 的基础，如果检索不到相关的知识，后续的生成就无从谈起。 常见的检索质量评测指标包括：</h4><ul>
<li><p>**Recall@k (召回率@k)**：  检索到的前 <em>k</em> 个文档中，包含相关文档的比例。 例如，Recall@10 &#x3D; 0.8 表示，检索结果的前 10 个文档中，有 8 个是相关的。 Recall@k 越高，说明检索系统 “找得全”。</p>
</li>
<li><p>**MRR (Mean Reciprocal Rank，平均倒数排名)**：  衡量检索结果排序质量的指标。 对于每个问题，找到第一个相关文档的排名 (Rank)，MRR 就是所有问题第一个相关文档排名的倒数的平均值。 MRR 越高，说明检索系统 “排得准”，相关文档排在更靠前的位置。</p>
</li>
<li><p>**NDCG (Normalized Discounted Cumulative Gain，归一化折损累积增益)**：  更精细的排序质量指标，它不仅考虑相关文档的排名，还考虑相关文档的相关性程度。 NDCG 越高，说明检索系统 “排得好”，不仅相关文档排在前面，而且更相关的文档排在更前面。</p>
</li>
</ul>
<h4 id="3-2-生成质量评测：-“说得好”-吗？生成质量是-RAG-的最终目标，我们需要评价生成的答案是否准确、流畅、有用。-常见的生成质量评测指标包括："><a href="#3-2-生成质量评测：-“说得好”-吗？生成质量是-RAG-的最终目标，我们需要评价生成的答案是否准确、流畅、有用。-常见的生成质量评测指标包括：" class="headerlink" title="3.2 生成质量评测： “说得好” 吗？生成质量是 RAG 的最终目标，我们需要评价生成的答案是否准确、流畅、有用。 常见的生成质量评测指标包括："></a>3.2 生成质量评测： “说得好” 吗？生成质量是 RAG 的最终目标，我们需要评价生成的答案是否准确、流畅、有用。 常见的生成质量评测指标包括：</h4><ul>
<li><p>**Faithfulness (忠实度)**：  生成的答案是否与检索到的文档一致，是否捏造事实 (幻觉)。 Faithfulness 越高，说明 RAG 系统 “说实话”，不乱编。</p>
</li>
<li><p>**Relevance (相关性)**：  生成的答案是否与用户提出的问题相关，是否回答了问题。 Relevance 越高，说明 RAG 系统 “答对题”，没有跑题。</p>
</li>
<li><p>**Harmfulness (无害性)**：  生成的答案是否包含有害信息，例如歧视、偏见、攻击性言论等。 Harmfulness 越低，说明 RAG 系统 “三观正”，不会输出有害内容。</p>
</li>
</ul>
<h4 id="3-3-端到端评测：综合能力大考-除了单独评测检索和生成质量，还需要进行端到端的评测，综合评价-RAG-系统的整体性能。-一些-RAG-评测框架应运而生："><a href="#3-3-端到端评测：综合能力大考-除了单独评测检索和生成质量，还需要进行端到端的评测，综合评价-RAG-系统的整体性能。-一些-RAG-评测框架应运而生：" class="headerlink" title="3.3 端到端评测：综合能力大考  除了单独评测检索和生成质量，还需要进行端到端的评测，综合评价 RAG 系统的整体性能。  一些 RAG 评测框架应运而生："></a>3.3 端到端评测：综合能力大考  除了单独评测检索和生成质量，还需要进行端到端的评测，综合评价 RAG 系统的整体性能。  一些 RAG 评测框架应运而生：</h4><ul>
<li><p>**RAGAS (RAG Assessment)**：  一个流行的 RAG 评估框架，提供多个指标，从忠实度、答案相关性、上下文相关性等多个维度评估 RAG 系统的性能。 RAGAS 就像一个 “综合评分系统”，从多个角度评价 RAG 的表现。</p>
</li>
<li><p>**ARES (Adversarial Retrieval Evaluation System)**：  另一个 RAG 评估框架，侧重于评估 RAG 系统的鲁棒性和稳定性，通过对抗性的方式，发现 RAG 系统的薄弱环节。 ARES 就像一个 “压力测试工具”，检验 RAG 系统在各种复杂情况下的表现。</p>
</li>
</ul>
<h3 id="四、RAG-的最新进展与挑战：探索智能的边界"><a href="#四、RAG-的最新进展与挑战：探索智能的边界" class="headerlink" title="四、RAG 的最新进展与挑战：探索智能的边界"></a>四、RAG 的最新进展与挑战：探索智能的边界</h3><p>RAG 技术仍在快速发展中，研究人员不断探索新的方法，提升 RAG 系统的性能和应用范围。</p>
<h4 id="4-1-最新进展：RAG-技术-“进化”-之路"><a href="#4-1-最新进展：RAG-技术-“进化”-之路" class="headerlink" title="4.1 最新进展：RAG 技术 “进化”  之路"></a>4.1 最新进展：RAG 技术 “进化”  之路</h4><ul>
<li><p>**多跳 RAG (Multi-Hop RAG)**：  应对复杂问题，需要多次检索，逐步获取所需的全部信息，像 “剥洋葱” 一样，一层层深入挖掘。 例如，回答 “A 公司的 CEO 的配偶是谁，配偶的国籍是什么？”，需要先检索 A 公司的 CEO 是谁，再检索 CEO 的配偶是谁，最后检索配偶的国籍。</p>
</li>
<li><p>**细粒度 RAG (Fine-Grained RAG)**：  将检索单元从文档级别细化到句子级别甚至短语级别，提高检索精度，更精准地定位到问题的答案。  就像用 “显微镜” 观察知识，更精细地提取信息。</p>
</li>
<li><p>**自适应 RAG (Adaptive RAG)**：  根据问题的类型和难度，动态调整检索策略，更智能地选择合适的检索方法和参数。 就像 “智能驾驶”，根据路况自动调整驾驶模式。</p>
</li>
<li><p>**跨模态 RAG (Cross-Modal RAG)**：  打破文本的限制，支持从图像、视频、音频等多种模态的知识库中检索信息，扩展 RAG 的应用场景。 就像 “多语种翻译”，不仅能理解文字，还能理解图像、声音等多种信息。</p>
</li>
<li><p>**端到端训练 (End-to-End Training)**：  将检索器和生成器联合训练，优化整个 RAG 系统的性能，实现 “1+1 &gt; 2” 的效果。 就像 “团队合作”，检索和生成两个模块协同工作，共同提升整体性能。</p>
</li>
<li><p>**RAG 与微调的结合 (RAG + Fine-tuning)**：  利用 RAG 检索到的高质量数据，对 LLM 进行微调，进一步提升 LLM 的知识水平和生成能力。 就像 “名师辅导”，利用 RAG 找到的优质学习资料，帮助 LLM 提升能力。</p>
</li>
</ul>
<h4 id="4-2-挑战：RAG-技术-“攻坚克难”-之路"><a href="#4-2-挑战：RAG-技术-“攻坚克难”-之路" class="headerlink" title="4.2 挑战：RAG 技术 “攻坚克难”  之路"></a>4.2 挑战：RAG 技术 “攻坚克难”  之路</h4><p>RAG 技术虽然取得了显著进展，但仍然面临着一些挑战：</p>
<ul>
<li><p>**中间丢失问题 (Lost in the Middle)**：  LLM 在处理长文本输入时，更容易关注开头和结尾部分的信息，而忽略中间部分的信息，导致 RAG 系统无法充分利用检索到的上下文。  就像 “注意力分散”，LLM 在阅读长篇文章时，容易忽略中间段落的内容。</p>
</li>
<li><p>**幻觉问题 (Hallucination)**：  即使使用了 RAG，LLM 仍然可能生成与检索到的文档不一致的信息，出现 “一本正经地胡说八道” 的情况。  就像 “记忆偏差”，LLM 有时候会 “脑补” 一些不存在的事实。</p>
</li>
<li><p><strong>检索效率与效果的平衡</strong>：  提高检索精度往往会牺牲检索效率，如何在保证检索效果的同时，提高检索速度，是一个需要持续优化的方向。 就像 “鱼与熊掌不可兼得”，需要在检索的准确性和速度之间找到平衡点。</p>
</li>
<li><p><strong>知识库的构建与维护</strong>：  构建高质量、动态更新的知识库，需要投入大量的人力物力，如何高效地构建和维护知识库，是一个实际应用中需要考虑的问题。 就像 “建图书馆”，需要收集大量的书籍，并定期更新。</p>
</li>
<li><p><strong>多语言与跨语言支持</strong>：  如何处理不同语言的知识库，以及实现跨语言的检索和生成，仍然是一个具有挑战性的问题。 就像 “跨语言交流”，需要克服语言障碍，实现不同语言之间的信息互通。</p>
</li>
<li><p>**可解释性 (Explainability)**：  如何解释 RAG 模型的决策过程，让人们了解 RAG 系统为什么给出这样的答案，提高模型的可信度，是一个重要的研究方向。 就像 “黑盒变白盒”，让人们了解 AI 的思考过程，增加信任感。</p>
</li>
<li><p>**长上下文处理 (Long Context Handling)**： 如何高效地处理长上下文，以及是否需要进行多轮检索和上下文压缩，以应对越来越长的用户问题和知识库文档。 就像 “阅读理解马拉松”，如何处理越来越长的阅读材料，并从中提取关键信息。</p>
</li>
</ul>
<h3 id="五、总结：RAG，通往更智能-AI-的桥梁"><a href="#五、总结：RAG，通往更智能-AI-的桥梁" class="headerlink" title="五、总结：RAG，通往更智能 AI 的桥梁"></a>五、总结：RAG，通往更智能 AI 的桥梁</h3><p>RAG 技术是当前 LLM 领域最受关注的技术之一，它为 LLM 注入了 “检索” 的能力，使其在知识密集型任务中表现更出色，应用前景广阔。 尽管 RAG 技术仍然面临一些挑战，但随着研究的深入和技术的进步，我们有理由相信，RAG 将成为通往更智能、更可靠的 AI 的重要桥梁。</p>
<p>掌握 RAG 技术，就如同掌握了一把开启智能知识引擎大门的钥匙。  无论是构建智能客服、知识问答系统、还是内容创作工具，RAG 都将为你提供强大的技术支撑，助你打造更智能、更强大的 AI 应用。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2202.01110">A Survey on Retrieval-Augmented Text Generation</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.05876">Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.03172">Lost in the Middle: How Language Models Use Long Contexts</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.15217">RAGAS: Automated Evaluation of Retrieval Augmented Generation</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/BAAI/bge-large-en">BGE: BAAI General Embedding</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/thenlper/gte-large">GTE: General Text Embeddings</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/intfloat/e5-large-v2">E5: EmbEddings from bidirEctional Encoder rEpresentations</a></li>
<li><a target="_blank" rel="noopener" href="https://jina.ai/news/jina-embeddings-v2-8192-tokens-for-text-and-code-are-here/">Jina Embeddings</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/Xenova/text-embedding-ada-002">text-embedding-ada-002</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>RAG 技术概要</div>
      <div>https://gawain12.github.io/2024/09/11/Rag/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Gawain</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年9月11日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/11/01/GAT&#39;s%20Toturial/" title="GAT教程">
                        <span class="hidden-mobile">GAT教程</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'Gawain12/comment-utterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
