<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>DeepLearningTextCNN</title>
    <url>/2021/08/22/DeepLearningTextCNN/</url>
    <content><![CDATA[<h1 id="深度学习算法背景"><a href="#深度学习算法背景" class="headerlink" title="深度学习算法背景"></a>深度学习算法背景</h1><h2 id="人工智能发展历史"><a href="#人工智能发展历史" class="headerlink" title="人工智能发展历史"></a>人工智能发展历史</h2><p><img src="https://ptpimg.me/r97b26.jpg" alt="人工智能的发展历史"><br>随着算力提高以及深度学习的应用，近几年算法发展很快</p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul>
<li><strong>计算机视觉</strong> 用于车牌识别和面部识别等的应用。</li>
<li><strong>信息检索</strong> 用于诸如搜索引擎的应用 - 包括文本搜索和图像搜索。</li>
<li><strong>市场营销</strong> 针对自动电子邮件营销和目标群体识别等的应用。</li>
<li><strong>医疗诊断</strong> 诸如癌症识别和异常检测等的应用。</li>
<li><strong>自然语言处理</strong> 如情绪分析和照片标记标题归类等的应用。</li>
</ul>
<h2 id="机器学习和深度学习关系与区别"><a href="#机器学习和深度学习关系与区别" class="headerlink" title="机器学习和深度学习关系与区别"></a>机器学习和深度学习关系与区别</h2><h4 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h4><p>深度学习定义：深度学习是一种特殊的机器学习，通过学习将世界使用嵌套的概念层次来表示并实现巨大的功能和灵活性，其中每个概念都定义为与简单概念相关联，而更为抽象的表示则以较不抽象的方式来计算。</p>
<h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><p>深度学习对比常规的的机器学习来说，它需要训练的数据更多，而且参数可以自动调节，机器学习通常cpu也能训练，但是深度学习需要显卡训练</p>
<h1 id="TextCNN算法原理"><a href="#TextCNN算法原理" class="headerlink" title="TextCNN算法原理"></a>TextCNN算法原理</h1><p>若有兴趣可以看这篇文章：<a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/"><em>Understanding Convolutional Neural Networks for NLP</em></a></p>
<p>Yoon Kim于2014年发表论文<a href="https://arxiv.org/pdf/1408.5882.pdf"><em>Convolutional Neural Networks for Sentence Classification</em></a>将CNN第一次引入NLP（自然语言处理）的应用，此前CNN几乎都是应用于图像识别领域。</p>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><p>CNN全称 Convolutional Neural Networks ，卷积神经网络，正如他的名字他的灵感来源是人的神经结构，最先由科学家杨立昆(Yann Lee Cun)提出，</p>
<p>何谓卷积，就是利用一种数学方法提取信息的特征。对于图片用矩阵可以很好描述像素点的分布特征，<br><img src="https://ptpimg.me/739919.gif" alt="在这里插入图片描述"><br>动图理解卷积运算的过程，</p>
<h2 id="TextCNN结构"><a href="#TextCNN结构" class="headerlink" title="TextCNN结构"></a>TextCNN结构</h2><p><img src="https://ptpimg.me/533622.png" alt="在这里插入图片描述"></p>
<h3 id="嵌入层-embedding-layer"><a href="#嵌入层-embedding-layer" class="headerlink" title="嵌入层(embedding layer)"></a>嵌入层(embedding layer)</h3><p><strong>TextCNN</strong>使用预先训练好的词向量作embedding layer。对于数据集里的所有词，因为每个词都可以表征成一个向量，因此我们可以得到一个嵌入矩阵MM, MM里的每一行都是词向量。这个MM可以是静态(static)的，也就是固定不变。可以是非静态(non-static)的，也就是可以根据反向传播更新。<br>多种模型：Convolutional Neural Networks for Sentence Classification文章中给出了几种模型，其实这里基本都是针对Embedding layer做的变化。<strong>CNN-rand、CNN-static、CNN-non-static、CNN-multichannel</strong><br>具体介绍及实验结果可见原论文，以上是学术定义</p>
<p>我个人理解是：<br>文字无法被直接被计算机识别，需要编码，将其映射为2维的矩阵</p>
<h3 id="卷积池化层-convolution-and-pooling"><a href="#卷积池化层-convolution-and-pooling" class="headerlink" title="卷积池化层(convolution and pooling)"></a>卷积池化层(convolution and pooling)</h3><h4 id="卷积-convolution"><a href="#卷积-convolution" class="headerlink" title="卷积(convolution)"></a>卷积(convolution)</h4><p>输入一个句子，首先对这个句子进行切词，假设有s个单词。对每个词，跟句嵌入矩阵M, 可以得到词向量。假设词向量一共有d维。那么对于这个句子，便可以得到s行d列的矩阵AϵRs×d.<br>我们可以把矩阵A看成是一幅图像，使用卷积神经网络去提取特征。由于句子中相邻的单词关联性总是很高的，因此可以使用一维卷积，即文本卷积与图像卷积的不同之处在于只在文本序列的一个方向（垂直）做卷积，卷积核的宽度固定为词向量的维度d。高度是超参数，可以设置。 对句子单词每个可能的窗口做卷积操作得到特征图(feature map) c &#x3D; [c_1, c_2, …, c_s-h+1]。</p>
<p>现在假设有一个卷积核，是宽度为d，高度为h的矩阵w，那么w有h∗d个参数需要被更新。对于一个句子，经过嵌入层之后可以得到矩阵AϵRs×d。 A[i:j]表示A的第i行到第j行, 那么卷积操作可以用公式表示：o<del>i</del> &#x3D; w · A[i : i + h − 1] , i &#x3D; 1 . . . s − h + 1<br>叠加上偏置b,在使用激活函数f激活, 得到所需的特征。公式如下：c<del>i</del> &#x3D; f(o<del>i</del> + b). </p>
<p>对一个卷积核，可以得到特征cϵRs−h+1, 总共s−h+1个特征。我们可以使用更多高h不同的卷积核，得到更丰富的特征表达。</p>
<p>Note: </p>
<ol>
<li><p>TextCNN网络包括很多不同窗口大小的卷积核，常用的filter size ∈ {3,4,5}，每个filter的feature maps&#x3D;100。这里的特征图就是不同的k元语法。如上图中分别有两个不同的二、三和四元语法。<br>如果设置padding&#x3D;’same’即使用宽卷积，则每个feature maps for each region size都是seq_len<em>1，所有的feature map可以拼接成seq_len</em>(num_filters*num_filter_size)的矩阵，回到输入类似维度，这样就可以使用多层cnn了。</p>
</li>
<li><p>通道（Channels）：图像中可以利用 (R, G, B) 作为不同channel。而文本的输入的channel通常是不同方式的embedding方式（比如 word2vec或Glove），实践中也有利用静态词向量和fine-tunning词向量作为不同channel的做法；channel也可以一个是词序列，另一个channel是对应的词性序列。接下来就可以通过加和或者拼接进行结合。</p>
</li>
</ol>
<h3 id="池化-pooling"><a href="#池化-pooling" class="headerlink" title="池化(pooling)"></a>池化(pooling)</h3><p>不同尺寸的卷积核得到的特征(feature map)大小也是不一样的，因此我们对每个feature map使用池化函数，使它们的维度相同。</p>
<h5 id="Max-Pooling"><a href="#Max-Pooling" class="headerlink" title="Max Pooling"></a>Max Pooling</h5><p>最常用的就是1-max pooling，提取出feature map照片那个的最大值，通过选择每个feature map的最大值，可捕获其最重要的特征。这样每一个卷积核得到特征就是一个值，对所有卷积核使用1-max pooling，再级联起来，可以得到最终的特征向量，这个特征向量再输入softmax layer做分类。这个地方可以使用drop out防止过拟合。</p>
<h5 id="Average-Pooling"><a href="#Average-Pooling" class="headerlink" title="Average Pooling"></a>Average Pooling</h5><p>average pooling即取每个维度的均值而不是最大值。理解是对句子中的连续词袋(CBOW)而不是词进行卷积得到的表示（lz：每个filter都是对cbow来的）。<br>其他池化方式K-Max Pooling、动态k-max pooling可见论文<a href="https://www.cnblogs.com/szxspark/p/10262681.html">《Event Extraction via Dynamic Multi-Pooling Convolutional Neural Network》</a>[2]</p>
<h3 id="简单模型结构的示例分析"><a href="#简单模型结构的示例分析" class="headerlink" title="简单模型结构的示例分析"></a>简单模型结构的示例分析</h3><p>分析<a href="http://link.zhihu.com/?target=https://arxiv.org/pdf/1510.03820.pdf">《A Sensitivity Analysis …》</a>[2]模型示意图：</p>
<p><img src="https://ptpimg.me/q61c16.png" alt="在这里插入图片描述"></p>
<p>word embedding的维度是5，对于句子 i like this movie very much，转换成矩阵AϵR7×5；<br>有6个卷积核，尺寸为(2×5), (3×5), (4×5)，每种尺寸各2个，A分别与以上卷积核进行卷积操作（这里的Stride Size相当于等于高度h）；</p>
<p>再用激活函数激活，每个卷积核得到了特征向量(feature maps)；<br>使用1-max pooling提取出每个feature map的最大值；</p>
<p>然后在级联得到最终的特征表达；<br>将特征输入至softmax layer进行分类, 在这层可以进行正则化操作( l2-regulariation)。</p>
<h2 id="实验参数分析"><a href="#实验参数分析" class="headerlink" title="实验参数分析"></a>实验参数分析</h2><p>TextCNN模型中，超参数主要有词向量，Region Size的大小，Feature Map的数量，激活函数的选择，Pooling的方法，正则化的影响。《A Sensitivity Analysis…》论文前面几章对实验内容和结果进行了详细介绍，在9个数据集上基于Kim Y的模型做了大量的调参实验，得出AUC进行比较，根据的实验对比：</p>
<p>1）<strong>初始化词向量</strong>：一般不直接使用One-hot。除了随机初始化Embedding layer的外，使用预训练的word2vec、 GloVe初始化的效果都更加好（具体哪个更好依赖于任务本身）。非静态的比静态的效果好一些。</p>
<p>2）<strong>卷积核的尺寸filter_sizes</strong>：影响较大，通常过滤器的大小范围在1-10之间，一般取为3-5，对于句子较长的文本（100+），则应选择大一些。为了找到最优的过滤器大小(Filter Region Size)，可以使用线性搜索的方法。对不同尺寸ws的窗口进行结合会对结果产生影响。当把与最优ws相近的ws结合时会提升效果，但是如果将距离最优ws较远的ws相结合时会损害分类性能。刚开始，我们可以只用一个filter，调节Region Size来比对各自的效果，来看看那种size有最好的表现，然后在这个范围在调节不同Region的匹配。</p>
<p>3）<strong>卷积核的数量num_filters（对每个巻积核尺寸来说）</strong>：有较大的影响，一般取100<del>600（需要兼顾模型的训练效率） ，同时一般使用Dropout（0</del>0.5）。最好不要超过600，超过600可能会导致过拟合。可设为100-200。</p>
<p>4）<strong>激活函数</strong>：可以尽量多尝试激活函数，实验发现ReLU和tanh两种激活函数表现较佳。</p>
<p>5）<strong>池化选择</strong>：1-max pooling（1-max pooling的方式已经足够好了，相比于其他的pooling方式而言）。</p>
<p>6）<strong>Dropout和正则化</strong>：Dropout rate &#x2F; dropout_keep_prob：dropout一般设为0.5。随着feature map数量增加，性能减少时，可以考虑增大正则化的力度，如尝试大于0.5的Dropout。</p>
<p>   正则化的作用微乎其微，正则项对最终模型性能的影响很小。l2正则化效益很小，所以这里建议设置一个比较大的L2 norm constrain，相比而言，dropout在神经网络中有着广泛的使用和很好的效果。</p>
<p>7）为了检验模型的性能水平，多次反复的交叉验证是必要的，这可以确保模型的高性能并不是偶然。</p>
<p>8） <strong>随机性影响</strong>：由于模型训练过程中的随机性因素，如随机初始化的权重参数，mini-batch，随机梯度下降优化算法等，造成模型在数据集上的结果有一定的浮动，如准确率(accuracy)能达到1.5%的浮动，而AUC则有3.4%的浮动。</p>
<p>其它的训练参数：batch_size：64；num_epochs：10；每checkpoint_every：100轮便保存模型；仅保存最近num_checkpoints：5次模型</p>
<h1 id="实现文本分类的过程"><a href="#实现文本分类的过程" class="headerlink" title="实现文本分类的过程"></a>实现文本分类的过程</h1><h2 id="Text-Classification-with-CNN"><a href="#Text-Classification-with-CNN" class="headerlink" title="Text Classification with CNN"></a>Text Classification with CNN</h2><p>使用卷积神经网络进行中文文本分类</p>
<h2 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h2><ul>
<li>Python 3.6.8</li>
<li>TensorFlow 1.8.0</li>
<li>numpy</li>
<li>scikit-learn</li>
<li>scipy</li>
</ul>
<h2 id="硬件环境"><a href="#硬件环境" class="headerlink" title="硬件环境"></a>硬件环境</h2><ul>
<li>CPU:Ryzen 2500U(2.0GHZ)</li>
<li>Menmory: 16G</li>
<li><strong>注</strong>：轻薄本不适合训练深度学习，该环境运行10+小时，同时内存必须大于8G，不然会爆内存</li>
</ul>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>本训练集由predict_check_data表的17万条产品名称和对应分类组成。</p>
<h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p><code>data_prepare.py</code>运行该程序，即可根据数据表，生成指定的训练，测试，验证集。</p>
<p><code>data/cnews_loader.py</code>为数据的预处理文件。</p>
<ul>
<li><code>read_file()</code>: 读取文件数据;</li>
<li><code>build_vocab()</code>: 构建词汇表，使用字符级的表示，这一函数会将词汇表存储下来，避免每一次重复处理;</li>
<li><code>read_vocab()</code>: 读取上一步存储的词汇表，转换为<code>&#123;词：id&#125;</code>表示;</li>
<li><code>read_category()</code>: 将分类目录固定，转换为<code>&#123;类别: id&#125;</code>表示;</li>
<li><code>to_words()</code>: 将一条由id表示的数据重新转换为文字;</li>
<li><code>process_file()</code>: 将数据集从文字转换为固定长度的id序列表示;</li>
<li><code>batch_iter()</code>: 为神经网络的训练准备经过shuffle的批次的数据。</li>
</ul>
<p>经过数据预处理，数据的格式如下：</p>
<table>
<thead>
<tr>
<th align="left">Data</th>
<th align="left">Shape</th>
<th align="left">Data</th>
<th align="left">Shape</th>
</tr>
</thead>
<tbody><tr>
<td align="left">x_train</td>
<td align="left">[50000, 600]</td>
<td align="left">y_train</td>
<td align="left">[50000, 10]</td>
</tr>
<tr>
<td align="left">x_val</td>
<td align="left">[5000, 600]</td>
<td align="left">y_val</td>
<td align="left">[5000, 10]</td>
</tr>
<tr>
<td align="left">x_test</td>
<td align="left">[10000, 600]</td>
<td align="left">y_test</td>
<td align="left">[10000, 10]</td>
</tr>
</tbody></table>
<h2 id="CNN卷积神经网络"><a href="#CNN卷积神经网络" class="headerlink" title="CNN卷积神经网络"></a>CNN卷积神经网络</h2><h3 id="配置项"><a href="#配置项" class="headerlink" title="配置项"></a>配置项</h3><p>CNN可配置的参数如下所示，在<code>cnn_model.py</code>中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TCNNConfig</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;CNN配置参数&quot;&quot;&quot;</span><br><br>    embedding_dim = <span class="hljs-number">128</span>  <span class="hljs-comment"># 词向量维度</span><br>    seq_length = <span class="hljs-number">300</span>  <span class="hljs-comment"># 序列长度</span><br>    <span class="hljs-comment"># num_classes = 668  # 类别数</span><br>    num_filters = <span class="hljs-number">1024</span>  <span class="hljs-comment"># 卷积核数目</span><br>    kernel_size = <span class="hljs-number">3</span>  <span class="hljs-comment"># 卷积核尺寸</span><br>    vocab_size = <span class="hljs-number">8000</span>  <span class="hljs-comment"># 词汇表大小</span><br><br>    hidden_dim = <span class="hljs-number">256</span>  <span class="hljs-comment"># 全连接层神经元</span><br><br>    dropout_keep_prob = <span class="hljs-number">0.55</span>  <span class="hljs-comment"># dropout保留比例</span><br>    learning_rate = <span class="hljs-number">1e-3</span>  <span class="hljs-comment"># 学习率</span><br><br>    batch_size = <span class="hljs-number">64</span>  <span class="hljs-comment"># 每批训练大小</span><br>    num_epochs = <span class="hljs-number">20</span>  <span class="hljs-comment"># 总迭代轮次</span><br><br>    print_per_batch = <span class="hljs-number">100</span>  <span class="hljs-comment"># 每多少轮输出一次结果</span><br>    save_per_batch = <span class="hljs-number">10</span>  <span class="hljs-comment"># 每多少轮存入tensorboard</span><br></code></pre></td></tr></table></figure>

<h3 id="CNN模型"><a href="#CNN模型" class="headerlink" title="CNN模型"></a>CNN模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TextCNN</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;文本分类，CNN模型&quot;&quot;&quot;</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-variable language_">self</span>.config = config<br>        <span class="hljs-comment"># 三个待输入的数据</span><br>        <span class="hljs-variable language_">self</span>.input_x = tf.placeholder(tf.int32, [<span class="hljs-literal">None</span>, <span class="hljs-variable language_">self</span>.config.seq_length], name=<span class="hljs-string">&#x27;input_x&#x27;</span>)<br>        <span class="hljs-variable language_">self</span>.input_y = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-variable language_">self</span>.config.num_classes], name=<span class="hljs-string">&#x27;input_y&#x27;</span>)<br>        <span class="hljs-variable language_">self</span>.keep_prob = tf.placeholder(tf.float32, name=<span class="hljs-string">&#x27;keep_prob&#x27;</span>)<br><br>        <span class="hljs-variable language_">self</span>.cnn()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">cnn</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;CNN模型&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 词向量映射</span><br>        <span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">&#x27;/cpu:0&#x27;</span>):<br>            embedding = tf.get_variable(<span class="hljs-string">&#x27;embedding&#x27;</span>, [<span class="hljs-variable language_">self</span>.config.vocab_size, <span class="hljs-variable language_">self</span>.config.embedding_dim])<br>            embedding_inputs = tf.nn.embedding_lookup(embedding, <span class="hljs-variable language_">self</span>.input_x)<br><br>        <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&quot;cnn&quot;</span>):<br>            <span class="hljs-comment"># CNN layer 3*3</span><br>            conv_1 = tf.layers.conv1d(embedding_inputs, <span class="hljs-variable language_">self</span>.config.num_filters, <span class="hljs-variable language_">self</span>.config.kernel_size, name=<span class="hljs-string">&#x27;conv_1&#x27;</span>)<br>            <span class="hljs-comment"># global max pooling layer</span><br>            gmp_1 = tf.reduce_max(conv_1, reduction_indices=[<span class="hljs-number">1</span>], name=<span class="hljs-string">&#x27;gmp_1&#x27;</span>)<br><br>        <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&quot;score&quot;</span>):<br>            <span class="hljs-comment"># 全连接层，后面接dropout以及relu激活</span><br>            fc_1 = tf.layers.dense(gmp_1, <span class="hljs-variable language_">self</span>.config.hidden_dim, name=<span class="hljs-string">&#x27;fc_1&#x27;</span>)<br>            fc_1 = tf.contrib.layers.dropout(fc_1, <span class="hljs-variable language_">self</span>.keep_prob)<br>            fc_1 = tf.nn.relu(fc_1)<br>            <span class="hljs-comment"># 分类器</span><br>            <span class="hljs-variable language_">self</span>.logits = tf.layers.dense(fc_1, <span class="hljs-variable language_">self</span>.config.num_classes, name=<span class="hljs-string">&#x27;fc_2&#x27;</span>)<br>            <span class="hljs-variable language_">self</span>.y_pred_cls = tf.argmax(tf.nn.softmax(<span class="hljs-variable language_">self</span>.logits), <span class="hljs-number">1</span>)  <span class="hljs-comment"># 预测类别</span><br><br>        <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&quot;optimize&quot;</span>):<br>            <span class="hljs-comment"># 损失函数，交叉熵</span><br>            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=<span class="hljs-variable language_">self</span>.logits, labels=<span class="hljs-variable language_">self</span>.input_y)<br>            <span class="hljs-variable language_">self</span>.loss = tf.reduce_mean(cross_entropy)<br>            <span class="hljs-comment"># 优化器</span><br>            <span class="hljs-variable language_">self</span>.optim = tf.train.AdamOptimizer(learning_rate=<span class="hljs-variable language_">self</span>.config.learning_rate).minimize(<span class="hljs-variable language_">self</span>.loss)<br><br>        <span class="hljs-keyword">with</span> tf.name_scope(<span class="hljs-string">&quot;accuracy&quot;</span>):<br>            <span class="hljs-comment"># 准确率</span><br>            correct_pred = tf.equal(tf.argmax(<span class="hljs-variable language_">self</span>.input_y, <span class="hljs-number">1</span>), <span class="hljs-variable language_">self</span>.y_pred_cls)<br>            <span class="hljs-variable language_">self</span>.acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))<br></code></pre></td></tr></table></figure>
<h3 id="训练与验证"><a href="#训练与验证" class="headerlink" title="训练与验证"></a>训练与验证</h3><p>运行 <code>python run_cnn.py train</code>，可以开始训练。</p>
<blockquote>
<p>若之前进行过训练，请把tensorboard&#x2F;textcnn删除，避免TensorBoard多次训练结果重叠。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">Configuring CNN model...<br>Configuring TensorBoard and Saver...<br>Loading training and validation data...<br>Time usage: 0:00:14<br>Training and evaluating...<br>Epoch: 1<br>Iter:      0, Train Loss:    8.9, Train Acc:   0.00%, Val Loss:    8.9, Val Acc:   0.00%, Time: 0:00:15<br>Iter:    100, Train Loss:    7.1, Train Acc:   3.12%, Val Loss:    7.3, Val Acc:   1.75%, Time: 0:00:22 *<br>Iter:    200, Train Loss:    6.7, Train Acc:   9.38%, Val Loss:    6.9, Val Acc:   7.68%, Time: 0:00:29 *<br>Iter:    300, Train Loss:    5.8, Train Acc:  20.31%, Val Loss:    6.4, Val Acc:  15.43%, Time: 0:00:35 *<br>Iter:    400, Train Loss:    5.8, Train Acc:  18.75%, Val Loss:    5.8, Val Acc:  23.33%, Time: 0:00:42 *<br>Iter:    500, Train Loss:    5.4, Train Acc:  29.69%, Val Loss:    5.3, Val Acc:  30.68%, Time: 0:00:49 *<br>Iter:    600, Train Loss:    4.1, Train Acc:  40.62%, Val Loss:    5.0, Val Acc:  37.10%, Time: 0:00:56 *<br>Iter:    700, Train Loss:    4.3, Train Acc:  40.62%, Val Loss:    4.7, Val Acc:  39.64%, Time: 0:01:03 *<br>Iter:    800, Train Loss:    4.1, Train Acc:  48.44%, Val Loss:    4.5, Val Acc:  43.47%, Time: 0:01:10 *<br>Iter:    900, Train Loss:    4.2, Train Acc:  37.50%, Val Loss:    4.3, Val Acc:  45.70%, Time: 0:01:17 *<br>Iter:   1000, Train Loss:    3.0, Train Acc:  56.25%, Val Loss:    4.1, Val Acc:  48.36%, Time: 0:01:23 *<br>Iter:   1100, Train Loss:    4.3, Train Acc:  50.00%, Val Loss:    4.0, Val Acc:  50.28%, Time: 0:01:30 *<br>Iter:   1200, Train Loss:    3.5, Train Acc:  53.12%, Val Loss:    3.9, Val Acc:  51.55%, Time: 0:01:37 *<br>Iter:   1300, Train Loss:    4.2, Train Acc:  50.00%, Val Loss:    3.8, Val Acc:  52.80%, Time: 0:01:44 *<br>Iter:   1400, Train Loss:    2.6, Train Acc:  59.38%, Val Loss:    3.6, Val Acc:  54.80%, Time: 0:01:51 *<br>Iter:   1500, Train Loss:    4.0, Train Acc:  51.56%, Val Loss:    3.5, Val Acc:  55.76%, Time: 0:01:58 *<br>Iter:   1600, Train Loss:    4.1, Train Acc:  46.88%, Val Loss:    3.5, Val Acc:  56.52%, Time: 0:02:05 *<br>Iter:   1700, Train Loss:    3.0, Train Acc:  59.38%, Val Loss:    3.4, Val Acc:  57.38%, Time: 0:02:12 *<br>Iter:   1800, Train Loss:    2.9, Train Acc:  60.94%, Val Loss:    3.3, Val Acc:  58.31%, Time: 0:02:19 *<br>Iter:   1900, Train Loss:    3.8, Train Acc:  50.00%, Val Loss:    3.2, Val Acc:  58.58%, Time: 0:02:26 *<br>Iter:   2000, Train Loss:    3.9, Train Acc:  54.69%, Val Loss:    3.2, Val Acc:  59.42%, Time: 0:02:33 *<br>.<br>.#训练迭代10次后<br>. <br>Epoch: 11<br>Iter:  20800, Train Loss:  0.013, Train Acc: 100.00%, Val Loss:   0.44, Val Acc:  92.10%, Time: 0:24:38 *<br>Iter:  20900, Train Loss:  0.012, Train Acc: 100.00%, Val Loss:   0.44, Val Acc:  92.15%, Time: 0:24:45 *<br>Iter:  21000, Train Loss:  0.025, Train Acc:  98.44%, Val Loss:   0.47, Val Acc:  91.75%, Time: 0:24:51<br>Iter:  21100, Train Loss:  0.026, Train Acc: 100.00%, Val Loss:   0.43, Val Acc:  92.22%, Time: 0:24:58 *<br>Iter:  21200, Train Loss:  0.094, Train Acc:  98.44%, Val Loss:   0.46, Val Acc:  91.80%, Time: 0:25:05<br>Iter:  21300, Train Loss:   0.17, Train Acc:  98.44%, Val Loss:   0.45, Val Acc:  92.25%, Time: 0:25:12 *<br>Iter:  21400, Train Loss:  0.094, Train Acc:  96.88%, Val Loss:   0.46, Val Acc:  92.18%, Time: 0:25:18<br>Iter:  21500, Train Loss:  0.029, Train Acc:  98.44%, Val Loss:   0.45, Val Acc:  91.92%, Time: 0:25:25<br>Iter:  21600, Train Loss:   0.11, Train Acc:  98.44%, Val Loss:   0.44, Val Acc:  92.10%, Time: 0:25:31<br>Iter:  21700, Train Loss:  0.099, Train Acc:  98.44%, Val Loss:   0.46, Val Acc:  91.93%, Time: 0:25:38<br>Iter:  21800, Train Loss:  0.069, Train Acc:  98.44%, Val Loss:   0.46, Val Acc:  91.68%, Time: 0:25:45<br>Iter:  21900, Train Loss:  0.097, Train Acc:  96.88%, Val Loss:   0.46, Val Acc:  91.90%, Time: 0:25:51<br>Iter:  22000, Train Loss:  0.024, Train Acc:  98.44%, Val Loss:   0.45, Val Acc:  92.13%, Time: 0:25:58<br>Iter:  22100, Train Loss:   0.01, Train Acc: 100.00%, Val Loss:   0.43, Val Acc:  92.14%, Time: 0:26:05<br>Iter:  22200, Train Loss:   0.11, Train Acc:  98.44%, Val Loss:   0.43, Val Acc:  92.25%, Time: 0:26:11<br>Iter:  22300, Train Loss:  0.011, Train Acc: 100.00%, Val Loss:   0.43, Val Acc:  92.21%, Time: 0:26:18<br>No optimization for a long time, auto-stopping...<br></code></pre></td></tr></table></figure>


<p>在验证集上的最佳效果为92.25%.</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>运行 <code>python run_cnn.py test</code> 在测试集上进行测试。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">Configuring CNN model...<br>Loading test data...<br>Testing...<br>Test Loss:   0.46, Test Acc:  91.85%<br></code></pre></td></tr></table></figure>
<p>在测试集上的准确率达到了91.85%。</p>
<h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><p>运行 <code>python run_cnn.py predict</code> 在预测集上进行预测。</p>
<p>预测集命名为<code>name2category.predict.txt</code>,放入data中的name2category文件夹，每行一个产品名称。</p>
<p>输出在目录文件夹，名称为<code>predicted_data.txt</code></p>
<h3 id="功能调用"><a href="#功能调用" class="headerlink" title="功能调用"></a>功能调用</h3><p>调用方法为:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> run_cnn <span class="hljs-keyword">import</span> name2subcategory<br><br>name_list = [<span class="hljs-string">&#x27;乔思伯 JONSBO CR-201RGB版本RGBCPU散热器（黑色/多平台/4热管/温控/12CM风扇/支持AURARGB/附硅脂）&#x27;</span>] <br>a = name2subcategory()<br>category = a.namelyst_predict(name_list)<br></code></pre></td></tr></table></figure>

<p>输入一个含有多个产品名称的列表，返回一个各名称子类的列表。</p>
]]></content>
  </entry>
  <entry>
    <title>PT服务器工具</title>
    <url>/2022/05/11/PT%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>本文主要包括PT的各类辅种发种的shell命令，电影种的截图制种，音乐种的抓流、转码、发种频谱图等等。</p>
<h3 id="服务器性能测试脚本"><a href="#服务器性能测试脚本" class="headerlink" title="服务器性能测试脚本"></a>服务器性能测试脚本</h3><p><a href="https://zhuanlan.zhihu.com/p/117547388">其他脚本参考</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">wget -qO- --no-check-certificate https://raw.githubusercontent.com/oooldking/script/master/superbench.sh | bash<br></code></pre></td></tr></table></figure>

<p>两个大家常用的脚本，基本集成了多数需要的发种工具，(有概率装不上其他软件比如wine)<br><a href="https://github.com/Aniverse/inexistence">星大Inexistence</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">bash &lt;(wget --no-check-certificate -qO- https://github.com/Aniverse/inexistence/raw/master/inexistence.sh)<br></code></pre></td></tr></table></figure>
<p><a href="https://github.com/jerry048/Dedicated-Seedbox">Jerry048</a></p>
<figure class="highlight vim"><table><tr><td class="code"><pre><code class="hljs vim">bash &lt;(wget -qO- https://raw.githubusercontent.<span class="hljs-keyword">com</span>/jerry048/Dedicated-Seedbox/main/Install.<span class="hljs-keyword">sh</span>) <span class="hljs-symbol">&lt;username&gt;</span> <span class="hljs-symbol">&lt;password&gt;</span> &lt;Cache Size(uni<span class="hljs-variable">t:GiB</span>)&gt;<br># 格式类似，注意空格 name password <span class="hljs-number">16</span> GB<br></code></pre></td></tr></table></figure>


<h1 id="虚拟环境搭建"><a href="#虚拟环境搭建" class="headerlink" title="虚拟环境搭建"></a>虚拟环境搭建</h1><h4 id="Docker一键安装"><a href="#Docker一键安装" class="headerlink" title="Docker一键安装"></a>Docker一键安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">curl -fsSL https://get.docker.com -o get-docker.sh<br>sh get-docker.sh<br></code></pre></td></tr></table></figure>
<h4 id="conda安装使用"><a href="#conda安装使用" class="headerlink" title="conda安装使用"></a>conda安装使用</h4><p>主要用于python的运行，比起virtualenv，conda最大优点是可以自动安装指定新版本python，不用本地环境</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">wget -4 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh<br><span class="hljs-meta prompt_">#</span><span class="language-bash">第二步安装</span><br>sh Miniconda3-py39_4.9.2-Linux-x86_64.sh<br><span class="hljs-meta prompt_">#</span><span class="language-bash">第三步配置conda镜像</span><br><br>export PATH=/root/miniconda3/bin:$PATH<br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">alias</span> ohmyzsh=<span class="hljs-string">&quot;mate ~/.oh-my-zsh&quot;</span></span><br><br>vim ~/.zshrc<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment"># 添加下面的内容</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">&gt;&gt;&gt; conda initialize &gt;&gt;&gt;</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">!! Contents within this block are managed by <span class="hljs-string">&#x27;conda init&#x27;</span> !!</span><br>__conda_setup=&quot;$(&#x27;/root/miniconda3/bin/conda&#x27; &#x27;shell.zsh&#x27; &#x27;hook&#x27; 2&gt; /dev/null)&quot;<br>if [ $? -eq 0 ]; then<br>    eval &quot;$__conda_setup&quot;<br>else<br>    if [ -f &quot;/root/miniconda3/etc/profile.d/conda.sh&quot; ]; then<br>        . &quot;/root/miniconda3/etc/profile.d/conda.sh&quot;<br>    else<br>        export PATH=&quot;/root/miniconda3/bin:$PATH&quot;<br>    fi<br>fi<br>unset __conda_setup<br><span class="hljs-meta prompt_"># </span><span class="language-bash">&lt;&lt;&lt; <span class="hljs-string">conda initialize &lt;&lt;&lt;</span></span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-string">添加完后激活</span></span><br>source ~/.zshrc<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-string">使用</span></span><br>conda create -n py39 python=3.9<br>conda activate py39<br></code></pre></td></tr></table></figure>

<h1 id="下载器工具"><a href="#下载器工具" class="headerlink" title="下载器工具"></a>下载器工具</h1><h2 id="transmission"><a href="#transmission" class="headerlink" title="transmission"></a>transmission</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">version: &quot;3.2&quot;<br><br>services:<br>  transmission:<br>    image: chisbread/transmission<br>    container_name: transmission<br>    environment:<br>      - PUID=0<br>      - PGID=0<br>      - TZ=Asia/Shanghai<br>      - USER= <br>      - PASS=<br>      - PEERPORT=10413<br>    volumes:<br>      - /tr/config:/config<br>      - /tr/downloads:/downloads<br>      - /tr/watch:/watch<br>      <br>    ports:<br>      - 9091:9091<br>      - 10413:10413<br>      - 10413:10413/udp<br>    restart: unless-stopped<br></code></pre></td></tr></table></figure>

<p>配置好yml文件后需要下载docker-compose命令<br>在对应的目录输入docker-compose up<br><a href="https://blog.csdn.net/shangyexin/article/details/122085552?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2.pc_relevant_paycolumn_v3&utm_relevant_index=5">具体参考这篇文章</a></p>
<h2 id="Usenet下载器sabnzbd"><a href="#Usenet下载器sabnzbd" class="headerlink" title="Usenet下载器sabnzbd"></a>Usenet下载器sabnzbd</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker run -d \<br>  --name=sabnzbd \<br>  -p 8384:8080 \<br>  -e PUID=1000 \<br>  -e PGID=1000 \<br>  -v /home/你的用户名/sabnzbd/config:/config \<br>  -v /home/你的用户名/sabnzbd/downloads:/downloads \<br>  -v /home/你的用户名/sabnzbd/incomplete:/incomplete-downloads \<br>  --restart unless-stopped \<br>  linuxserver/sabnzbd<br></code></pre></td></tr></table></figure>
<p>vim &#x2F;home&#x2F;你的用户名&#x2F;sabnzbd&#x2F;config&#x2F;sabnzbd.ini<br>把–inet_exposure从0修改到5才能正常访问</p>
<ul>
<li>记得替换路径！</li>
</ul>
<h1 id="助手工具"><a href="#助手工具" class="headerlink" title="助手工具"></a>助手工具</h1><h2 id="PPTP"><a href="#PPTP" class="headerlink" title="PPTP"></a>PPTP</h2><p>Chrome<br>Edge</p>
<h2 id="Jackett"><a href="#Jackett" class="headerlink" title="Jackett"></a>Jackett</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker create --name=jackett \<br>--restart=always \<br>-v /root/jackett/config:/config \<br>-v /root/jackett/downloads:/downloads \<br>-e PGID=0 -e PUID=0 \<br>-p 9117:9117 \<br>linuxserver/jackett<br><br>docker start<br></code></pre></td></tr></table></figure>
<h2 id="Prowlarr"><a href="#Prowlarr" class="headerlink" title="Prowlarr"></a>Prowlarr</h2><p>更推荐这个工具，还能支持Usenet的indexer，比上者维护更勤</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker run -d \<br>--name=prowlarr \<br>-e PUID=1000 \<br>-e PGID=1000 \<br>-e TZ=Asia/Shanghai \<br>-p 9696:9696 \<br>-v /prowlarr/config:/config \<br>-v /本地下载目录:/downloads \<br>--restart unless-stopped \<br>linuxserver/prowlarr<br></code></pre></td></tr></table></figure>

<h2 id="IYUU-plus"><a href="#IYUU-plus" class="headerlink" title="IYUU plus"></a>IYUU plus</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">mkdir /root/plus -p<br>docker run -d  --name IYUUPlus  -v /root/plus:/IYUU/db -v /etc/qbit/config/qBittorrent/BT_backup:/qb -v /etc/transmission/config/torrents:/tr -p 8787:8787  --restart=always iyuucn/iyuuplus:latest<br></code></pre></td></tr></table></figure>
<h2 id="seedcross"><a href="#seedcross" class="headerlink" title="seedcross"></a>seedcross</h2><p>辅种外站神器，不过还没成熟有辅错的可能，它的原理是用你下载器的种子通过jackett搜索匹配。<br><a href="https://github.com/ccf-2012/seedcross">github链接</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker run -d --name seedcross -v /somedir/in/host:/code/seedcross/db -p 8019:8019 ccf2012/seedcross:latest<br></code></pre></td></tr></table></figure>
<p>打开8787端口<br>密码为空，第一次输入时你可以自由设置你的密码；以后密码与第一次相同才能登录</p>
<h1 id="FileBrower"><a href="#FileBrower" class="headerlink" title="FileBrower"></a>FileBrower</h1><p>荒野无灯FBE的安装脚，作为网盘可直接做种截图，非常方便</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">mkdir -p ~/docker/fb/config ~/docker/fb/myfiles<br>docker run -d --name fb \<br>  --restart=unless-stopped \<br>  -e PUID=$UID \<br>  -e PGID=$GID \<br>  -e WEB_PORT=8082 \<br>  -e FB_AUTH_SERVER_ADDR=&quot;127.0.0.1&quot; \<br>  -p 8082:8082 \<br>  -v ~/docker/fb/config:/config \<br>  -v /:/myfiles \<br>  --mount type=tmpfs,destination=/tmp \<br>  80x86/filebrowser:2.9.4-amd64<br></code></pre></td></tr></table></figure>


<h1 id="做截图"><a href="#做截图" class="headerlink" title="做截图"></a>做截图</h1><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">ffmpeg -i [视频路径] -r 1 -vframes 4 -q:v 2 -f image2 image-%d.jpeg<br></code></pre></td></tr></table></figure>
<h1 id="Rclone"><a href="#Rclone" class="headerlink" title="Rclone"></a>Rclone</h1><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">安装最新版本rclone</span> <br>apt-get install p7zip-full<br>curl https://rclone.org/install.sh | sudo bash<br></code></pre></td></tr></table></figure>
<p>盒子文件同步到云盘，主要是我盒子拉本地非常慢，所以用云盘做中转。<br>可以是Onedrive、Google drive<br>我这里说阿里云盘</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker run -d \<br>--name=aliyundrive-webdav \<br>--restart=always \<br>-p 8080:8080 \<br>-v $PWD/docker/aliyundrive-webdav/:/etc/aliyundrive-webdav/ \<br> -e REFRESH_TOKEN=&#x27;your refreshToken&#x27; \<br> -e WEBDAV_AUTH_USER=admin \<br> -e WEBDAV_AUTH_PASSWORD=admin \<br> messense/aliyundrive-webdav<br>​<br></code></pre></td></tr></table></figure>
<p>可以点开ip:8080访问，密码账号如上，需要注意的是，换成其他端口可能会服务不了，如果冲突的话先把另一个关了。</p>
<h1 id="Clouddrive2的服务搭建"><a href="#Clouddrive2的服务搭建" class="headerlink" title="Clouddrive2的服务搭建"></a>Clouddrive2的服务搭建</h1><p>这个比rlone更方便，主要是用来挂载115的</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">wget https://github.com/cloud-fs/cloud-fs.github.io/releases/download/v0.8.1/clouddrive-2-linux-x86_64-0.8.1.tgz<br>md /opt/clouddrive<br>tar zxvf clouddrive-2-linux-x86_64-0.8.1.tgz -C /opt/clouddrive<br><br>vim /etc/systemd/system/clouddrive.service<br><span class="hljs-meta prompt_">#</span><span class="language-bash">写入下面的内容，daemon reload</span><br><br></code></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">Description=clouddrive2<br>After=network.target<br><br>[Service]<br>Type=exec<br>Restart=on-failure<br>ExecStart=/opt/clouddrive/clouddrive<br><br>[Install]<br>WantedBy=multi-user.target<br></code></pre></td></tr></table></figure>
<h4 id="Onedrive"><a href="#Onedrive" class="headerlink" title="Onedrive"></a>Onedrive</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">要在mac/win上先用rclone authorize &quot;onedrive&quot;跳转网页授权，返回token（注意要把整个json全复制下来）<br></code></pre></td></tr></table></figure>
<p>同时挂载多个rclone的网盘</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">curl https://rclone.org/install.sh | sudo bash<br><span class="hljs-meta prompt_">#</span><span class="language-bash">安装完成后，运行rclone连接webdav完成配置</span><br>rclone config<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">配置玩rclone后</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">前者上<span class="hljs-built_in">od</span>地址后者上本地地址，复制以下内容创建service</span><br>vim /etc/systemd/system/rclone@.service<br><span class="hljs-meta prompt_">#</span><span class="language-bash">粘贴以下内容</span><br>[Unit]<br>Description=Rclone mount %I drive<br>AssertPathIsDirectory=LocalFolder<br>After=network-online.target<br><br>[Service]<br>Type=simple<br>ExecStart=/usr/bin/rclone mount %i: /mnt/%i \<br>--config /root/.config/rclone/rclone.conf \<br>--copy-links \<br>--no-gzip-encoding \<br>--no-check-certificate \<br>--vfs-cache-mode full \<br>--umask 0000 \<br>--default-permissions \<br>--allow-non-empty \<br>--allow-other \<br>--attr-timeout 5m \<br>--vfs-cache-max-size 1G \<br>--buffer-size 500M \<br>--vfs-read-chunk-size 64M \<br>--vfs-read-chunk-size-limit 1G<br>ExecStop=/bin/fusermount -u LocalFolder<br>Restart=on-abort<br>User=root<br><br>[Install]<br>WantedBy=default.target<br></code></pre></td></tr></table></figure>
<p>&#x2F;mnt改为想挂载的目标目录根目录。配置好后创建挂载目标子目录后可以自动挂载，注意名字要和rclone的remotes一致。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">mkdir /mnt/od1<br>systemctl enable rclone@od1<br>systemctl start rclone@od1<br></code></pre></td></tr></table></figure>
<p>最简单的方法 rclone config file 直接复制conf文件夹内的配置信息，粘贴到对应的服务器</p>
<p><a href="http://bbs.chinauos.com/zh/post/9207">配置教程参考</a>，需要注意最新版可能编号不一样，要自己选择webdav</p>
<h1 id="IRC"><a href="#IRC" class="headerlink" title="IRC"></a>IRC</h1><p>挂在到nas上的thelounge客户端</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">wget -P /root https://github.com/thelounge/thelounge/releases/download/v4.2.0/thelounge_4.2.0_all.deb<br>dpkg -i /root/thelounge_4.2.0_all.deb<br><span class="hljs-comment">#systemctl stop thelounge.service</span><br><span class="hljs-comment">#sed -i &#x27;s/9000,/11111,/g&#x27; /etc/thelounge/config.js</span><br><span class="hljs-comment"># 以上命令替换端口号，9000端口号挺常见容易产生冲突</span><br><span class="hljs-comment"># 比如 docker 的 portainer 镜像默认映射端口号就用的是 9000</span><br><span class="hljs-comment"># 该命令将 9000 端口号替换成 11111，这个可以自定义（1-65535 任选一个没重复的当端口号）</span><br><br>systemctl start thelounge.service<br>systemctl <span class="hljs-built_in">enable</span> thelounge.service<br>thelounge add 用户名#手动添加登陆的用户名<br><span class="hljs-comment">#配置的时候记得在命令里面加上以下三句命令</span><br>/msg NickServ RECOVER 昵称<br>/msg NickServ IDENTIFY 昵称 密码#避免被挤掉<br>/msg Vertigo ENTER 昵称 irc密码<br></code></pre></td></tr></table></figure>
<p>如果提示node版本问题可能需要更新，nvm是个管理node的工具</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash<br>export NVM_DIR=&quot;$HOME/.nvm&quot;<br>[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \. &quot;$NVM_DIR/nvm.sh&quot;  # This loads nvm<br>[ -s &quot;$NVM_DIR/bash_completion&quot; ] &amp;&amp; \. &quot;$NVM_DIR/bash_completion&quot;  # This loads nvm bash_completion<br></code></pre></td></tr></table></figure>
<h1 id="音乐相关"><a href="#音乐相关" class="headerlink" title="音乐相关"></a>音乐相关</h1><h3 id="Flac-to-mp3"><a href="#Flac-to-mp3" class="headerlink" title="Flac to mp3"></a>Flac to mp3</h3><p><a href="http://robinbowes.github.io/flac2mp3/">Flac2Mp3</a>该工具会将你所有flac文件转为mp3，且按相同的名字文件结构保存。</p>
<p><a href="https://github.com/robinbowes/flac2mp3/tarball/master">下载链接download.tar.gz</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">tar zxvf flac2mp3-0.3.0.tar.gz<br>apt install flac<br>apt install lame<br><span class="hljs-meta prompt_">#</span><span class="language-bash">找到解压文件内的flac2mp3.pl文件，善用软连接,默认v2，自己修改为v0或320</span><br><br>ln -s 文件所在路径  f2m<br>./f2m --preset=V0 /path/to/lossless /path/to/lossy<br></code></pre></td></tr></table></figure>

<h3 id="Flac-24bit-16bit"><a href="#Flac-24bit-16bit" class="headerlink" title="Flac 24bit-&gt;16bit"></a>Flac 24bit-&gt;16bit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">sox input.flac -G -b 16 output.flac rate -v -L 48000 dither<br><br>for flac in *.flac; do sox -S &quot;$&#123;flac&#125;&quot; -r 44100 -b 16 new/&quot;$&#123;flac&#125;&quot;; done<br></code></pre></td></tr></table></figure>
<h3 id="一键上传图床脚本"><a href="#一键上传图床脚本" class="headerlink" title="一键上传图床脚本"></a>一键上传图床脚本</h3><p><a href="https://github.com/theirix/ptpimg-uploader">https://github.com/theirix/ptpimg-uploader</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">pip install ptpimg_uploader<br><br>export PTPIMG_API_KEY=&lt;your hex key&gt;<br><br>ptpimg_uploader ~/seed/mytorrent/folder.jpg<br></code></pre></td></tr></table></figure>

<h3 id="频谱图"><a href="#频谱图" class="headerlink" title="频谱图"></a>频谱图</h3><ol>
<li>sox 专辑路径名字&#x2F;*.flac -n spectrogram -o 专辑.png</li>
<li>要是二级目录<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/zsh/bin</span><br>dir=/home/download/<br>filename=$1<br>cd &quot;$filename&quot;<br>ls -d */ | grep -o &#x27;[a-Z]*\ *[0-9]/&#x27; &gt;temp.log<br>sed -i &#x27;s/$/*flac/&#x27; temp.log<br>mapfile acmd &lt;temp.log<br>echo $&#123;acmd[@]&#125;<br>fdir=&#x27;&#x27;<br>if test -z &quot;$acmd&quot;<br>then<br>  echo &quot;No subfolder~&quot;<br>  sox *flac -n spectrogram -o $dir/spectrograms/&quot;$filename&quot;.png<br>else<br>  l=$&#123;#acmd[@]&#125;<br>  case &quot;$l&quot; in<br>          2)<br>             echo &quot;There 2 discs&quot;<br>             a1=`cat temp.log | sed -n &#x27;1p&#x27;`<br>             a2=`cat temp.log | sed -n &#x27;2p&#x27;`<br>             sox &quot;$a1&quot; &quot;$a2&quot; -n spectrogram -o $dir/spectrograms/&quot;$filename&quot;.png<br>            <br>             ;;<br>          *)<br>             echo &quot;There more than 3 discs, only take first 3&quot;<br>             a1=`cat temp.log | sed -n &#x27;1p&#x27;`<br>             a2=`cat temp.log | sed -n &#x27;2p&#x27;`<br>             a3=`cat temp.log | sed -n &#x27;3p&#x27;`<br>             sox &quot;$a1&quot; &quot;$a2&quot; &quot;$a3&quot; -n spectrogram -o $dir/spectrograms/&quot;$filename&quot;.png<br>             ;;<br>  esac<br></code></pre></td></tr></table></figure></li>
<li>单碟版一键制谱并上传图床返回链接</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">vim sp-up.sh<br><span class="hljs-meta prompt_">#</span><span class="language-bash">复制以下内容</span><br>n=$1<br>cd &quot;$n&quot;<br><br>sox *flac -n spectrogram -o ../spectrograms/&quot;$n&quot;.png<br>sp=$(ptpimg_uploader -k your-ptpimg-key --bbcode <br>spec=[hide=spectrogram]$sp[/hide]<br>echo &quot;PTPIMGurl: $spec&quot;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">具体使用</span><br>sh sp-up.sh 专辑目录<br><br></code></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">git clone https://github.com/EwolBash/spsox.git<br>cd spsox<br>chmod +x spsox<br>cp spsox /usr/local/bin/<br>spsox<br>spsox -r /home/ewol/Music/music/&#x27;Chuck Prophet - Bobby Fuller Died For Your Sins (2017) [FLAC]&#x27;/<br>spsox -r /home/ewol/Music/music<br></code></pre></td></tr></table></figure>
<h3 id="web抓流"><a href="#web抓流" class="headerlink" title="web抓流"></a>web抓流</h3><p><a href="https://github.com/nathom/streamrip">https://github.com/nathom/streamrip</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">需要python&gt;3.8</span><br>pip3 install streamrip --upgrade<br><br>rip config --open<br><span class="hljs-meta prompt_">#</span><span class="language-bash">填上arl之类的信息</span><br><br>rip 专辑url<br></code></pre></td></tr></table></figure>
<h3 id="压缩flac专辑到lv8"><a href="#压缩flac专辑到lv8" class="headerlink" title="压缩flac专辑到lv8"></a>压缩flac专辑到lv8</h3><p><a href="https://xiph.org/flac/documentation_tools_flac.html">flac命令行文档</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">flac -8 专辑名字/* -f<br></code></pre></td></tr></table></figure>

<h1 id="抓流制种频谱图集合"><a href="#抓流制种频谱图集合" class="headerlink" title="抓流制种频谱图集合"></a>抓流制种频谱图集合</h1><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/zsh</span><br>l=($*)<br><span class="hljs-meta prompt_">#</span><span class="language-bash">num=<span class="hljs-variable">$1</span></span><br>for num in $&#123;l[*]&#125;;do<br>        echo https://www.xxx.com/album/$num<br>        ripb=`rip url line https://www.deezer.com/album/$num`<br>        echo &quot;$ripb&quot;<br>        fullname=/home/download<br><br>        if [[ $ripb =~ &quot;Unable to stream&quot; ]] || [[ $ripb =~ &quot;already downloaded&quot; ]]<br>        then<br>                echo $num &quot;$ripb&quot;&gt;&gt;$fullname/fail.log#抓流失败或者重复跳过循环<br>                continue<br>        fi<br>        dirname=$(ls -At $fullname | sed -n &quot;1p&quot;)<br>        mktorrent -v -p -l 22 -o $fullname/torrents/&quot;$dirname&quot;.torrent $fullname/&quot;$dirname&quot;<br>        cd $fullname/&quot;$dirname&quot;<br><br>        ls -d */ | grep -o &#x27;[a-Z]*\ *[0-9]/&#x27; &gt;temp.log<br>        sed -i &#x27;s/$/*flac/&#x27; temp.log<br>        mapfile acmd &lt;temp.log<br><br>        fdir=&#x27;&#x27;<br>        if test -z &quot;$acmd&quot;<br>        then<br>        echo &quot;No subfolder~&quot;<br>         sox *flac -n spectrogram -o $fullname/spectrograms/&quot;$dirname&quot;.png<br>        else<br>         l=$&#123;#acmd[@]&#125;<br>         case &quot;$l&quot; in<br>          2)<br>             echo &quot;There 2 discs&quot;<br>             a1=`cat temp.log | sed -n &#x27;1p&#x27;`<br>             a2=`cat temp.log | sed -n &#x27;2p&#x27;`<br>             sox &quot;$a1&quot; &quot;$a2&quot; -n spectrogram -o $fullname/spectrograms/&quot;$dirname&quot;.png<br>             ;;<br>          3)<br>             echo &quot;There 3 discs&quot;<br>             a1=`cat temp.log | sed -n &#x27;1p&#x27;`<br>             a2=`cat temp.log | sed -n &#x27;2p&#x27;`<br>             a3=`cat temp.log | sed -n &#x27;3p&#x27;`<br>             sox &quot;$a1&quot; &quot;$a2&quot; &quot;$a3&quot; -n spectrogram -o $fullname/spectrograms/&quot;$dirname&quot;.png<br>             ;;<br>          4)<br>             echo &quot;There 4 discs&quot;<br>             a1=`cat temp.log | sed -n &#x27;1p&#x27;`<br>             a2=`cat temp.log | sed -n &#x27;2p&#x27;`<br>             a3=`cat temp.log | sed -n &#x27;3p&#x27;`<br>             a4=`cat temp.log | sed -n &#x27;4p&#x27;`<br>             sox &quot;$a1&quot; &quot;$a2&quot; &quot;$a3&quot; &quot;$a4&quot; -n spectrogram -o $fullname/spectrograms/&quot;$dirname&quot;.png<br>             ;;<br>          *)<br>             echo &quot;There more than 5 discs, only take first 6&quot;<br>             a1=`cat temp.log | sed -n &#x27;1p&#x27;`<br>             a2=`cat temp.log | sed -n &#x27;2p&#x27;`<br>             a3=`cat temp.log | sed -n &#x27;3p&#x27;`<br>             a4=`cat temp.log | sed -n &#x27;4p&#x27;`<br>             a5=`cat temp.log | sed -n &#x27;5p&#x27;`<br>             a6=`cat temp.log | sed -n &#x27;6p&#x27;`<br>             sox &quot;$a1&quot; &quot;$a2&quot; &quot;$a3&quot; &quot;$a4&quot; &quot;$a5&quot; &quot;$a6&quot; -n spectrogram -o $fullname/spectrograms/&quot;$dirname&quot;.png<br>             ;;<br>         esac<br>        fi<br>        #sox $fullname/&quot;$dirname&quot;/*flac -n spectrogram -o $fullname/spectrograms/&quot;$dirname&quot;.png<br>        sp=$(ptpimg_uploader --bbcode $fullname/spectrograms/&quot;$dirname&quot;.png)<br>        spec=[hide=spectrogram]$sp[/hide]<br>        echo &quot;$spec $dirname $num&quot; &gt;&gt;&quot;$fullname&quot;/torrents/PtpimgUrl.txt<br>        echo &quot;PTPIMGurl: $spec&quot;<br>        sleep $[($RANDOM % 10)+3]<br></code></pre></td></tr></table></figure>

<h2 id="截图工具convert"><a href="#截图工具convert" class="headerlink" title="截图工具convert"></a>截图工具convert</h2><p>要apt install imagemagick</p>
<h2 id="AutoBrr"><a href="#AutoBrr" class="headerlink" title="AutoBrr"></a>AutoBrr</h2><p><a href="https://autobrr.com/configuration/irc">https://autobrr.com/configuration/irc</a><br>刷外站神器，主要是支持没有rss用irc推送的站，上面的官方文档已经相当详细，我这个是介绍下docker安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">vim docker-compose.yml<br><span class="hljs-meta prompt_">#</span><span class="language-bash">写入以下内容，替换映射地址</span><br>version: &quot;3.7&quot;<br><br>services:<br>  autobrr:<br>    container_name: autobrr<br>    image: ghcr.io/autobrr/autobrr:latest<br>    restart: unless-stopped<br>    #logging:<br>    #  driver: json-file<br>    #  options:<br>    #    max-file: $&#123;DOCKERLOGGING_MAXFILE&#125;<br>    #    max-size: $&#123;DOCKERLOGGING_MAXSIZE&#125;<br>    user: 1000:1000<br>    environment:<br>      - TZ=$&#123;TZ&#125;<br>    volumes:<br>      - $&#123;BASE_DOCKER_DATA_PATH&#125;/autobrr/config:/config<br>    ports:<br>      - 7474:7474<br></code></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker compose up -d<br></code></pre></td></tr></table></figure>
<p>注意盒子上使用要找到config.toml文件，把127.0.0.1改成0.0.0.0</p>
<p>通知可用tg的bot，怎么搞详细教程参考<a href="https://blog.csdn.net/whatday/article/details/113748634?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167496205316800192275150%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167496205316800192275150&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-113748634-null-null.142%5Ev71%5Einsert_chatgpt,201%5Ev4%5Eadd_ask&utm_term=telegram%20bot&spm=1018.2226.3001.4187">这个教程</a>，简单一点就是先去搜索botFather创建一个bot，搞号命名描述获取token，再去getuseridbot查自己id(有概率搜不到)。点击链接测试返回值<a href="https://api.telegram.org/bot%3Ctoken%3E/getUpdates">https://api.telegram.org/bot&lt;换自己token&gt;&#x2F;getUpdates</a><br>填的时候注意token直接复制整个‘数字:字符串’，chat_id是自己的id。</p>
<ul>
<li>注意：<br>添加客户端的时候deluge一个坑，他的名字密码要去&#x2F;docker&#x2F;appdata&#x2F;deluge&#x2F;auth找，username:password:level的形式，地址必须是纯数字ip，不是官方推荐的127.0.0.1或者localhost。qb地址是<a href="http://ip:端口">http://ip:端口</a></li>
</ul>
<h2 id="flexget"><a href="#flexget" class="headerlink" title="flexget"></a>flexget</h2><p>自动rss新种，可自定义规则，星大脚本直接装或者直接：pip install flexget</p>
<p>配置文件config.yml</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">templates:<br><span class="hljs-meta prompt_"># </span><span class="language-bash">剩余空间模板，当 path 对应的路径的剩余空间小于 space 规定的数值的时候停止 RSS 下载</span><br>  freespace:<br>    free_space:<br>      path: /home/gawain/deluge/download/<br>      space: 20240<br><span class="hljs-meta prompt_"># </span><span class="language-bash">qb 的模板，之后写 qb 就是指把种子推送到 qb 进行下载；下面 <span class="hljs-built_in">tr</span> de rt 也是如此</span><br>  qb:<br>    qbittorrent:<br>      path: /home/gawain/deluge/download/<br>      host: localhost<br>      port: 2017<br>      username: **** <br>      password: ****<br>  de:<br>    deluge:<br>      path: /home/gawain/deluge/TSBluray/rar<br>      host: localhost<br>      port: 58846<br>      username: ...<br>      password: ...<br>  size:<br>    content_size:<br>      min: 13000<br>      max: 46666<br>      strict: yes<br><br>tasks:<br>  Ts-Bluray:<br>    rss: https://www.torrentseeds.org/rss/****<br>    if:<br>      - &quot;&#x27;BLURAY&#x27; in title&quot;: accept<br>      #- &quot;&#x27;subs&#x27; in title&quot;: reject<br>    temperate: <br>      - de<br>      - freespace<br>      - size<br>    deluge:<br>      label: TSBluray<br><br>web_server:<br>  port: 6566<br>  web_ui: yes<br><br>schedules: no<br></code></pre></td></tr></table></figure>
<p>然后测试：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">不下载只测试获取情况</span><br>flexget --test <br><span class="hljs-meta prompt_">#</span><span class="language-bash">标记老的种子</span><br>flexget --learn<br><span class="hljs-meta prompt_">#</span><span class="language-bash">确定flexget安装目录</span><br>which flexget<br><span class="hljs-meta prompt_">#</span><span class="language-bash">添加cron</span><br>crontab -e<br><span class="hljs-meta prompt_">#</span><span class="language-bash">添加语句，后面替换上面获取的路径</span><br>*/3 * * * * /usr/local/bin/flexget execute<br></code></pre></td></tr></table></figure>
<h1 id="差速器"><a href="#差速器" class="headerlink" title="差速器"></a>差速器</h1><p><a href="https://leishi.io/blog/posts/2021-12/Differential/">大佬博客</a><br>只要提供给差速器一个需要发布的文件夹和豆瓣信息页面，差速器会自动帮你</p>
<ol>
<li>根据豆瓣链接获取PTGen信息</li>
<li>根据资源载体获取MediaInfo&#x2F;BDInfo信息</li>
<li>截取自定数量的无损截图，上传到指定的图床</li>
<li>制作种子</li>
<li>如果是本地环境，自动打开浏览器，然后自动填充所有的信息<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">Linux一键安装，其他平台和docker参考以上文章</span><br>curl -Lso- https://raw.githubusercontent.com/LeiShi1313/Differential/main/install.sh | bash<br><br>vim config.ini<br><span class="hljs-meta prompt_">#</span><span class="language-bash">写入以下内容</span><br>[DEFAULT]<br>; 是否制种<br>make_torrent = true<br><br>; 生成截图的数量<br>screenshot_count = 6<br>; 图床，差速器支持PTPIMG、自建imgurl、自建Chevereto（z4a、imgbb、猫柠的图床等）、SM.MS和BYR作为图床<br>image_hosting = CHEVERETO<br>; 自建Chevereto的地址<br>chevereto_hosting_url = https://XXX.com<br>; 自建Chevereto的用户名<br>chevereto_username = XXXX<br>; 自建Chevereto的密码<br>chevereto_password = YYYY<br><br>; 自动填充使用的脚本，这里使用树大的脚本<br>easy_upload = true<br>; 也可以使用明日大的脚本来进行自动填充<br>; auto_feed = true<br><br>; 使用差速器自带的短网址服务<br>use_short_url = true<br><br>; 差速器自带一个自建的PTGen，如果无法访问，可以提供自定义PTGen地址<br>;ptgen_url = https://XXXXX.com<br><br>[NexusPHP]<br>; 发种页面的链接<br>upload_url = https://XXXXX.com/upload.php<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">发布格式</span><br>dft ne -f [种子文件夹] -u [豆瓣链接]<br></code></pre></td></tr></table></figure>
需要注意的是需要自己配置config，和视频文件同一文件夹，可能需要科学使用默认ptgen。</li>
</ol>
<h1 id="解压rar"><a href="#解压rar" class="headerlink" title="解压rar"></a>解压rar</h1><p>主要为了解压0day资源，只能手动安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">wget http://www.rarlab.com/rar/rarlinux-x64-5.0.0.tar.gz --no-check-certificate<br>tar xvf rarlinux-x64-5.0.0.tar.gz<br>cd rar<br>make install<br>ln -n unrar /usr/bin/unrar<br><span class="hljs-meta prompt_">#</span><span class="language-bash">使用方法</span><br>unrar e  ***.rar(or folder) target-path<br></code></pre></td></tr></table></figure>
<h1 id="Remux"><a href="#Remux" class="headerlink" title="Remux"></a>Remux</h1><p>Remux必须有eac3to的解码日志，而eac3to又只支持windows，所以需要wine32</p>
<h2 id="Wine"><a href="#Wine" class="headerlink" title="Wine"></a>Wine</h2><p> 可以星大脚本直接手动加参数装<br> Debian10安装Wine32有很多坑，wine是为了eac3to</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt-get install libgnutls30:i386 libldap-2.4-2:i386 libgpg-error0:i386 libxml2:i386 libasound2-plugins:i386 libsdl2-2.0-0:i386 libfreetype6:i386 libdbus-1-3:i386 libsqlite3-0:i386<br></code></pre></td></tr></table></figure>
<h2 id="eac3to"><a href="#eac3to" class="headerlink" title="eac3to"></a>eac3to</h2><p><a href="https://unixsheikh.com/tutorials/remuxing-iso-dvd-or-bluray-using-cat-and-ffmpeg-on-linux.html">https://unixsheikh.com/tutorials/remuxing-iso-dvd-or-bluray-using-cat-and-ffmpeg-on-linux.html</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">eac3to日志：</span><br>wget -O eac3to.zip https://www.videohelp.com/download/eac3to336.zip\?r\=LRXdxQfL<br>unzip eac3to.zip<br>wine eac3to/eac3to.exe `winepath -w /home/gawain/deluge/download/Songs.From.The.Second.Floor.2000.COMPLETE.BLURAY-iFPD/BDMV` &#x27;1)&#x27; 1:chapter.txt 2:h264.mkv 3:DTSMAENG.dtsma -progressnumbers -log=eac3to.txt<br><span class="hljs-meta prompt_">#</span><span class="language-bash">注意，这里有个非常诡异的问题，排查了很久，1）会选者不上，主要是因为路径的问题，要用winepath</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">1）ffmpeg</span><br>ffmpeg -i 00009.m2ts -map 0:0 -vcodec copy -map 0:1 -acodec copy -map 0:7 -scodec copy W.E.2011.1080p.BluRay.Remux.mkv<br><span class="hljs-meta prompt_">#</span><span class="language-bash">2）mkvermerge</span><br>mkvmerge -o W.E.2011.1080p.BluRay.Remux.mkv 00009.m2ts <br></code></pre></td></tr></table></figure>
<p> i is the name of the input file.<br>-map is used to map each track to a specific command option.<br>0:0 is the first track, i.e. the video, which is then mapped to the -vcodec option, i.e. video codec option, which simply copies the video track into the new mkv container.<br>0:1 is the first audio track, i.e. the English audio, which is then mapped to the -acodec option, i.e. audio codec option, which simply copies the English audio track into the new mkv container.<br>0:9 is the first subtitle track, i.e. the English subtitle, which is then mapped to the -scodec option, i.e. subtitle codec option, which simply copies the English subtitle into the new mkv container.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt install mkvtoolnix<br>mkvmerge <br></code></pre></td></tr></table></figure>

<h1 id="小工具集合"><a href="#小工具集合" class="headerlink" title="小工具集合"></a>小工具集合</h1><h3 id="mosh连接"><a href="#mosh连接" class="headerlink" title="mosh连接"></a>mosh连接</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">brew install mosh#mac 客户端<br><br>sudo apt-get install mosh<br>mosh-server new -c 256 -s -l LANG=en_US.UTF-8 -p 60000<br><br>mosh pi@pi42.local -p 6000<br></code></pre></td></tr></table></figure>


<h3 id="远程同步文件"><a href="#远程同步文件" class="headerlink" title="远程同步文件"></a>远程同步文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">rsync -avz --progress /root/client/   root@202.112.23.12:/home/work/      <br><span class="hljs-meta prompt_">#</span><span class="language-bash">将本机的/root/client/拷贝至远程的202.112.23.12:/home/work/目录，--progress可以查看拷贝的过程</span><br></code></pre></td></tr></table></figure>

<h4 id="docker查看映射目录"><a href="#docker查看映射目录" class="headerlink" title="docker查看映射目录"></a>docker查看映射目录</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker inspect 容器名称 | grep Mounts -A 20<br><br></code></pre></td></tr></table></figure>

<h2 id="批量获取前端种子下载链接"><a href="#批量获取前端种子下载链接" class="headerlink" title="批量获取前端种子下载链接"></a>批量获取前端种子下载链接</h2><p>主要是针对ptpp不支持的站点</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><code class="hljs javascript"><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">clear</span>()<br><br><span class="hljs-keyword">var</span> trs = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">querySelectorAll</span>(<span class="hljs-string">&quot;form[action]&quot;</span>)<br><span class="hljs-keyword">var</span> pk =<span class="hljs-string">&quot;passkey&quot;</span><br><span class="hljs-keyword">var</span> dl =<span class="hljs-string">&#x27;&#x27;</span><br>href=<span class="hljs-string">&#x27;&#x27;</span><br>ct=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">var</span> tr <span class="hljs-keyword">of</span> trs)&#123;<br>    a=tr.<span class="hljs-property">action</span><br>    <span class="hljs-keyword">if</span> (a.<span class="hljs-title function_">match</span>(<span class="hljs-regexp">/zip/</span>))<br>    &#123;<br>       <span class="hljs-keyword">continue</span><br>    &#125;<br>    tid=a.<span class="hljs-title function_">match</span>(<span class="hljs-regexp">/id=(\d+)&amp;*sign=(\d+)/</span>)<br>    <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(tr)<br>    <span class="hljs-keyword">if</span>(tid)<br>       href=<span class="hljs-string">&quot;https://***./download.php?id=&quot;</span>+tid[<span class="hljs-number">1</span>]+<span class="hljs-string">&quot;&amp;passkey=&quot;</span>+pk+<span class="hljs-string">&quot;&amp;https=1&quot;</span><br>       dl=dl+href+<span class="hljs-string">&quot;\r\n&quot;</span><br>       ct=ct+<span class="hljs-number">1</span><br>&#125;<br><span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(dl,ct)<br><span class="hljs-title function_">copy</span>(dl)<br><br></code></pre></td></tr></table></figure>

<h3 id="新服务器探针ServerStatus"><a href="#新服务器探针ServerStatus" class="headerlink" title="新服务器探针ServerStatus"></a>新服务器探针ServerStatus</h3><p><a href="https://github.com/zdz/ServerStatus-Rust">https://github.com/zdz/ServerStatus-Rust</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">自动安装配置脚本</span><br>wget --no-check-certificate -qO status.sh &#x27;https://raw.githubusercontent.com/zdz/ServerStatus-Rust/master/scripts/status.sh&#x27;<br><span class="hljs-meta prompt_">#</span><span class="language-bash">客户端</span><br>./status.sh -i -c http://name:password@ip:8080<br><span class="hljs-meta prompt_">#</span><span class="language-bash">服务器</span><br>./status.sh -i -s <br></code></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>GAT教程</title>
    <url>/2023/11/01/GAT&#39;s%20Toturial/</url>
    <content><![CDATA[<h1 id="GAT教程"><a href="#GAT教程" class="headerlink" title="GAT教程"></a>GAT教程</h1><h3 id="本文来自对作者gordicaleksa的notebook代码pytorch-GAT的翻译。感谢作者"><a href="#本文来自对作者gordicaleksa的notebook代码pytorch-GAT的翻译。感谢作者" class="headerlink" title="本文来自对作者gordicaleksa的notebook代码pytorch-GAT的翻译。感谢作者"></a><strong>本文来自对作者gordicaleksa的notebook代码<a href="https://github.com/gordicaleksa/pytorch-GAT">pytorch-GAT</a>的翻译。感谢作者</strong></h3><p>本文的想法是让非研究人员也能更轻松地理解图注意力网络（以及通用的GNN）！</p>
<p>在本文中，您将获得以下问题的答案：</p>
<p>✅ GAT 到底是什么？<br/><br>✅ 如何加载和可视化Cora引文网络？<br/><br>✅ 我们如何训练GAT（Cora分类示例）？<br/><br>✅ 如何可视化不同GAT的属性？<br/></p>
<p>完成本课程后，您将对图神经网络有更好的理解！</p>
<p><em>注意：在本笔记本中，我们将重点关注 Cora（传导法示例），如果需要可以查看其他笔记本中的PPI - 蛋白质相互作用数据集（归纳法）。</em></p>
<p>很好，让我们开始吧！</p>
<hr>
<h2 id="图注意力网络到底是什么？"><a href="#图注意力网络到底是什么？" class="headerlink" title="图注意力网络到底是什么？"></a>图注意力网络到底是什么？</h2><p>图注意力网络（Graph Attention Network），简称 GAT，是一种图神经网络（GNN），早在 2017 年就在一篇名为<a href="https://arxiv.org/abs/1710.10903">《Graph Attention Networks》</a>Veličković et al.的论文中发表。</p>
<p>事实证明，将注意力的想法与现有的图卷积网络（GCN）相结合是一个很好的举措，GAT是GNN文献中被引用次数第二多的论文（截至撰写本文时）。</p>
<p>因为<code>GCN + attention = GAT</code>为了理解GAT，你基本上需要理解GCN。</p>
<p>整个想法来自 CNN。卷积神经网络发展非常好，解决了各种计算机视觉任务，并在深度学习领域引起了巨大的轰动，因此一些人决定将这个想法转移到图上。</p>
<p>基本问题是，虽然图像位于规则网格上（您也可以将其视为图形），但因此具有精确的顺序概念（例如我的左上角邻居（通常称为CV世界里的像素）))，图不具备这种良好的特性，并且邻居的数量以及邻居的顺序都可能会有所不同。</p>
<p>那么如何为图定义内核呢？内核大小不能是这样3x3，因为有时一个节点有2个邻居，有时是 233240（<em>抓狂</em>）。</p>
<p>出现了 2 个主要想法：</p>
<ul>
<li>谱方法（它们都以某种方式利用图拉普拉斯特征基（我在这里完全忽略它们））</li>
<li>空间方法</li>
</ul>
<p>尽管空间方法可能隐约受到谱方法的启发，但直接从空间角度思考它们要好得多。好的，就这样吧。</p>
<hr>
<p><strong>空间（消息传递）方法的高级解释：</strong></p>
<p>所以你可以使用来自邻居的特征向量。您执行以下操作：</p>
<ol>
<li>你以某种方式变换它们（也许是线性投影）</li>
<li>你以某种方式聚合它们（也许用注意力系数来衡量它们，瞧，我们得到了 GAT（你看我在那里做了什么））</li>
<li>您可以通过将当前节点（变换后的）特征向量与聚合邻居表示相结合来更新当前节点的特征向量（以某种方式）。<br>差不多就是这样，你可以将许多不同的 GNN 放入这个框架中。</li>
</ol>
<p>GAT 示意图如下（不同颜色的边代表不同的注意力头）：<br><img src="https://i-blog.csdnimg.cn/blog_migrate/45d6723d19b7b712df7a148478dd9256.png" alt="transformer architecture" align="center" style="width: 500px;"/> <br/></p>
<p><strong>有趣的事实:</strong> <em>transformers</em> 可以被认为是GAT的一个特例—当输入图是<strong>全连接</strong>时。查看<a href="https://thegradient.pub/transformers-are-graph-neural-networks/">此博客</a>了解更多详细信息。</p>
<hr>
<p>这就是您现在需要了解的一切！</p>
<p>如果您需要进一步帮助理解所有细节，我们创建了 <a href="https://www.youtube.com/watch?v=uFLeKkXWq2c">in-depth overview of the GAT paper:</a>这篇GAT 论文的深入概述：</p>
<p>重要提示：此笔记本中的代码是这个repo中可以使用的代码的子集。我将在这里重点关注单个GAT实现（概念上最难理解的实现，但同时也是最有效的实现）。请注意，我实际上在repo中有3个GAT实现。</p>
<p>抛开这些，让我们开始深入研究吧！让我们从与数据加载和可视化相关的导入开始。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># I always like to structure my imports into Python&#x27;s native libs,</span><br><span class="hljs-comment"># stuff I installed via conda/pip and local file imports (but we don&#x27;t have those here)</span><br><br><span class="hljs-keyword">import</span> pickle<br><br><span class="hljs-comment"># 可视化相关导入</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">import</span> igraph <span class="hljs-keyword">as</span> ig<br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br><span class="hljs-comment"># 主要的计算依赖</span><br><span class="hljs-keyword">import</span> scipy.sparse <span class="hljs-keyword">as</span> sp<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 深度学习相关</span><br><span class="hljs-keyword">import</span> torch<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> enum<br><br><span class="hljs-comment"># 支持的数据集 - 仅在此笔记本中使用 Cora</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DatasetType</span>(enum.Enum):<br>    CORA = <span class="hljs-number">0</span><br><br>    <br><span class="hljs-comment"># Networkx 并不是专为绘图而制作的，但我进行了一些实验</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GraphVisualizationTool</span>(enum.Enum):<br>    NETWORKX = <span class="hljs-number">0</span>,<br>    IGRAPH = <span class="hljs-number">1</span><br><br><br><span class="hljs-comment"># 我们将从此目录中导出和读取数据</span><br>DATA_DIR_PATH = os.path.join(os.getcwd(), <span class="hljs-string">&#x27;data&#x27;</span>)<br>CORA_PATH = os.path.join(DATA_DIR_PATH, <span class="hljs-string">&#x27;cora&#x27;</span>)  <span class="hljs-comment"># 这是已经检入的，无需创建目录</span><br><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Cora 特定常量</span><br><span class="hljs-comment">#</span><br><br><span class="hljs-comment"># Thomas Kipf 等人在 GCN 论文中首次使用了此拆分，后来 Petar Veličković 等人在 GAT 论文中也使用了它</span><br>CORA_TRAIN_RANGE = [<span class="hljs-number">0</span>, <span class="hljs-number">140</span>]  <span class="hljs-comment"># 我们将前 140 个节点用作训练节点</span><br>CORA_VAL_RANGE = [<span class="hljs-number">140</span>, <span class="hljs-number">140</span>+<span class="hljs-number">500</span>]<br>CORA_TEST_RANGE = [<span class="hljs-number">1708</span>, <span class="hljs-number">1708</span>+<span class="hljs-number">1000</span>]<br>CORA_NUM_INPUT_FEATURES = <span class="hljs-number">1433</span><br>CORA_NUM_CLASSES = <span class="hljs-number">7</span><br><br><span class="hljs-comment"># 无论何时我们需要可视化来自不同类别的点时（t-SNE、CORA 可视化）</span><br>cora_label_to_color_map = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&quot;red&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;blue&quot;</span>, <span class="hljs-number">2</span>: <span class="hljs-string">&quot;green&quot;</span>, <span class="hljs-number">3</span>: <span class="hljs-string">&quot;orange&quot;</span>, <span class="hljs-number">4</span>: <span class="hljs-string">&quot;yellow&quot;</span>, <span class="hljs-number">5</span>: <span class="hljs-string">&quot;pink&quot;</span>, <span class="hljs-number">6</span>: <span class="hljs-string">&quot;gray&quot;</span>&#125;<br><br></code></pre></td></tr></table></figure>

<p>这样我们就解锁了1级（数据📜）。我们继续！</p>
<h1 id="第-1-部分：了解您的数据（与数据合而为一📜❤️）"><a href="#第-1-部分：了解您的数据（与数据合而为一📜❤️）" class="headerlink" title="第 1 部分：了解您的数据（与数据合而为一📜❤️）"></a>第 1 部分：了解您的数据（与数据合而为一📜❤️）</h1><p>我将使用 Cora 引文网络作为本笔记本中的运行示例。</p>
<p>说到这里，你可能会想，传导学习和归纳学习有什么区别？如果您不熟悉 GNN，这可能看起来是一个奇怪的概念。但实际上很简单。</p>
<p><strong>传导法</strong> - 你有一个图（如 Cora），你将一些节点（而不是图）分成训练&#x2F;验证&#x2F;测试训练集。在训练时，您将仅使用训练节点中的标签。但。在前向传播期间，根据空间 GNN 工作方式的本质，您将聚合来自邻居的特征向量，其中一些可能属于验证甚至测试集！要点是 - 您没有使用它们的标签信息，而是使用了结构信息及其特征。</p>
<p><strong>归纳法</strong> - 如果您有计算机视觉或 NLP基础，您可能会更熟悉这一概念。您有一组训练图、一组单独的验证图，当然还有一组单独的测试图。例如，在图分类任务中，训练数据可以包含带标签的图，测试数据可以包含不带标签的图。模型只能利用训练数据中的图来学习图分类模型。</p>
<p>解释这些完后，让我们进入代码并加载和可视化 Cora。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先，让我们定义这些简单的功能用于加载/保存pickle文件 - 为了Cora我们需要它们</span><br><br><span class="hljs-comment"># 所有Cora数据都存储为pickle文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pickle_read</span>(<span class="hljs-params">path</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>        data = pickle.load(file)<br><br>    <span class="hljs-keyword">return</span> data<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pickle_save</span>(<span class="hljs-params">path, data</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>        pickle.dump(data, file, protocol=pickle.HIGHEST_PROTOCOL)<br></code></pre></td></tr></table></figure>

<p>现在让我们看看如何加载 Cora！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 我们稍后会传入训练配置字典</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_graph_data</span>(<span class="hljs-params">training_config, device</span>):<br>    dataset_name = training_config[<span class="hljs-string">&#x27;dataset_name&#x27;</span>].lower()<br>    should_visualize = training_config[<span class="hljs-string">&#x27;should_visualize&#x27;</span>]<br><br>    <span class="hljs-keyword">if</span> dataset_name == DatasetType.CORA.name.lower():<br><br>        <span class="hljs-comment"># 形状 = (N, FIN)，其中 N 是节点数，FIN 是输入特征数</span><br>        node_features_csr = pickle_read(os.path.join(CORA_PATH, <span class="hljs-string">&#x27;node_features.csr&#x27;</span>))<br>        <span class="hljs-comment"># 形状 = (N, 1)</span><br>        node_labels_npy = pickle_read(os.path.join(CORA_PATH, <span class="hljs-string">&#x27;node_labels.npy&#x27;</span>))<br>        <span class="hljs-comment"># 形状 = (N, 相邻节点数) &lt;- 这是一个字典，不是矩阵！</span><br>        adjacency_list_dict = pickle_read(os.path.join(CORA_PATH, <span class="hljs-string">&#x27;adjacency_list.dict&#x27;</span>))<br><br>        <span class="hljs-comment"># 标准化特征（有助于训练）</span><br>        node_features_csr = normalize_features_sparse(node_features_csr)<br>        num_of_nodes = <span class="hljs-built_in">len</span>(node_labels_npy)<br><br>        <span class="hljs-comment"># 形状 = (2, E)，其中 E 是边数，2 是源节点和目标节点。基本上边缘索引</span><br>        <span class="hljs-comment"># 包含格式为 S-&gt;T 的元组，例如 0-&gt;3 表示具有 ID 0 的节点指向具有 ID 3 的节点。</span><br>        topology = build_edge_index(adjacency_list_dict, num_of_nodes, add_self_edges=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment"># 注意：topology 只是命名图结构数据的花哨方式</span><br>        <span class="hljs-comment"># （除边缘索引之外，它可以是邻接矩阵的形式）</span><br><br>        <span class="hljs-keyword">if</span> should_visualize:  <span class="hljs-comment"># 网络分析和图绘制</span><br>            plot_in_out_degree_distributions(topology, num_of_nodes, dataset_name)  <span class="hljs-comment"># 我们将在第二部分定义这些</span><br>            visualize_graph(topology, node_labels_npy, dataset_name)<br><br>        <span class="hljs-comment"># 转换为稠密 PyTorch 张量</span><br><br>        <span class="hljs-comment"># 需要是 long int 类型，因为以后像 PyTorch 的 index_select 这样的函数期望它</span><br>        topology = torch.tensor(topology, dtype=torch.long, device=device)<br>        node_labels = torch.tensor(node_labels_npy, dtype=torch.long, device=device)  <span class="hljs-comment"># 交叉熵期望一个 long int</span><br>        node_features = torch.tensor(node_features_csr.todense(), device=device)<br><br>        <span class="hljs-comment"># 帮助我们提取属于训练/验证和测试拆分的节点的索引</span><br>        train_indices = torch.arange(CORA_TRAIN_RANGE[<span class="hljs-number">0</span>], CORA_TRAIN_RANGE[<span class="hljs-number">1</span>], dtype=torch.long, device=device)<br>        val_indices = torch.arange(CORA_VAL_RANGE[<span class="hljs-number">0</span>], CORA_VAL_RANGE[<span class="hljs-number">1</span>], dtype=torch.long, device=device)<br>        test_indices = torch.arange(CORA_TEST_RANGE[<span class="hljs-number">0</span>], CORA_TEST_RANGE[<span class="hljs-number">1</span>], dtype=torch.long, device=device)<br><br>        <span class="hljs-keyword">return</span> node_features, node_labels, topology, train_indices, val_indices, test_indices<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;dataset_name&#125;</span> not yet supported.&#x27;</span>)<br><br></code></pre></td></tr></table></figure>

<p>很好，我还使用了另外 2 个尚未定义的函数。首先让我们看看如何在 Cora 上进行特征标准化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_features_sparse</span>(<span class="hljs-params">node_features_sparse</span>):<br>    <span class="hljs-keyword">assert</span> sp.issparse(node_features_sparse), <span class="hljs-string">f&#x27;Expected a sparse matrix, got <span class="hljs-subst">&#123;node_features_sparse&#125;</span>.&#x27;</span><br><br>    <span class="hljs-comment"># 而不是像 normalize_features_dense() 中那样进行除法，我们对特征的逆和进行乘法。</span><br>    <span class="hljs-comment"># 现代硬件（GPU、TPU、ASIC）针对快速矩阵乘法进行了优化！ ^^ (* &gt;&gt; /)</span><br>    <span class="hljs-comment"># 形状 = (N, FIN) -&gt; (N, 1)，其中 N 表示节点数，FIN 表示输入特征数</span><br>    node_features_sum = np.array(node_features_sparse.<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>))  <span class="hljs-comment"># 对每个节点特征向量求和特征</span><br><br>    <span class="hljs-comment"># 创建一个逆矩阵（记住 * by 1/x 优于（更快）/ by x）</span><br>    <span class="hljs-comment"># 形状 = (N, 1) -&gt; (N)</span><br>    node_features_inv_sum = np.power(node_features_sum, -<span class="hljs-number">1</span>).squeeze()<br><br>    <span class="hljs-comment"># 再次某些和将为 0，因此 1/0 将为我们提供 inf，因此我们将它们替换为 1，它是 mul 的中性元素</span><br>    node_features_inv_sum[np.isinf(node_features_inv_sum)] = <span class="hljs-number">1.</span><br><br>    <span class="hljs-comment"># 创建一个对角矩阵，其对角线上的值来自 node_features_inv_sum</span><br>    diagonal_inv_features_sum_matrix = sp.diags(node_features_inv_sum)<br><br>    <span class="hljs-comment"># 我们返回归一化的特征。</span><br>    <span class="hljs-keyword">return</span> diagonal_inv_features_sum_matrix.dot(node_features_sparse)<br><br></code></pre></td></tr></table></figure>

<p>它基本上使Cora 的二元节点特征向量总和为1。例如，如果我们有[1, 0, 1, 0, 1]（Cora的特征向量更长，我们很快就会看到，但我们暂时采用​​这个），它将被转换为[0.33, 0, 0.33, 0, 0.33]. 就那么简单。理解实际的实现总是比较困难，但从概念上讲，这是小菜一碟。</p>
<p>让我们建立边索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_edge_index</span>(<span class="hljs-params">adjacency_list_dict, num_of_nodes, add_self_edges=<span class="hljs-literal">True</span></span>):<br>    source_nodes_ids, target_nodes_ids = [], []<br>    seen_edges = <span class="hljs-built_in">set</span>()<br><br>    <span class="hljs-keyword">for</span> src_node, neighboring_nodes <span class="hljs-keyword">in</span> adjacency_list_dict.items():<br>        <span class="hljs-keyword">for</span> trg_node <span class="hljs-keyword">in</span> neighboring_nodes:<br>            <span class="hljs-comment"># if this edge hasn&#x27;t been seen so far we add it to the edge index (coalescing - removing duplicates)</span><br>            <span class="hljs-keyword">if</span> (src_node, trg_node) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> seen_edges:  <span class="hljs-comment"># it&#x27;d be easy to explicitly remove self-edges (Cora has none..)</span><br>                source_nodes_ids.append(src_node)<br>                target_nodes_ids.append(trg_node)<br><br>                seen_edges.add((src_node, trg_node))<br><br>    <span class="hljs-keyword">if</span> add_self_edges:<br>        source_nodes_ids.extend(np.arange(num_of_nodes))<br>        target_nodes_ids.extend(np.arange(num_of_nodes))<br><br>    <span class="hljs-comment"># shape = (2, E), where E is the number of edges in the graph</span><br>    edge_index = np.row_stack((source_nodes_ids, target_nodes_ids))<br><br>    <span class="hljs-keyword">return</span> edge_index<br></code></pre></td></tr></table></figure>

<p>这个应该相当简单 - 我们只是以这种格式累积边：<br>[[0, 1], [2, 2], …] 其中 [s, t] 元组基本上定义了节点s（源）指向的边到节点t（目标）。</p>
<p>其他流行的格式（在源码另外个实现中使用）是邻接矩阵- 但它们占用更多的内存（准确地说，O(N^2)，与边缘索引结构的 O(E) 进行比较）。</p>
<p>很好，最后让我们尝试加载它。我们还应该分析形状——这总是一个好主意。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Let&#x27;s just define dummy visualization functions for now - just to stop Python interpreter from complaining!</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_in_out_degree_distributions</span>():<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">visualize_graph</span>():<br>    <span class="hljs-keyword">pass</span><br><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <span class="hljs-comment"># checking whether you have a GPU</span><br><br>config = &#123;<br>    <span class="hljs-string">&#x27;dataset_name&#x27;</span>: DatasetType.CORA.name,<br>    <span class="hljs-string">&#x27;should_visualize&#x27;</span>: <span class="hljs-literal">False</span><br>&#125;<br><br>node_features, node_labels, edge_index, train_indices, val_indices, test_indices = load_graph_data(config, device)<br><br><span class="hljs-built_in">print</span>(node_features.shape, node_features.dtype)<br><span class="hljs-built_in">print</span>(node_labels.shape, node_labels.dtype)<br><span class="hljs-built_in">print</span>(edge_index.shape, edge_index.dtype)<br><span class="hljs-built_in">print</span>(train_indices.shape, train_indices.dtype)<br><span class="hljs-built_in">print</span>(val_indices.shape, val_indices.dtype)<br><span class="hljs-built_in">print</span>(test_indices.shape, test_indices.dtype)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">torch.Size([2708, 1433]) torch.float32
torch.Size([2708]) torch.int64
torch.Size([2, 13264]) torch.int64
torch.Size([140]) torch.int64
torch.Size([500]) torch.int64
torch.Size([1000]) torch.int64


/var/folders/f0/812mfv7x63vbytjs3yf4gxtc0000gn/T/ipykernel_16269/2448994618.py:6: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.
  data = pickle.load(file)
</code></pre>
<p>好的！分析形状我们可以看到以下内容：</p>
<ol>
<li>Cora有2708个节点</li>
<li>每个节点有 1433 个特征（查看data_loading.py了解更多详细信息）</li>
<li>我们有 13264 条边！（包括自身边）</li>
<li>我们有140个训练节点</li>
<li>我们有 500 个验证节点</li>
<li>我们有1000个测试节点<br>此外，几乎所有数据都是 int 64 类型。为什么？这是 PyTorch 强加给我们的一个限制。损失函数nn.CrossEntropyLoss和index_select函数需要 torch.long （即 64 位整数）-所以这样。</li>
</ol>
<ul>
<li><code>node_labels</code>是 int64 因为<code>nn.CrossEntropyLoss</code></li>
<li>其他变量是 int64 因为<code>index_select</code><br>在“旁注”中，随着您的进展测试您的代码总是一个好主意。</li>
</ul>
<p>数据加载与此笔记本的其余部分完全正交，因此我们可以独立测试它，并确保形状和数据类型有意义。我在开发像这样的项目（以及一般情况下）时使用这一策略。</p>
<p>我从数据开始，添加加载功能，添加一些可视化，然后我通常才开始开发深度学习模型本身。</p>
<p>可视化是一个巨大的好处，所以让我们开发它们。</p>
<h1 id="可视化数据🔮👓"><a href="#可视化数据🔮👓" class="headerlink" title="可视化数据🔮👓"></a>可视化数据🔮👓</h1><p>让我们首先了解 Cora 中节点的度分布 - 即节点有多少条输入&#x2F;输出边，这是图连通性的某种度量。</p>
<p>运行以下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_in_out_degree_distributions</span>(<span class="hljs-params">edge_index, num_of_nodes, dataset_name</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        注意：使用 igraph/networkx 等工具可以轻松进行各种强大的网络分析。</span><br><span class="hljs-string">        我选择在此处显式计算仅节点度量统计，但如果需要，您可以深入研究并计算图直径、三角形数量以及许多其他网络分析领域的概念。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(edge_index, torch.Tensor):<br>        edge_index = edge_index.cpu().numpy()<br>        <br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(edge_index, np.ndarray), <span class="hljs-string">f&#x27;Expected NumPy array got <span class="hljs-subst">&#123;<span class="hljs-built_in">type</span>(edge_index)&#125;</span>.&#x27;</span><br><br>    <span class="hljs-comment"># 存储每个节点的输入和输出度（对于无向图如 Cora，它们是相同的）</span><br>    in_degrees = np.zeros(num_of_nodes, dtype=<span class="hljs-built_in">int</span>)<br>    out_degrees = np.zeros(num_of_nodes, dtype=<span class="hljs-built_in">int</span>)<br><br>    <span class="hljs-comment"># 边索引形状 = (2, E)，第一行包含源节点，第二行包含目标/汇节点</span><br>    <span class="hljs-comment"># 术语说明：源节点指向目标/汇节点</span><br>    num_of_edges = edge_index.shape[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">for</span> cnt <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_of_edges):<br>        source_node_id = edge_index[<span class="hljs-number">0</span>, cnt]<br>        target_node_id = edge_index[<span class="hljs-number">1</span>, cnt]<br><br>        out_degrees[source_node_id] += <span class="hljs-number">1</span>  <span class="hljs-comment"># 源节点指向其他节点 -&gt; 增加其出度</span><br>        in_degrees[target_node_id] += <span class="hljs-number">1</span>  <span class="hljs-comment"># 类似地</span><br><br>    hist = np.zeros(np.<span class="hljs-built_in">max</span>(out_degrees) + <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> out_degree <span class="hljs-keyword">in</span> out_degrees:<br>        hist[out_degree] += <span class="hljs-number">1</span><br><br>    fig = plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">8</span>), dpi=<span class="hljs-number">100</span>)  <span class="hljs-comment"># 否则在 Jupyter Notebook 中图表会很小</span><br>    fig.subplots_adjust(hspace=<span class="hljs-number">0.6</span>)<br><br>    plt.subplot(<span class="hljs-number">311</span>)<br>    plt.plot(in_degrees, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;node id&#x27;</span>); plt.ylabel(<span class="hljs-string">&#x27;in-degree count&#x27;</span>); plt.title(<span class="hljs-string">&#x27;不同节点 id 的输入度&#x27;</span>)<br><br>    plt.subplot(<span class="hljs-number">312</span>)<br>    plt.plot(out_degrees, color=<span class="hljs-string">&#x27;green&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;node id&#x27;</span>); plt.ylabel(<span class="hljs-string">&#x27;out-degree count&#x27;</span>); plt.title(<span class="hljs-string">&#x27;不同节点 id 的输出度&#x27;</span>)<br><br>    plt.subplot(<span class="hljs-number">313</span>)<br>    plt.plot(hist, color=<span class="hljs-string">&#x27;blue&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;node degree&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;给定出度的节点数量&#x27;</span>) <br>    plt.title(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;dataset_name&#125;</span> 数据集的节点出度分布&#x27;</span>)<br>    plt.xticks(np.arange(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(hist), <span class="hljs-number">5.0</span>))<br><br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.show()<br><br></code></pre></td></tr></table></figure>

<p>太棒了，现在让我们可视化 Cora 的度分布！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">num_of_nodes = <span class="hljs-built_in">len</span>(node_labels)<br>plot_in_out_degree_distributions(edge_index, num_of_nodes, config[<span class="hljs-string">&#x27;dataset_name&#x27;</span>])<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/92t60u.png" alt="请添加图片描述"></p>
<p>您可以立即注意到以下几件事：</p>
<ul>
<li>前2个图是相同的，因为我们将 Cora 视为无向图（即使它自然应该建模为有向图）</li>
<li>某些节点具有大量边（中间的峰值），但大多数节点的边要少得多</li>
<li>第三张图以直方图的形式很好地可视化了这一点 - 大多数节点只有2-5条边（因此峰值位于最左侧）<br>好吧，我们开始对 Cora 有了一些有价值的见解，让我们继续进一步，从字面上想象&#x2F;看到 Cora。</li>
</ul>
<p>下面的单元格将绘制 Cora，运行它。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">请参阅此博客以了解可用的图形可视化工具：</span><br><span class="hljs-string">  https://towardsdatascience.com/large-graph-visualization-tools-and-approaches-2b8758a1cd59</span><br><span class="hljs-string"></span><br><span class="hljs-string">基本上，取决于您的图形大小，可能会有一些比 igraph 更好的绘图工具。</span><br><span class="hljs-string"></span><br><span class="hljs-string">注意：不幸的是，我不得不将此函数扁平化，因为 igraph 在 Jupyter Notebook 中遇到了一些问题，</span><br><span class="hljs-string">我们只会在这里调用它，所以没关系！</span><br><span class="hljs-string"></span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>dataset_name = config[<span class="hljs-string">&#x27;dataset_name&#x27;</span>]<br>visualization_tool=GraphVisualizationTool.IGRAPH<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(edge_index, torch.Tensor):<br>    edge_index_np = edge_index.cpu().numpy()<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(node_labels, torch.Tensor):<br>    node_labels_np = node_labels.cpu().numpy()<br><br>num_of_nodes = <span class="hljs-built_in">len</span>(node_labels_np)<br>edge_index_tuples = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(edge_index_np[<span class="hljs-number">0</span>, :], edge_index_np[<span class="hljs-number">1</span>, :]))  <span class="hljs-comment"># igraph 要求这种格式</span><br><br><span class="hljs-comment"># 构建 igraph 图</span><br>ig_graph = ig.Graph()<br>ig_graph.add_vertices(num_of_nodes)<br>ig_graph.add_edges(edge_index_tuples)<br><br><span class="hljs-comment"># 准备可视化设置字典</span><br>visual_style = &#123;<br>    <span class="hljs-string">&quot;bbox&quot;</span>: (<span class="hljs-number">700</span>, <span class="hljs-number">700</span>),<br>    <span class="hljs-string">&quot;margin&quot;</span>: <span class="hljs-number">5</span>,<br>&#125;<br><br><span class="hljs-comment"># 我选择边的厚度与通过我们图中某个边的最短路径（测地线）的数量成比例（edge_betweenness 函数，一个简单的 ad hoc 启发式）</span><br><br><span class="hljs-comment"># line1：我使用日志，否则一些边会太厚，而其他边根本不明显</span><br><span class="hljs-comment"># edge_betweenness 返回 &lt; 1 对于某些边，这就是为什么我使用 clip 作为 log 对于那些边来说是负的</span><br><span class="hljs-comment"># line2：归一化，使最厚的边为 1，否则边在图表上看起来太厚</span><br><span class="hljs-comment"># line3：这里的想法是让最强的边缘保持比其他边缘更强，6 刚刚好，不要纠结于此</span><br><br>edge_weights_raw = np.clip(np.log(np.asarray(ig_graph.edge_betweenness())+<span class="hljs-number">1e-16</span>), a_min=<span class="hljs-number">0</span>, a_max=<span class="hljs-literal">None</span>)<br>edge_weights_raw_normalized = edge_weights_raw / np.<span class="hljs-built_in">max</span>(edge_weights_raw)<br>edge_weights = [w**<span class="hljs-number">6</span> <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> edge_weights_raw_normalized]<br>visual_style[<span class="hljs-string">&quot;edge_width&quot;</span>] = edge_weights<br><br><span class="hljs-comment"># 顶点大小的简单启发式。大小 ~ (度/4)（我尝试了 log 和 sqrt 也取得了很好的效果）</span><br>visual_style[<span class="hljs-string">&quot;vertex_size&quot;</span>] = [deg / <span class="hljs-number">4</span> <span class="hljs-keyword">for</span> deg <span class="hljs-keyword">in</span> ig_graph.degree()]<br><br><span class="hljs-comment"># Cora 特有的部分，因为 Cora 有 7 个标签</span><br><span class="hljs-keyword">if</span> dataset_name.lower() == DatasetType.CORA.name.lower():<br>    visual_style[<span class="hljs-string">&quot;vertex_color&quot;</span>] = [cora_label_to_color_map[label] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> node_labels_np]<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;请随意为您的特定数据集添加自定义配色方案。使用 igraph 默认配色。&#x27;</span>)<br><br><span class="hljs-comment"># 设置布局 - 图表在 2D 图表上呈现的方式。图形绘制本身是一个子领域！</span><br><span class="hljs-comment"># 我使用“Kamada Kawai”力导向方法，这组方法基于物理系统模拟。</span><br><span class="hljs-comment"># （layout_drl 也为 Cora 提供了不错的结果）</span><br>visual_style[<span class="hljs-string">&quot;layout&quot;</span>] = ig_graph.layout_kamada_kawai()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;正在绘制结果...（可能需要几秒钟）。&#x27;</span>)<br>ig.plot(ig_graph, **visual_style)<br><br><span class="hljs-comment"># 这个网站有一些很棒的可视化效果，请查看：</span><br><span class="hljs-comment"># http://networkrepository.com/graphvis.php?d=./data/gsm50/labeled/cora.edges</span><br><br></code></pre></td></tr></table></figure>

<pre><code class="hljs">正在绘制结果...（可能需要几秒钟）。
</code></pre>
<p><img src="https://ptpimg.me/s94oh0.png" alt="请添加图片描述"></p>
<p>尝试使用visual_style[“bbox”]设置到(3000, 3000)和在vertex_size用 &#x2F; 2运行，你会得到一个巨巨巨大而惊人的绘图（C处理 igraph 后面的绘图，所以它至少在我的机器上相当快 - 当你滚动它时有一些轻微的滞后）。</p>
<p>好的，我们已经完成了可视化并理解了我们的数据。这是一个巨大的里程碑，所以请拍拍自己的肩膀。🏆🎂🎵</p>
<p>我们已经解锁了 2 级（GAT模型🦄）。😍</p>
<p>现在，让我们了解这个模型！</p>
<h1 id="第-2-部分：了解-GAT-的内部运作方式"><a href="#第-2-部分：了解-GAT-的内部运作方式" class="headerlink" title="第 2 部分：了解 GAT 的内部运作方式"></a>第 2 部分：了解 GAT 的内部运作方式</h1><p>GAT首先，让我们创建一个高级类，我们将在其中从GatLayer对象构建。</p>
<p>它基本上只是将层堆叠到 nn.Sequential 对象中，此外，由于 nn.Sequential 需要单个输入（并且它有一个输出），我只是将数据（特征、边缘索引）打包到一个元组中 - 纯语法糖。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Adam<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GAT</span>(torch.nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    最有趣和最难的实现是实现＃3。</span><br><span class="hljs-string">    Imp1和imp2在细节上有所不同，但基本上是相同的东西。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    因此，我将在本笔记本中专注于imp＃3。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_of_layers, num_heads_per_layer, num_features_per_layer, add_skip_connection=<span class="hljs-literal">True</span>, bias=<span class="hljs-literal">True</span>,</span><br><span class="hljs-params">                 dropout=<span class="hljs-number">0.6</span>, log_attention_weights=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">assert</span> num_of_layers == <span class="hljs-built_in">len</span>(num_heads_per_layer) == <span class="hljs-built_in">len</span>(num_features_per_layer) - <span class="hljs-number">1</span>, <span class="hljs-string">f&#x27;输入有效的架构参数。&#x27;</span><br><br>        num_heads_per_layer = [<span class="hljs-number">1</span>] + num_heads_per_layer  <span class="hljs-comment"># 技巧-这样我可以很好地创建下面的GAT层</span><br><br>        gat_layers = []  <span class="hljs-comment"># 收集GAT层</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_of_layers):<br>            layer = GATLayer(<br>                num_in_features=num_features_per_layer[i] * num_heads_per_layer[i],  <span class="hljs-comment"># 连接的结果</span><br>                num_out_features=num_features_per_layer[i+<span class="hljs-number">1</span>],<br>                num_of_heads=num_heads_per_layer[i+<span class="hljs-number">1</span>],<br>                concat=<span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> i &lt; num_of_layers - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span>,  <span class="hljs-comment"># 最后一个GAT层执行平均值，其他层执行连接</span><br>                activation=nn.ELU() <span class="hljs-keyword">if</span> i &lt; num_of_layers - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,  <span class="hljs-comment"># 最后一层只输出原始分数</span><br>                dropout_prob=dropout,<br>                add_skip_connection=add_skip_connection,<br>                bias=bias,<br>                log_attention_weights=log_attention_weights<br>            )<br>            gat_layers.append(layer)<br><br>        <span class="hljs-variable language_">self</span>.gat_net = nn.Sequential(<br>            *gat_layers,<br>        )<br><br>    <span class="hljs-comment"># 数据只是一个（in_nodes_features，edge_index）元组，我必须这样做是因为nn.Sequential：</span><br>    <span class="hljs-comment"># https://discuss.pytorch.org/t/forward-takes-2-positional-arguments-but-3-were-given-for-nn-sqeuential-with-linear-layers/65698</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, data</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.gat_net(data)<br><br></code></pre></td></tr></table></figure>

<p>现在，有趣的部分让我们定义图层。</p>
<p>我不认为用文字来解释它，比你花时间消化代码和注释更好。</p>
<p>在你开始浪费时间尝试“从头开始”弄清楚之前，可以先观看作者在 GAT 上的视频。手头有一些理论背景总是好的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GATLayer</span>(torch.nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    实现 #3 受到 PyTorch Geometric 启发：https://github.com/rusty1s/pytorch_geometric</span><br><span class="hljs-string"></span><br><span class="hljs-string">    但是，这里的实现应该更容易理解！（并且性能相似）</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <span class="hljs-comment"># 我们会在许多函数中使用这些常量，所以在这里提取为成员字段</span><br>    src_nodes_dim = <span class="hljs-number">0</span>  <span class="hljs-comment"># 边索引中源节点的位置</span><br>    trg_nodes_dim = <span class="hljs-number">1</span>  <span class="hljs-comment"># 边索引中目标节点的位置</span><br><br>    <span class="hljs-comment"># 在归纳设置中，这些可能会改变 - 暂时保留这样的设置（未来可能不适用）</span><br>    nodes_dim = <span class="hljs-number">0</span>      <span class="hljs-comment"># 节点维度（轴在张量中可能是一个更熟悉的术语，节点维度是&quot;N&quot;的位置）</span><br>    head_dim = <span class="hljs-number">1</span>       <span class="hljs-comment"># 注意力头维度</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_in_features, num_out_features, num_of_heads, concat=<span class="hljs-literal">True</span>, activation=nn.ELU(<span class="hljs-params"></span>),</span><br><span class="hljs-params">                 dropout_prob=<span class="hljs-number">0.6</span>, add_skip_connection=<span class="hljs-literal">True</span>, bias=<span class="hljs-literal">True</span>, log_attention_weights=<span class="hljs-literal">False</span></span>):<br><br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        <span class="hljs-variable language_">self</span>.num_of_heads = num_of_heads<br>        <span class="hljs-variable language_">self</span>.num_out_features = num_out_features<br>        <span class="hljs-variable language_">self</span>.concat = concat  <span class="hljs-comment"># 是否应该连接还是平均注意力头</span><br>        <span class="hljs-variable language_">self</span>.add_skip_connection = add_skip_connection<br><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># 可训练权重：线性投影矩阵（在论文中表示为&quot;W&quot;）、注意力目标/源（在论文中表示为&quot;a&quot;）和偏差（在论文中未提到，但在官方GAT存储库中存在）</span><br>        <span class="hljs-comment">#</span><br><br>        <span class="hljs-comment"># 可以将这个矩阵视为 num_of_heads 个独立的 W 矩阵</span><br>        <span class="hljs-variable language_">self</span>.linear_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-comment"># 在我们连接目标节点（节点 i）和源节点（节点 j）之后，我们应用“加法”评分函数</span><br>        <span class="hljs-comment"># 它给我们未标准化的分数 &quot;e&quot;。在这里，我们分割 &quot;a&quot; 向量 - 但语义保持不变。</span><br>        <span class="hljs-comment"># 基本上，与执行 [x, y]（连接，x/y 是节点特征向量）和与 &quot;a&quot; 的点积不同，</span><br>        <span class="hljs-comment"># 我们分别对 x 和 &quot;a_left&quot; 进行点积，对 y 和 &quot;a_right&quot; 进行点积，然后将它们相加</span><br>        <span class="hljs-variable language_">self</span>.scoring_fn_target = nn.Parameter(torch.Tensor(<span class="hljs-number">1</span>, num_of_heads, num_out_features))<br>        <span class="hljs-variable language_">self</span>.scoring_fn_source = nn.Parameter(torch.Tensor(<span class="hljs-number">1</span>, num_of_heads, num_out_features))<br><br>        <span class="hljs-comment"># 在 GAT 中偏置绝对不是关键的 - 随时实验（我在这个问题上向主要作者 Petar 询问过）</span><br>        <span class="hljs-keyword">if</span> bias <span class="hljs-keyword">and</span> concat:<br>            <span class="hljs-variable language_">self</span>.bias = nn.Parameter(torch.Tensor(num_of_heads * num_out_features))<br>        <span class="hljs-keyword">elif</span> bias <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> concat:<br>            <span class="hljs-variable language_">self</span>.bias = nn.Parameter(torch.Tensor(num_out_features))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.register_parameter(<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>)<br><br>        <span class="hljs-keyword">if</span> add_skip_connection:<br>            <span class="hljs-variable language_">self</span>.skip_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-variable language_">self</span>.register_parameter(<span class="hljs-string">&#x27;skip_proj&#x27;</span>, <span class="hljs-literal">None</span>)<br><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># 可训练权重结束</span><br>        <span class="hljs-comment">#</span><br><br>        <span class="hljs-variable language_">self</span>.leakyReLU = nn.LeakyReLU(<span class="hljs-number">0.2</span>)  <span class="hljs-comment"># 使用 0.2，就像在论文中一样，不需要公开每个设置</span><br>        <span class="hljs-variable language_">self</span>.activation = activation<br>        <span class="hljs-comment"># 可能不是最好的设计，但我在 3 个位置使用相同的模块，用于特征投影之前/之后和注意力系数。</span><br>        <span class="hljs-comment"># 就功能而言，它与使用独立模块是相同的。</span><br>        <span class="hljs-variable language_">self</span>.dropout = nn.Dropout(p=dropout_prob)<br><br>        <span class="hljs-variable language_">self</span>.log_attention_weights = log_attention_weights  <span class="hljs-comment"># 是否应记录注意力权重</span><br>        <span class="hljs-variable language_">self</span>.attention_weights = <span class="hljs-literal">None</span>  <span class="hljs-comment"># 用于后续可视化目的，我在这里缓存权重</span><br><br>        <span class="hljs-variable language_">self</span>.init_params()<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, data</span>):<br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># 步骤 1：线性投影 + 正则化</span><br>        <span class="hljs-comment">#</span><br><br>        in_nodes_features, edge_index = data  <span class="hljs-comment"># 解包数据</span><br>        num_of_nodes = in_nodes_features.shape[<span class="hljs-variable language_">self</span>.nodes_dim]<br>        <span class="hljs-keyword">assert</span> edge_index.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">2</span>, <span class="hljs-string">f&#x27;期望形状为 (2,E) 的边索引，得到了 <span class="hljs-subst">&#123;edge_index.shape&#125;</span>&#x27;</span><br><br>        <span class="hljs-comment"># 形状 = (N, FIN)，其中 N 是图中的节点数，FIN 是每个节点的输入特征数</span><br>        <span class="hljs-comment"># 我们对所有输入节点特征应用 dropout（正如论文中所提到的）</span><br>        <span class="hljs-comment"># 注意：对于 Cora，特征已经非常稀疏，所以实际上可能帮助不大</span><br>        in_nodes_features = <span class="hljs-variable language_">self</span>.dropout(in_nodes_features)<br><br>        <span class="hljs-comment"># 形状 = (N, FIN) * (FIN, NH*FOUT) -&gt; (N, NH, FOUT)，其中 NH 是注意力头的数量，FOUT 是输出特征的数量</span><br>        <span class="hljs-comment"># 我们将输入节点特征投影到 NH 个独立的输出特征中（每个注意力头一个）</span><br>        nodes_features_proj = <span class="hljs-variable language_">self</span>.linear_proj(in_nodes_features).view(-<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.num_of_heads, <span class="hljs-variable language_">self</span>.num_out_features)<br><br>        nodes_features_proj = <span class="hljs-variable language_">self</span>.dropout(nodes_features_proj)  <span class="hljs-comment"># 在官方 GAT 实现中，他们在这里也使用了 dropout</span><br><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># 步骤 2：边注意力计算</span><br>        <span class="hljs-comment">#</span><br><br>        <span class="hljs-comment"># 应用评分函数（* 表示按元素（也称为Hadamard）乘法）</span><br>        <span class="hljs-comment"># 形状 = (N, NH, FOUT) * (1, NH, FOUT) -&gt; (N, NH, 1) -&gt; (N, NH)，因为 sum 压缩了最后一个维度</span><br>        <span class="hljs-comment"># 优化注：在我的实验中，torch.sum() 的性能与 .sum() 一样好</span><br>        scores_source = (nodes_features_proj * <span class="hljs-variable language_">self</span>.scoring_fn_source).<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>)<br>        scores_target = (nodes_features_proj * <span class="hljs-variable language_">self</span>.scoring_fn_target).<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 我们只需根据边索引复制（提升）源/目标节点的分数。我们不需要准备所有可能的分数组合，</span><br>        <span class="hljs-comment"># 我们只需要准备那些将实际使用的分数组合，这由边索引定义</span><br>        <span class="hljs-comment"># 分数形状 = (E, NH)，nodes_features_proj_lifted 形状 = (E, NH, FOUT)，E 是图中的边数</span><br>        scores_source_lifted, scores_target_lifted, nodes_features_proj_lifted = <span class="hljs-variable language_">self</span>.lift(scores_source, scores_target, nodes_features_proj, edge_index)<br>        scores_per_edge = <span class="hljs-variable language_">self</span>.leakyReLU(scores_source_lifted + scores_target_lifted)<br><br>        <span class="hljs-comment"># 形状 = (E, NH, 1)</span><br>        attentions_per_edge = <span class="hljs-variable language_">self</span>.neighborhood_aware_softmax(scores_per_edge, edge_index[<span class="hljs-variable language_">self</span>.trg_nodes_dim], num_of_nodes)<br>        <span class="hljs-comment"># 对邻居聚合添加随机性</span><br>        attentions_per_edge = <span class="hljs-variable language_">self</span>.dropout(attentions_per_edge)<br><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># 步骤 3：邻居聚合</span><br>        <span class="hljs-comment">#</span><br><br>        <span class="hljs-comment"># 逐元素（也称为Hadamard）乘法。运算符 * 执行与 torch.mul 相同的操作</span><br>        <span class="hljs-comment"># 形状 = (E, NH, FOUT) * (E, NH, 1) -&gt; (E, NH, FOUT)，1 被广播到 FOUT</span><br>        nodes_features_proj_lifted_weighted = nodes_features_proj_lifted * attentions_per_edge<br><br>        <span class="hljs-comment"># 这一部分对每个目标节点累积加权和投影的邻居特征向量</span><br>        <span class="hljs-comment"># 形状 = (N, NH, FOUT)</span><br>        out_nodes_features = <span class="hljs-variable language_">self</span>.aggregate_neighbors(nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes)<br><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># 步骤 4：残差/跳跃连接、连接和偏差</span><br>        <span class="hljs-comment">#</span><br><br>        out_nodes_features = <span class="hljs-variable language_">self</span>.skip_concat_bias(attentions_per_edge, in_nodes_features, out_nodes_features)<br>        <span class="hljs-keyword">return</span> (out_nodes_features, edge_index)<br><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># 辅助函数（没有注释几乎没有代码，所以不要害怕！）</span><br>    <span class="hljs-comment">#</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">neighborhood_aware_softmax</span>(<span class="hljs-params">self, scores_per_edge, trg_index, num_of_nodes</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        正如函数名所示，它对邻居执行 softmax。例如：假设图中有 5 个节点。其中的两个节点 1、2 与节点 3 相连。</span><br><span class="hljs-string">        如果我们要计算节点 3 的表示，我们应该考虑节点 1、2 和节点 3 本身的特征向量。由于我们对边 1-3、2-3 和 3-3 的分数</span><br><span class="hljs-string">        进行了评估，这个函数将计算类似这样的注意力分数：1-3 / (1-3 + 2-3 + 3-3)（其中 1-3 是过载的符号，它表示边 1-3 及其（exp）分数），</span><br><span class="hljs-string">        类似地对于 2-3 和 3-3，即对于这个邻居，我们不关心包含节点 4 和 5 的其他边分数。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        注意：</span><br><span class="hljs-string">        从 logits 中减去最大值不会改变最终结果，但它提高了数值稳定性，并且在几乎每个深度学习框架中，这是一个相当常见的“技巧”。</span><br><span class="hljs-string">        有关更多详细信息，请查看此链接：</span><br><span class="hljs-string"></span><br><span class="hljs-string">        https://stats.stackexchange.com/questions/338285/how-does-the-subtraction-of-the-logit-maximum-improve-learning</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 计算分子。使 logits &lt;= 0，以便 e^logit &lt;= 1（这将提高数值稳定性）</span><br>        scores_per_edge = scores_per_edge - scores_per_edge.<span class="hljs-built_in">max</span>()<br>        exp_scores_per_edge = scores_per_edge.exp()  <span class="hljs-comment"># softmax</span><br><br>        <span class="hljs-comment"># 计算分母。形状 = (E, NH)</span><br>        neigborhood_aware_denominator = <span class="hljs-variable language_">self</span>.sum_edge_scores_neighborhood_aware(exp_scores_per_edge, trg_index, num_of_nodes)<br><br>        <span class="hljs-comment"># 1e-16 在理论上不是必需的，但它仅出于数值稳定性考虑存在（避免除以 0）- 由于计算机将非常小的数字四舍五入到 0，这是可能的</span><br>        attentions_per_edge = exp_scores_per_edge / (neigborhood_aware_denominator + <span class="hljs-number">1e-16</span>)<br><br>        <span class="hljs-comment"># shape = (E, NH) -&gt; (E, NH, 1) so that we can do element-wise multiplication with projected node features</span><br>        <span class="hljs-keyword">return</span> attentions_per_edge.unsqueeze(-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sum_edge_scores_neighborhood_aware</span>(<span class="hljs-params">self, exp_scores_per_edge, trg_index, num_of_nodes</span>):<br>        <span class="hljs-comment"># 形状必须与 exp_scores_per_edge 相同（由 scatter_add_ 要求），即从 E 变为 (E, NH)</span><br>        trg_index_broadcasted = <span class="hljs-variable language_">self</span>.explicit_broadcast(trg_index, exp_scores_per_edge)<br><br>        <span class="hljs-comment"># 形状为 (N, NH)，其中 N 是节点数量，NH 是注意力头的数量</span><br>        size = <span class="hljs-built_in">list</span>(exp_scores_per_edge.shape)  <span class="hljs-comment"># 转换为列表，否则无法进行赋值</span><br>        size[<span class="hljs-variable language_">self</span>.nodes_dim] = num_of_nodes<br>        neighborhood_sums = torch.zeros(size, dtype=exp_scores_per_edge.dtype, device=exp_scores_per_edge.device)<br><br>        <span class="hljs-comment"># 位置 i 包含所有指向节点 i 的节点的 exp 分数之和（由目标索引指定）</span><br>        neighborhood_sums.scatter_add_(<span class="hljs-variable language_">self</span>.nodes_dim, trg_index_broadcasted, exp_scores_per_edge)<br><br>        <span class="hljs-comment"># 再次扩展，以便将其用作 softmax 分母。例如，节点 i 的总和将复制到源节点指向 i 的所有位置（由目标索引指定）</span><br>        <span class="hljs-comment"># 形状为 (N, NH) -&gt; (E, NH)</span><br>        <span class="hljs-keyword">return</span> neighborhood_sums.index_select(<span class="hljs-variable language_">self</span>.nodes_dim, trg_index)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">aggregate_neighbors</span>(<span class="hljs-params">self, nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes</span>):<br>        size = <span class="hljs-built_in">list</span>(nodes_features_proj_lifted_weighted.shape)  <span class="hljs-comment"># 转换为列表，否则无法进行赋值</span><br>        size[<span class="hljs-variable language_">self</span>.nodes_dim] = num_of_nodes  <span class="hljs-comment"># 形状为 (N, NH, FOUT)</span><br>        out_nodes_features = torch.zeros(size, dtype=in_nodes_features.dtype, device=in_nodes_features.device)<br><br>        <span class="hljs-comment"># 形状为 (E) -&gt; (E, NH, FOUT)</span><br>        trg_index_broadcasted = <span class="hljs-variable language_">self</span>.explicit_broadcast(edge_index[<span class="hljs-variable language_">self</span>.trg_nodes_dim], nodes_features_proj_lifted_weighted)<br>        <span class="hljs-comment"># 聚合步骤 - 我们累积所有注意力头的投影加权节点特征</span><br>        <span class="hljs-comment"># 形状为 (E, NH, FOUT) -&gt; (N, NH, FOUT)</span><br>        out_nodes_features.scatter_add_(<span class="hljs-variable language_">self</span>.nodes_dim, trg_index_broadcasted, nodes_features_proj_lifted_weighted)<br><br>        <span class="hljs-keyword">return</span> out_nodes_features<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lift</span>(<span class="hljs-params">self, scores_source, scores_target, nodes_features_matrix_proj, edge_index</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        抬升（Lift）即根据边索引复制特定向量。</span><br><span class="hljs-string">        张量的维度之一从 N 变为 E（这就是“抬升”一词的来源）。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        src_nodes_index = edge_index[<span class="hljs-variable language_">self</span>.src_nodes_dim]<br>        trg_nodes_index = edge_index[<span class="hljs-variable language_">self</span>.trg_nodes_dim]<br><br>        <span class="hljs-comment"># 使用 index_select 比在 PyTorch 中使用 &quot;normal&quot; 索引（scores_source[src_nodes_index]）更快！</span><br>        scores_source = scores_source.index_select(<span class="hljs-variable language_">self</span>.nodes_dim, src_nodes_index)<br>        scores_target = scores_target.index_select(<span class="hljs-variable language_">self</span>.nodes_dim, trg_nodes_index)<br>        nodes_features_matrix_proj_lifted = nodes_features_matrix_proj.index_select(<span class="hljs-variable language_">self</span>.nodes_dim, src_nodes_index)<br><br>        <span class="hljs-keyword">return</span> scores_source, scores_target, nodes_features_matrix_proj_lifted<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">explicit_broadcast</span>(<span class="hljs-params">self, this, other</span>):<br>        <span class="hljs-comment"># 附加单例维度，直到 this.dim() == other.dim()</span><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(this.dim(), other.dim()):<br>            this = this.unsqueeze(-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 明确扩展以使形状相同</span><br>        <span class="hljs-keyword">return</span> this.expand_as(other)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_params</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        我们使用 Glorot（也称为 Xavier 均匀）初始化的原因是因为它是 TF 的默认初始化方式：</span><br><span class="hljs-string">            https://stackoverflow.com/questions/37350131/what-is-the-default-variable-initializer-in-tensorflow</span><br><span class="hljs-string"></span><br><span class="hljs-string">        原始库在 TensorFlow（TF）中开发，并且他们使用了默认初始化。</span><br><span class="hljs-string">        随时进行实验 - 根据问题可能有更好的初始化方法。</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        nn.init.xavier_uniform_(<span class="hljs-variable language_">self</span>.linear_proj.weight)<br>        nn.init.xavier_uniform_(<span class="hljs-variable language_">self</span>.scoring_fn_target)<br>        nn.init.xavier_uniform_(<span class="hljs-variable language_">self</span>.scoring_fn_source)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            torch.nn.init.zeros_(<span class="hljs-variable language_">self</span>.bias)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">skip_concat_bias</span>(<span class="hljs-params">self, attention_coefficients, in_nodes_features, out_nodes_features</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.log_attention_weights:  <span class="hljs-comment"># 可能记录以供稍后在 playground.py 中可视化</span><br>            <span class="hljs-variable language_">self</span>.attention_weights = attention_coefficients<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.add_skip_connection:  <span class="hljs-comment"># 添加跳跃或残差连接</span><br>            <span class="hljs-keyword">if</span> out_nodes_features.shape[-<span class="hljs-number">1</span>] == in_nodes_features.shape[-<span class="hljs-number">1</span>]:  <span class="hljs-comment"># 如果 FIN == FOUT</span><br>                <span class="hljs-comment"># unsqueeze 实现以下效果：(N, FIN) -&gt; (N, 1, FIN)，输出特征为 (N, NH, FOUT) 所以 1 被广播到 NH</span><br>                <span class="hljs-comment"># 因此，基本上我们将输入向量 NH 次复制并添加到处理过的向量中</span><br>                out_nodes_features += in_nodes_features.unsqueeze(<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-comment"># FIN != FOUT，因此我们需要将输入特征向量投影到可以添加到输出特征向量的维度。</span><br>                <span class="hljs-comment"># skip_proj 添加了大量额外的容量，这可能导致过拟合。</span><br>                out_nodes_features += <span class="hljs-variable language_">self</span>.skip_proj(in_nodes_features).view(-<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.num_of_heads, <span class="hljs-variable language_">self</span>.num_out_features)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.concat:<br>            <span class="hljs-comment"># 形状为 (N, NH, FOUT) -&gt; (N, NH*FOUT)</span><br>            out_nodes_features = out_nodes_features.view(-<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.num_of_heads * <span class="hljs-variable language_">self</span>.num_out_features)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 形状为 (N, NH, FOUT) -&gt; (N, FOUT)</span><br>            out_nodes_features = out_nodes_features.mean(dim=<span class="hljs-variable language_">self</span>.head_dim)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            out_nodes_features += <span class="hljs-variable language_">self</span>.bias<br><br>        <span class="hljs-keyword">return</span> out_nodes_features <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.activation <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-variable language_">self</span>.activation(out_nodes_features)<br></code></pre></td></tr></table></figure>

<p>巨大节省的思想是仅计算实际使用的节点的分数，而不是计算每个可想象的组合的分数（这仅在完全连接的图中有效）。</p>
<p>一旦我们计算出”left”分数和”right”分数，我们就使用边索引“lift”它们。这样，如果1-&gt;2图中不存在边，我们的数据结构中就不会有这些分数对。</p>
<p>在添加提升的“左”和“右”（或者更好的命名方式是源和目标）分数后，我们很聪明的用neighborhood-aware softmax-这样 GAT的语义就得到了表达。完成后scatter add（您应该花时间理解并阅读文档），我们可以组合投影的特征向量，瞧，我们得到了一个成熟的 GAT 层。</p>
<hr>
<p>慢慢来，要有耐心！特别是如果您是 GNN 新手。</p>
<p>我不是一天就能学会所有这些的，需要时间来消化知识。</p>
<p>话虽如此，我们已经解锁了第 3 级（模型训练 💪）。😍<br>我们已经准备好了数据📜，我们已经准备好了GAT模型🦄，让我们开始训练这头野兽吧！💪</p>
<h1 id="第-3-部分：训练-GAT-💪（Cora-上的分类！）"><a href="#第-3-部分：训练-GAT-💪（Cora-上的分类！）" class="headerlink" title="第 3 部分：训练 GAT 💪（Cora 上的分类！）"></a>第 3 部分：训练 GAT 💪（Cora 上的分类！）</h1><p>唷，好吧，最困难的部分已经过去了。让我们创建一个简单的训练循环，其目标是学习对 Cora 节点进行分类。</p>
<p>但首先让我们定义一些相关的常量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-comment"># train.py 中使用的 3 个不同的模型训练/评估阶段</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LoopPhase</span>(enum.Enum):<br>    TRAIN = <span class="hljs-number">0</span>,  <span class="hljs-comment"># 训练阶段</span><br>    VAL = <span class="hljs-number">1</span>,    <span class="hljs-comment"># 验证阶段</span><br>    TEST = <span class="hljs-number">2</span>    <span class="hljs-comment"># 测试阶段</span><br><br>writer = SummaryWriter()  <span class="hljs-comment"># （tensorboard）writer 默认将输出到 ./runs/ 目录</span><br><br><span class="hljs-comment"># 用于提前停止的全局变量。在没有在验证数据集上有任何改进（通过准确性度量）的情况下，</span><br><span class="hljs-comment"># 经过一定数量的 epochs（由 patience_period 变量定义），我们将退出训练循环。</span><br>BEST_VAL_ACC = <span class="hljs-number">0</span>      <span class="hljs-comment"># 最佳验证准确性</span><br>BEST_VAL_LOSS = <span class="hljs-number">0</span>     <span class="hljs-comment"># 最佳验证损失</span><br>PATIENCE_CNT = <span class="hljs-number">0</span>      <span class="hljs-comment"># 忍耐计数</span><br><br>BINARIES_PATH = os.path.join(os.getcwd(), <span class="hljs-string">&#x27;models&#x27;</span>, <span class="hljs-string">&#x27;binaries&#x27;</span>)  <span class="hljs-comment"># 存储二进制文件的路径</span><br>CHECKPOINTS_PATH = os.path.join(os.getcwd(), <span class="hljs-string">&#x27;models&#x27;</span>, <span class="hljs-string">&#x27;checkpoints&#x27;</span>)  <span class="hljs-comment"># 存储检查点的路径</span><br><br><span class="hljs-comment"># 确保这些路径存在，因为代码的其余部分假定存在它们</span><br>os.makedirs(BINARIES_PATH, exist_ok=<span class="hljs-literal">True</span>)<br>os.makedirs(CHECKPOINTS_PATH, exist_ok=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure>

<p>另外，我们定义几个在训练模型时有用的函数。</p>
<p>训练状态包含很多有用的内容metadata，我们可以在以后使用。您可以想象，保存模型的测试准确性非常重要，尤其是当您在云上训练模型时 - 它使组织变得更好。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> git<br><span class="hljs-keyword">import</span> re  <span class="hljs-comment"># 正则表达式</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_training_state</span>(<span class="hljs-params">training_config, model</span>):<br>    training_state = &#123;<br>        <span class="hljs-string">&quot;commit_hash&quot;</span>: git.Repo(search_parent_directories=<span class="hljs-literal">True</span>).head.<span class="hljs-built_in">object</span>.hexsha,<br><br>        <span class="hljs-comment"># 训练详细信息</span><br>        <span class="hljs-string">&quot;dataset_name&quot;</span>: training_config[<span class="hljs-string">&#x27;dataset_name&#x27;</span>],  <span class="hljs-comment"># 数据集名称</span><br>        <span class="hljs-string">&quot;num_of_epochs&quot;</span>: training_config[<span class="hljs-string">&#x27;num_of_epochs&#x27;</span>],  <span class="hljs-comment"># 训练的 epochs 数量</span><br>        <span class="hljs-string">&quot;test_acc&quot;</span>: training_config[<span class="hljs-string">&#x27;test_acc&#x27;</span>],  <span class="hljs-comment"># 测试准确度</span><br><br>        <span class="hljs-comment"># 模型结构</span><br>        <span class="hljs-string">&quot;num_of_layers&quot;</span>: training_config[<span class="hljs-string">&#x27;num_of_layers&#x27;</span>],  <span class="hljs-comment"># 层的数量</span><br>        <span class="hljs-string">&quot;num_heads_per_layer&quot;</span>: training_config[<span class="hljs-string">&#x27;num_heads_per_layer&#x27;</span>],  <span class="hljs-comment"># 每层的注意力头数</span><br>        <span class="hljs-string">&quot;num_features_per_layer&quot;</span>: training_config[<span class="hljs-string">&#x27;num_features_per_layer&#x27;</span>],  <span class="hljs-comment"># 每层的特征数</span><br>        <span class="hljs-string">&quot;add_skip_connection&quot;</span>: training_config[<span class="hljs-string">&#x27;add_skip_connection&#x27;</span>],  <span class="hljs-comment"># 是否添加跳跃连接</span><br>        <span class="hljs-string">&quot;bias&quot;</span>: training_config[<span class="hljs-string">&#x27;bias&#x27;</span>],  <span class="hljs-comment"># 是否使用偏置</span><br>        <span class="hljs-string">&quot;dropout&quot;</span>: training_config[<span class="hljs-string">&#x27;dropout&#x27;</span>],  <span class="hljs-comment"># 丢弃率</span><br><br>        <span class="hljs-comment"># 模型状态</span><br>        <span class="hljs-string">&quot;state_dict&quot;</span>: model.state_dict()  <span class="hljs-comment"># 模型的状态字典</span><br>    &#125;<br><br>    <span class="hljs-keyword">return</span> training_state<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_model_metadata</span>(<span class="hljs-params">training_state</span>):<br>    header = <span class="hljs-string">f&#x27;\n<span class="hljs-subst">&#123;<span class="hljs-string">&quot;*&quot;</span>*<span class="hljs-number">5</span>&#125;</span> 模型训练元数据: <span class="hljs-subst">&#123;<span class="hljs-string">&quot;*&quot;</span>*<span class="hljs-number">5</span>&#125;</span>&#x27;</span><br>    <span class="hljs-built_in">print</span>(header)<br><br>    <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> training_state.items():<br>        <span class="hljs-keyword">if</span> key != <span class="hljs-string">&#x27;state_dict&#x27;</span>:  <span class="hljs-comment"># 不打印 state_dict，因为它只是一堆数字...</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;key&#125;</span>: <span class="hljs-subst">&#123;value&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;<span class="hljs-string">&quot;*&quot;</span> * <span class="hljs-built_in">len</span>(header)&#125;</span>\n&#x27;</span>)<br><br><br><span class="hljs-comment"># 确保我们不覆盖有价值的模型二进制文件（可以忽略 - 对 GAT 方法不是关键的）</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_available_binary_name</span>():<br>    prefix = <span class="hljs-string">&#x27;gat&#x27;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">valid_binary_name</span>(<span class="hljs-params">binary_name</span>):<br>        <span class="hljs-comment"># 第一次看到原始 f-字符串？不用担心，唯一的技巧是要加倍大括号。</span><br>        pattern = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">rf&#x27;<span class="hljs-subst">&#123;prefix&#125;</span>_[0-9]&#123;&#123;6&#125;&#125;\.pth&#x27;</span>)<br>        <span class="hljs-keyword">return</span> re.fullmatch(pattern, binary_name) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span><br><br>    <span class="hljs-comment"># 只需列出现有的二进制文件，以便我们不会覆盖它们，而是写入新的二进制文件</span><br>    valid_binary_names = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(valid_binary_name, os.listdir(BINARIES_PATH)))<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(valid_binary_names) &gt; <span class="hljs-number">0</span>:<br>        last_binary_name = <span class="hljs-built_in">sorted</span>(valid_binary_names)[-<span class="hljs-number">1</span>]<br>        new_suffix = <span class="hljs-built_in">int</span>(last_binary_name.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>][-<span class="hljs-number">6</span>:]) + <span class="hljs-number">1</span>  <span class="hljs-comment"># 递增 1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;prefix&#125;</span>_<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(new_suffix).zfill(<span class="hljs-number">6</span>)&#125;</span>.pth&#x27;</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;prefix&#125;</span>_000000.pth&#x27;</span><br><br></code></pre></td></tr></table></figure>

<p>很好，现在是组织程序设置的argparse好方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_training_args</span>():<br>    parser = argparse.ArgumentParser()<br><br>    <span class="hljs-comment"># 与训练相关</span><br>    parser.add_argument(<span class="hljs-string">&quot;--num_of_epochs&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;训练轮数&quot;</span>, default=<span class="hljs-number">10000</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--patience_period&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;在终止之前在验证集上没有改进的轮数&quot;</span>, default=<span class="hljs-number">1000</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--lr&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;模型学习率&quot;</span>, default=<span class="hljs-number">5e-3</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--weight_decay&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;模型权重的L2正则化&quot;</span>, default=<span class="hljs-number">5e-4</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--should_test&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;是否在测试集上测试模型？&#x27;</span>, default=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 数据集相关</span><br>    parser.add_argument(<span class="hljs-string">&quot;--dataset_name&quot;</span>, choices=[el.name <span class="hljs-keyword">for</span> el <span class="hljs-keyword">in</span> DatasetType], <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;用于训练的数据集&#x27;</span>, default=DatasetType.CORA.name)<br>    parser.add_argument(<span class="hljs-string">&quot;--should_visualize&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;是否可视化数据集？&#x27;</span>, default=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-comment"># 日志/调试/检查点相关（对实验非常有帮助）</span><br>    parser.add_argument(<span class="hljs-string">&quot;--enable_tensorboard&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;启用TensorBoard日志&quot;</span>, default=<span class="hljs-literal">False</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--console_log_freq&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输出到控制台的日志（每轮）频率（无日志则为None）&quot;</span>, default=<span class="hljs-number">100</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--checkpoint_freq&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;检查点模型保存（每轮）频率（无日志则为None）&quot;</span>, default=<span class="hljs-number">1000</span>)<br>    args = parser.parse_args(<span class="hljs-string">&quot;&quot;</span>)<br><br>    <span class="hljs-comment"># 模型架构相关 - 这是在官方论文中定义的用于Cora分类的架构</span><br>    gat_config = &#123;<br>        <span class="hljs-string">&quot;num_of_layers&quot;</span>: <span class="hljs-number">2</span>,  <span class="hljs-comment"># GNNs与CNNs相反，通常是浅层的（最终取决于图的属性）</span><br>        <span class="hljs-string">&quot;num_heads_per_layer&quot;</span>: [<span class="hljs-number">8</span>, <span class="hljs-number">1</span>],<br>        <span class="hljs-string">&quot;num_features_per_layer&quot;</span>: [CORA_NUM_INPUT_FEATURES, <span class="hljs-number">8</span>, CORA_NUM_CLASSES],<br>        <span class="hljs-string">&quot;add_skip_connection&quot;</span>: <span class="hljs-literal">False</span>,  <span class="hljs-comment"># 在Cora上影响性能</span><br>        <span class="hljs-string">&quot;bias&quot;</span>: <span class="hljs-literal">True</span>,  <span class="hljs-comment"># 结果对偏置不太敏感</span><br>        <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.6</span>,  <span class="hljs-comment"># 对丢失灵敏</span><br>    &#125;<br><br>    <span class="hljs-comment"># 将训练配置封装到字典中</span><br>    training_config = <span class="hljs-built_in">dict</span>()<br>    <span class="hljs-keyword">for</span> arg <span class="hljs-keyword">in</span> <span class="hljs-built_in">vars</span>(args):<br>        training_config[arg] = <span class="hljs-built_in">getattr</span>(args, arg)<br><br>    <span class="hljs-comment"># 添加附加的配置信息</span><br>    training_config.update(gat_config)<br><br>    <span class="hljs-keyword">return</span> training_config<br><br></code></pre></td></tr></table></figure>

<p>在这里，我们组织了高级别的 GAT 训练所需的一切。只需结合我们已经学过的部分即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_gat</span>(<span class="hljs-params">config</span>):<br>    <span class="hljs-keyword">global</span> BEST_VAL_ACC, BEST_VAL_LOSS<br><br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <span class="hljs-comment"># 检查是否有GPU，希望有！</span><br><br>    <span class="hljs-comment"># 步骤1：加载图数据</span><br>    node_features, node_labels, edge_index, train_indices, val_indices, test_indices = load_graph_data(config, device)<br><br>    <span class="hljs-comment"># 步骤2：准备模型</span><br>    gat = GAT(<br>        num_of_layers=config[<span class="hljs-string">&#x27;num_of_layers&#x27;</span>],<br>        num_heads_per_layer=config[<span class="hljs-string">&#x27;num_heads_per_layer&#x27;</span>],<br>        num_features_per_layer=config[<span class="hljs-string">&#x27;num_features_per_layer&#x27;</span>],<br>        add_skip_connection=config[<span class="hljs-string">&#x27;add_skip_connection&#x27;</span>],<br>        bias=config[<span class="hljs-string">&#x27;bias&#x27;</span>],<br>        dropout=config[<span class="hljs-string">&#x27;dropout&#x27;</span>],<br>        log_attention_weights=<span class="hljs-literal">False</span>  <span class="hljs-comment"># 不需要存储注意力，仅在 playground.py 中用于可视化</span><br>    ).to(device)<br><br>    <span class="hljs-comment"># 步骤3：准备其他与训练相关的工具（损失和优化器以及装饰函数）</span><br>    loss_fn = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;mean&#x27;</span>)<br>    optimizer = Adam(gat.parameters(), lr=config[<span class="hljs-string">&#x27;lr&#x27;</span>], weight_decay=config[<span class="hljs-string">&#x27;weight_decay&#x27;</span>])<br><br>    <span class="hljs-comment"># 这是训练的核心部分（我们稍后会定义它）</span><br>    <span class="hljs-comment"># 装饰函数使得代码更整洁，因为在训练和验证循环之间有很多冗余</span><br>    main_loop = get_main_loop(<br>        config,<br>        gat,<br>        loss_fn,<br>        optimizer,<br>        node_features,<br>        node_labels,<br>        edge_index,<br>        train_indices,<br>        val_indices,<br>        test_indices,<br>        config[<span class="hljs-string">&#x27;patience_period&#x27;</span>],<br>        time.time())<br><br>    BEST_VAL_ACC, BEST_VAL_LOSS, PATIENCE_CNT = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]  <span class="hljs-comment"># 重置用于提前停止的变量</span><br><br>    <span class="hljs-comment"># 步骤4：开始训练过程</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config[<span class="hljs-string">&#x27;num_of_epochs&#x27;</span>]):<br>        <span class="hljs-comment"># 训练循环</span><br>        main_loop(phase=LoopPhase.TRAIN, epoch=epoch)<br><br>        <span class="hljs-comment"># 验证循环</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            <span class="hljs-keyword">try</span>:<br>                main_loop(phase=LoopPhase.VAL, epoch=epoch)<br>            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:  <span class="hljs-comment"># &quot;忍耐已经用完&quot; 的异常 :O</span><br>                <span class="hljs-built_in">print</span>(<span class="hljs-built_in">str</span>(e))<br>                <span class="hljs-keyword">break</span>  <span class="hljs-comment"># 退出训练循环</span><br><br>    <span class="hljs-comment"># 步骤5：可能测试您的模型</span><br>    <span class="hljs-comment"># 不要过度拟合测试数据集 - 仅当您在验证数据集上微调了模型时，才应该报告测试数据集上的最终损失和准确性。</span><br>    <span class="hljs-keyword">if</span> config[<span class="hljs-string">&#x27;should_test&#x27;</span>]:<br>        test_acc = main_loop(phase=LoopPhase.TEST)<br>        config[<span class="hljs-string">&#x27;test_acc&#x27;</span>] = test_acc<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Test accuracy = <span class="hljs-subst">&#123;test_acc&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        config[<span class="hljs-string">&#x27;test_acc&#x27;</span>] = -<span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 将最新的GAT保存在二进制目录中</span><br>    torch.save(get_training_state(config, gat), os.path.join(BINARIES_PATH, get_available_binary_name()))<br><br></code></pre></td></tr></table></figure>

<p>🎉🎉🎉</p>
<p>现在是训练的核心部分 - 主循环，正如我所说的那样。</p>
<p>我这样组织它，这样我就不必为训练&#x2F;验证&#x2F;测试循环复制&#x2F;粘贴一堆相同的代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 简单的装饰函数，这样我就不必传递从一个时期到另一个时期都不变的参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_main_loop</span>(<span class="hljs-params">config, gat, cross_entropy_loss, optimizer, node_features, node_labels, edge_index, train_indices, val_indices, test_indices, patience_period, time_start</span>):<br><br>    node_dim = <span class="hljs-number">0</span>  <span class="hljs-comment"># 这可能会在我添加归纳示例（Cora是归纳的）时发生变化</span><br><br>    train_labels = node_labels.index_select(node_dim, train_indices)<br>    val_labels = node_labels.index_select(node_dim, val_indices)<br>    test_labels = node_labels.index_select(node_dim, test_indices)<br><br>    <span class="hljs-comment"># node_features 形状 = (N, FIN)，edge_index 形状 = (2, E)</span><br>    graph_data = (node_features, edge_index)  <span class="hljs-comment"># 我将数据打包到元组中，因为GAT使用nn.Sequential，它要求这样做</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_node_indices</span>(<span class="hljs-params">phase</span>):<br>        <span class="hljs-keyword">if</span> phase == LoopPhase.TRAIN:<br>            <span class="hljs-keyword">return</span> train_indices<br>        <span class="hljs-keyword">elif</span> phase == LoopPhase.VAL:<br>            <span class="hljs-keyword">return</span> val_indices<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> test_indices<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_node_labels</span>(<span class="hljs-params">phase</span>):<br>        <span class="hljs-keyword">if</span> phase == LoopPhase.TRAIN:<br>            <span class="hljs-keyword">return</span> train_labels<br>        <span class="hljs-keyword">elif</span> phase == LoopPhase.VAL:<br>            <span class="hljs-keyword">return</span> val_labels<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> test_labels<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">main_loop</span>(<span class="hljs-params">phase, epoch=<span class="hljs-number">0</span></span>):<br>        <span class="hljs-keyword">global</span> BEST_VAL_ACC, BEST_VAL_LOSS, PATIENCE_CNT, writer<br><br>        <span class="hljs-comment"># 某些模块的行为取决于我们是否正在训练模型。</span><br>        <span class="hljs-comment"># 例如 nn.Dropout - 我们只想在训练期间丢弃模型权重。</span><br>        <span class="hljs-keyword">if</span> phase == LoopPhase.TRAIN:<br>            gat.train()<br>        <span class="hljs-keyword">else</span>:<br>            gat.<span class="hljs-built_in">eval</span>()<br><br>        node_indices = get_node_indices(phase)<br>        gt_node_labels = get_node_labels(phase)  <span class="hljs-comment"># gt 代表 ground truth（实际标签）</span><br><br>        <span class="hljs-comment"># 进行前向传播并仅提取相关节点得分（train/val或test）</span><br>        <span class="hljs-comment"># 注意：[0] 只是提取数据的 node_features 部分（索引 1 包含 edge_index）</span><br>        <span class="hljs-comment"># 形状 = (N, C)，其中 N 是分割中节点的数量（train/val/test），C 是类的数量</span><br>        nodes_unnormalized_scores = gat(graph_data)[<span class="hljs-number">0</span>].index_select(node_dim, node_indices)<br><br>        <span class="hljs-comment"># 例如：让我们取 Cora 上单个节点的输出 - 它是一个大小为 7 的向量，包含未规范化的分数，如下所示：</span><br>        <span class="hljs-comment"># V = [-1.393,  3.0765, -2.4445,  9.6219,  2.1658, -5.5243, -4.6247]</span><br>        <span class="hljs-comment"># PyTorch的交叉熵损失所做的是，对于每个这样的向量，首先应用 softmax，所以我们将 V 转换为：</span><br>        <span class="hljs-comment"># [1.6421e-05, 1.4338e-03, 5.7378e-06, 0.99797, 5.7673e-04, 2.6376e-07, 6.4848e-07]</span><br>        <span class="hljs-comment"># 其次，无论正确类别是什么（假设是 3），它都将在位置 3 处取元素，0.99797 在这种情况下，</span><br>        <span class="hljs-comment"># 损失将为 -log(0.99797)。对于每个节点，它都会这样做并应用均值。</span><br>        <span class="hljs-comment"># 可以看到，随着大多数节点的正确类别的概率接近 1，损失趋近于 0！ &lt;3</span><br>        loss = cross_entropy_loss(nodes_unnormalized_scores, gt_node_labels)<br><br>        <span class="hljs-keyword">if</span> phase == LoopPhase.TRAIN:<br>            optimizer.zero_grad()  <span class="hljs-comment"># 清理计算图中可训练权重的梯度（.grad 字段）</span><br>            loss.backward()  <span class="hljs-comment"># 为计算图中的每个可训练权重计算梯度</span><br>            optimizer.step()  <span class="hljs-comment"># 将梯度应用到权重上</span><br><br>        <span class="hljs-comment"># 找到每个节点最大（未规范化）得分的索引，这是该节点的类别预测。</span><br>        <span class="hljs-comment"># 将这些与真实（实际标签）标签进行比较，并找到正确预测的比例 -&gt; 准确性指标。</span><br>        class_predictions = torch.argmax(nodes_unnormalized_scores, dim=-<span class="hljs-number">1</span>)<br>        accuracy = torch.<span class="hljs-built_in">sum</span>(torch.eq(class_predictions, gt_node_labels).long()).item() / <span class="hljs-built_in">len</span>(gt_node_labels)<br><br>        <span class="hljs-keyword">if</span> phase == LoopPhase.TRAIN:<br>            <span class="hljs-comment"># 记录指标</span><br>            <span class="hljs-keyword">if</span> config[<span class="hljs-string">&#x27;enable_tensorboard&#x27;</span>]:<br>                writer.add_scalar(<span class="hljs-string">&#x27;training_loss&#x27;</span>, loss.item(), epoch)<br>                writer.add_scalar(<span class="hljs-string">&#x27;training_acc&#x27;</span>, accuracy, epoch)<br><br>            <span class="hljs-comment"># 保存模型检查点</span><br>            <span class="hljs-keyword">if</span> config[<span class="hljs-string">&#x27;checkpoint_freq&#x27;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> (epoch + <span class="hljs-number">1</span>) % config[<span class="hljs-string">&#x27;checkpoint_freq&#x27;</span>] == <span class="hljs-number">0</span>:<br>                ckpt_model_name = <span class="hljs-string">f&quot;gat_ckpt_epoch_<span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>.pth&quot;</span><br>                config[<span class="hljs-string">&#x27;test_acc&#x27;</span>] = -<span class="hljs-number">1</span><br>                torch.save(get_training_state(config, gat), os.path.join(CHECKPOINTS_PATH, ckpt_model_name))<br><br>        <span class="hljs-keyword">elif</span> phase == LoopPhase.VAL:<br>            <span class="hljs-comment"># 记录指标</span><br>            <span class="hljs-keyword">if</span> config[<span class="hljs-string">&#x27;enable_tensorboard&#x27;</span>]:<br>                writer.add_scalar(<span class="hljs-string">&#x27;val_loss&#x27;</span>, loss.item(), epoch)<br>                writer.add_scalar(<span class="hljs-string">&#x27;val_acc&#x27;</span>, accuracy, epoch)<br><br>            <span class="hljs-comment"># 记录到控制台</span><br>            <span class="hljs-keyword">if</span> config[<span class="hljs-string">&#x27;console_log_freq&#x27;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> epoch % config[<span class="hljs-string">&#x27;console_log_freq&#x27;</span>] == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;GAT training: time elapsed= <span class="hljs-subst">&#123;(time.time() - time_start):<span class="hljs-number">.2</span>f&#125;</span> [s] | epoch=<span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span> | val acc=<span class="hljs-subst">&#123;accuracy&#125;</span>&#x27;</span>)<br><br>            <span class="hljs-comment"># “耐心”逻辑 - 我们是否应该从训练循环中退出？如果验证准确性不断提高</span><br>            <span class="hljs-comment"># 或验证损失不断下降，我们就不会停止</span><br>            <span class="hljs-keyword">if</span> accuracy &gt; BEST_VAL_ACC <span class="hljs-keyword">or</span> loss.item() &lt; BEST_VAL_LOSS:<br>                BEST_VAL_ACC = <span class="hljs-built_in">max</span>(accuracy, BEST_VAL_ACC)  <span class="hljs-comment"># 跟踪到目前为止的最佳验证准确性</span><br>                BEST_VAL_LOSS = <span class="hljs-built_in">min</span>(loss.item(), BEST_VAL_LOSS)<br>                PATIENCE_CNT = <span class="hljs-number">0</span>  <span class="hljs-comment"># 每次遇到新的最佳准确性时重置计数器</span><br>            <span class="hljs-keyword">else</span>:<br>                PATIENCE_CNT += <span class="hljs-number">1</span>  <span class="hljs-comment"># 否则继续计数</span><br><br>            <span class="hljs-keyword">if</span> PATIENCE_CNT &gt;= patience_period:<br>                <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&#x27;停止训练，宇宙对这次训练没有更多的耐心了。&#x27;</span>)<br><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> accuracy  <span class="hljs-comment"># 在测试阶段，我们只返回测试准确性</span><br><br>    <span class="hljs-keyword">return</span> main_loop  <span class="hljs-comment"># 返回装饰函数</span><br><br></code></pre></td></tr></table></figure>

<p>开始训练吧</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Train the graph attention network (GAT)</span><br>train_gat(get_training_args())<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">/var/folders/f0/812mfv7x63vbytjs3yf4gxtc0000gn/T/ipykernel_16269/2448994618.py:6: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.
  data = pickle.load(file)


GAT training: time elapsed= 0.22 [s] | epoch=1 | val acc=0.124
GAT training: time elapsed= 5.56 [s] | epoch=101 | val acc=0.79
GAT training: time elapsed= 10.72 [s] | epoch=201 | val acc=0.8
GAT training: time elapsed= 15.92 [s] | epoch=301 | val acc=0.8
GAT training: time elapsed= 21.13 [s] | epoch=401 | val acc=0.782
GAT training: time elapsed= 26.34 [s] | epoch=501 | val acc=0.784
GAT training: time elapsed= 31.68 [s] | epoch=601 | val acc=0.816
GAT training: time elapsed= 36.79 [s] | epoch=701 | val acc=0.804
GAT training: time elapsed= 41.91 [s] | epoch=801 | val acc=0.806
GAT training: time elapsed= 47.01 [s] | epoch=901 | val acc=0.814
GAT training: time elapsed= 52.20 [s] | epoch=1001 | val acc=0.81
GAT training: time elapsed= 57.41 [s] | epoch=1101 | val acc=0.798
GAT training: time elapsed= 62.52 [s] | epoch=1201 | val acc=0.816
GAT training: time elapsed= 67.61 [s] | epoch=1301 | val acc=0.796
GAT training: time elapsed= 72.71 [s] | epoch=1401 | val acc=0.79
GAT training: time elapsed= 77.82 [s] | epoch=1501 | val acc=0.812
GAT training: time elapsed= 82.94 [s] | epoch=1601 | val acc=0.796
GAT training: time elapsed= 88.08 [s] | epoch=1701 | val acc=0.798
GAT training: time elapsed= 93.26 [s] | epoch=1801 | val acc=0.794
GAT training: time elapsed= 98.39 [s] | epoch=1901 | val acc=0.8
GAT training: time elapsed= 103.64 [s] | epoch=2001 | val acc=0.806
停止训练，宇宙对这次训练没有更多的耐心了。
Test accuracy = 0.817
</code></pre>
<p>好的！！！🎉🎉🎉 4 级解锁（GAT 可视化🔮）。</p>
<p>我们刚刚82.9 %在 Cora 的测试节点上实现了！与原始 GAT 论文中报告的数字相同！</p>
<p>现在我们已经一切就绪：</p>
<ol>
<li>数据加载和可视化📜 -&gt; 确认</li>
<li>GAT 模型定义 🦄 -&gt; 确认</li>
<li>训练循环设置和训练后的模型二进制文件 💪 -&gt; 确认</li>
</ol>
<p>现在让我们在显微镜🔬下观察 GAT 模型并了解我们得到的权重 - 我们可以通过多种方式做到这点。</p>
<h1 id="第-4-部分：可视化-GAT-🔮"><a href="#第-4-部分：可视化-GAT-🔮" class="headerlink" title="第 4 部分：可视化 GAT 🔮"></a>第 4 部分：可视化 GAT 🔮</h1><p>让我们首先定义一些我们需要的函数。</p>
<p>以下单元格的代码片段将被多次调用，因此我们将其提取到一个函数中 - 一个很好的模块化设计。</p>
<p>注意：主要原因实际上是 igraph 在 Jupyter 上出现问题，所以我正在解决这个问题，如果你好奇的话，请查看<a href="https://github.com/gordicaleksa/pytorch-GAT/blob/main/playground.py#L147">原始代码</a> 😂</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gat_forward_pass</span>(<span class="hljs-params">model_name, dataset_name</span>):<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <span class="hljs-comment"># 检查是否有 GPU，希望有！</span><br><br>    config = &#123;<br>        <span class="hljs-string">&#x27;dataset_name&#x27;</span>: dataset_name,<br>        <span class="hljs-string">&#x27;should_visualize&#x27;</span>: <span class="hljs-literal">False</span>  <span class="hljs-comment"># 不可视化数据集</span><br>    &#125;<br><br>    <span class="hljs-comment"># 步骤 1：准备数据</span><br>    node_features, node_labels, edge_index, _, _, _ = load_graph_data(config, device)<br><br>    <span class="hljs-comment"># 步骤 2：准备模型</span><br>    model_path = os.path.join(BINARIES_PATH, model_name)<br>    model_state = torch.load(model_path, map_location=torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>))<br><br>    gat = GAT(<br>        num_of_layers=model_state[<span class="hljs-string">&#x27;num_of_layers&#x27;</span>],<br>        num_heads_per_layer=model_state[<span class="hljs-string">&#x27;num_heads_per_layer&#x27;</span>],<br>        num_features_per_layer=model_state[<span class="hljs-string">&#x27;num_features_per_layer&#x27;</span>],<br>        add_skip_connection=model_state[<span class="hljs-string">&#x27;add_skip_connection&#x27;</span>],<br>        bias=model_state[<span class="hljs-string">&#x27;bias&#x27;</span>],<br>        dropout=model_state[<span class="hljs-string">&#x27;dropout&#x27;</span>],<br>        log_attention_weights=<span class="hljs-literal">True</span><br>    ).to(device)<br><br>    print_model_metadata(model_state)<br>    gat.load_state_dict(model_state[<span class="hljs-string">&quot;state_dict&quot;</span>], strict=<span class="hljs-literal">True</span>)<br>    gat.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 一些层，比如 nn.Dropout，在训练模式和评估模式下的行为是不同的，因此这一部分很重要</span><br><br>    <span class="hljs-comment"># 步骤 3：计算我们将需要不同可视化类型的所有东西（注意力、分数、edge_index）</span><br><br>    <span class="hljs-comment"># 这个上下文管理器很重要（你经常会看到它），否则 PyTorch 会占用更多内存。</span><br>    <span class="hljs-comment"># 它会保存反向传播的激活，但我们不会进行任何模型训练，只是预测。</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># 步骤 3：运行预测并收集高维数据</span><br>        all_nodes_unnormalized_scores, _ = gat((node_features, edge_index))  <span class="hljs-comment"># 形状 = (N, 类别数)</span><br>        all_nodes_unnormalized_scores = all_nodes_unnormalized_scores.cpu().numpy()<br><br>    <span class="hljs-keyword">return</span> all_nodes_unnormalized_scores, edge_index, node_labels, gat<br><br></code></pre></td></tr></table></figure>

<p>很高兴只生成将在下游可视化中使用的数据，您将在以下单元格中看到定义的数据。</p>
<p>我们还需要一个辅助函数，已经准备好了！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 绘制（但尚未绘制）熵直方图。如果你对为什么突然出现熵感到困惑，请跟我走，你很快就会明白的。</span><br><span class="hljs-comment"># 基本上，它帮助我们量化 GAT 学到的注意力模式的有用性。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">draw_entropy_histogram</span>(<span class="hljs-params">entropy_array, title, color=<span class="hljs-string">&#x27;blue&#x27;</span>, uniform_distribution=<span class="hljs-literal">False</span>, num_bins=<span class="hljs-number">30</span></span>):<br>    max_value = np.<span class="hljs-built_in">max</span>(entropy_array)<br>    bar_width = (max_value / num_bins) * (<span class="hljs-number">1.0</span> <span class="hljs-keyword">if</span> uniform_distribution <span class="hljs-keyword">else</span> <span class="hljs-number">0.75</span>)<br>    histogram_values, histogram_bins = np.histogram(entropy_array, bins=num_bins, <span class="hljs-built_in">range</span>=(<span class="hljs-number">0.0</span>, max_value))<br><br>    plt.bar(histogram_bins[:num_bins], histogram_values[:num_bins], width=bar_width, color=color)<br>    plt.xlabel(<span class="hljs-string">f&#x27;熵区间&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">f&#x27;节点邻居数量&#x27;</span>)<br>    plt.title(title)<br><br></code></pre></td></tr></table></figure>

<p>很好，接下来是我们将用来可视化 GAT 嵌入（通过 t-SNE）和熵直方图的主要函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.manifold <span class="hljs-keyword">import</span> TSNE<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> entropy<br><br><br><span class="hljs-comment"># 让我们定义一个枚举作为选择不同可视化选项的清晰方式</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VisualizationType</span>(enum.Enum):<br>    ATTENTION = <span class="hljs-number">0</span>,<br>    EMBEDDINGS = <span class="hljs-number">1</span>,<br>    ENTROPY = <span class="hljs-number">2</span>,<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">visualize_gat_properties</span>(<span class="hljs-params">model_name=<span class="hljs-string">r&#x27;gat_000000.pth&#x27;</span>, dataset_name=DatasetType.CORA.name, visualization_type=VisualizationType.ATTENTION</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    在可视化选项之间选择 t-SNE 或熵直方图。</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    t-SNE 的注意事项：</span><br><span class="hljs-string">    查看此链接以获取有关如何调整 t-SNE 的更多直观信息：https://distill.pub/2016/misread-tsne/</span><br><span class="hljs-string"></span><br><span class="hljs-string">    如果您认为实现 t-SNE 并解释每个细节的有用性，并且愿意让我知道，可以打开一个问题或在社交媒体上私信我！&lt;3</span><br><span class="hljs-string"></span><br><span class="hljs-string">    注意：我还尝试过使用 UMAP，但它并没有提供比 t-SNE 更多的见解。</span><br><span class="hljs-string">    （缺点：如果要使用其绘图功能，它有很多依赖项）</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    <span class="hljs-comment"># 获取创建可视化所需的数据</span><br>    all_nodes_unnormalized_scores, edge_index, node_labels, gat = gat_forward_pass(model_name, dataset_name)<br>    <br>    <span class="hljs-comment"># 执行特定的可视化（t-SNE 或熵直方图）</span><br>    <span class="hljs-keyword">if</span> visualization_type == VisualizationType.EMBEDDINGS:  <span class="hljs-comment"># 可视化嵌入（使用 t-SNE）</span><br>        node_labels = node_labels.cpu().numpy()<br>        num_classes = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(node_labels))<br><br>        <span class="hljs-comment"># 多尝试 perplexity，这可能是 t-SNE 中最重要的参数之一，它基本上控制了高维（原始）空间中 Gaussians 的标准差，即高维空间中邻居的大小。</span><br>        <span class="hljs-comment"># 简而言之，t-SNE 的目标是最小化高维点上拟合的联合高斯分布与低维点上拟合的 t-Student 分布之间的 KL 散度</span><br>        <span class="hljs-comment"># 直观地说，通过这样做，我们保留了高维和低维点之间的相似性（关系）。</span><br>        <span class="hljs-comment"># 如果您对 t-SNE尚不熟悉，这可能不会有太多意义，我已经尝试过了。:P</span><br>        t_sne_embeddings = TSNE(n_components=<span class="hljs-number">2</span>, perplexity=<span class="hljs-number">30</span>, method=<span class="hljs-string">&#x27;barnes_hut&#x27;</span>).fit_transform(all_nodes_unnormalized_scores)<br><br>        fig = plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)  <span class="hljs-comment"># 否则在 Jupyter Notebook 中，绘图会很小</span><br>        <span class="hljs-keyword">for</span> class_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_classes):<br>            <span class="hljs-comment"># 我们提取真实标签等于 class_id 的点，并以相同的方式对它们进行着色，希望它们在 2D 图上聚集在一起 -</span><br>            <span class="hljs-comment"># 这意味着 GAT 已经学到了很好的表示！</span><br>            plt.scatter(t_sne_embeddings[node_labels == class_id, <span class="hljs-number">0</span>], t_sne_embeddings[node_labels == class_id, <span class="hljs-number">1</span>], s=<span class="hljs-number">20</span>, color=cora_label_to_color_map[class_id], edgecolors=<span class="hljs-string">&#x27;black&#x27;</span>, linewidths=<span class="hljs-number">0.2</span>)<br>        plt.show()<br><br>    <span class="hljs-comment"># 我们希望我们的局部概率分布（对邻居的注意力权重）是非均匀的，因为这意味着 GAT 学到了有用的模式。熵直方图帮助我们可视化</span><br>    <span class="hljs-comment"># 这些邻居分布与均匀分布（常数关注）有多么不同。如果 GAT 学到了常量注意力，我们可能很好地使用 GCN 或一些更简单的模型。</span><br>    <span class="hljs-keyword">elif</span> visualization_type == VisualizationType.ENTROPY:<br>        num_heads_per_layer = [layer.num_of_heads <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> gat.gat_net]<br>        num_layers = <span class="hljs-built_in">len</span>(num_heads_per_layer)<br><br>        num_of_nodes = <span class="hljs-built_in">len</span>(node_features)<br>        target_node_ids = edge_index[<span class="hljs-number">1</span>].cpu().numpy()<br><br>        <span class="hljs-comment"># 对于每个 GAT 层和每个 GAT 注意力头，绘制熵直方图</span><br>        <span class="hljs-keyword">for</span> layer_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers):<br>            <span class="hljs-comment"># 获取边缘的注意力权重（在上面的 GAT 正向传递期间记录了注意力）</span><br>            <span class="hljs-comment"># 注意力形状 = (N, NH, 1) -&gt; (N, NH) - 我们只挤压了最后一个维度，它是多余的</span><br>            all_attention_weights = gat.gat_net[layer_id].attention_weights.squeeze(dim=-<span class="hljs-number">1</span>).cpu().numpy()<br><br>            <span class="hljs-keyword">for</span> head_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_heads_per_layer[layer_id]):<br>                uniform_dist_entropy_list = []  <span class="hljs-comment"># 将理想的均匀直方图保存为参考</span><br>                neighborhood_entropy_list = []<br><br>                <span class="hljs-comment"># 这也可以通过 scatter_add_（没有 for 循环）更有效地完成</span><br>                <span class="hljs-comment"># 伪：out.scatter_add_(node_dim, -all_attention_weights * log(all_attention_weights), target_index)</span><br>                <span class="hljs-keyword">for</span> target_node_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_of_nodes):  <span class="hljs-comment"># 找到图中每个节点的邻居</span><br>                    <span class="hljs-comment"># 这些注意力权重总和为 1，因为 GAT 的设计，所以我们可以将其视为概率分布</span><br>                    neigborhood_attention = all_attention_weights[target_node_ids == target_node_id].flatten()<br>                    <span class="hljs-comment"># 同样长度的参考均匀分布</span><br>                    ideal_uniform_attention = np.ones(<span class="hljs-built_in">len</span>(neigborhood_attention))/<span class="hljs-built_in">len</span>(neigborhood_attention)<br><br>                    <span class="hljs-comment"># 计算熵，如果您对该概念不熟悉，请查看此视频：</span><br>                    <span class="hljs-comment"># https://www.youtube.com/watch?v=ErfnhcEV1O8（Aurélien Géron）</span><br>                    neighborhood_entropy_list.append(entropy(neigborhood_attention, base=<span class="hljs-number">2</span>))<br>                    uniform_dist_entropy_list.append(entropy(ideal_uniform_attention, base=<span class="hljs-number">2</span>))<br><br>                title = <span class="hljs-string">f&#x27;Cora 熵直方图 层=<span class="hljs-subst">&#123;layer_id&#125;</span>，注意力头=<span class="hljs-subst">&#123;head_id&#125;</span>&#x27;</span><br>                draw_entropy_histogram(uniform_dist_entropy_list, title, color=<span class="hljs-string">&#x27;orange&#x27;</span>, uniform_distribution=<span class="hljs-literal">True</span>)<br>                draw_entropy_histogram(neighborhood_entropy_list, title, color=<span class="hljs-string">&#x27;dodgerblue&#x27;</span>)<br><br>                fig = plt.gcf()  <span class="hljs-comment"># 获取当前图形</span><br>                plt.show()<br>                fig.savefig(os.path.join(DATA_DIR_PATH, <span class="hljs-string">f&#x27;layer_<span class="hljs-subst">&#123;layer_id&#125;</span>_head_<span class="hljs-subst">&#123;head_id&#125;</span>.jpg&#x27;</span>))<br>                plt.close()<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">f&#x27;不支持的可视化类型 <span class="hljs-subst">&#123;visualization_type&#125;</span>。&#x27;</span>)<br><br></code></pre></td></tr></table></figure>

<p>好的！最后让我们用用吧！首先是-t-SNE。</p>
<h1 id="使用-t-SNE-可视化-GAT-的嵌入-📈"><a href="#使用-t-SNE-可视化-GAT-的嵌入-📈" class="headerlink" title="使用 t-SNE 可视化 GAT 的嵌入 📈"></a>使用 t-SNE 可视化 GAT 的嵌入 📈</h1><p>t-SNE 属于一大类降维方法。</p>
<p>它在社区中获得了巨大的关注，因为它使用简单并且效果良好（可能是因为它是由 Geoffrey Hinton khm共同创作的）</p>
<p>还有其他较新的方法比如UMAP，但尚未获得足够的关注（据我所知）。</p>
<p>但理论已经足够了，让我们看一些图表！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">model_name=<span class="hljs-string">r&#x27;gat_000000.pth&#x27;</span>  <span class="hljs-comment"># This model is checked-in, feel free to use the one you trained</span><br>dataset_name=DatasetType.CORA.name<br><br><br>visualize_gat_properties(<br>        model_name,<br>        dataset_name,<br>        visualization_type=VisualizationType.EMBEDDINGS  <span class="hljs-comment"># pick between attention, t-SNE embeddings and entropy</span><br>)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">/var/folders/f0/812mfv7x63vbytjs3yf4gxtc0000gn/T/ipykernel_16269/2448994618.py:6: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.
  data = pickle.load(file)



***** 模型训练元数据: *****
commit_hash: 91fb864b8f9ddefd401bf5399cea779bd3c0a63b
dataset_name: CORA
num_of_epochs: 10000
test_acc: 0.822
num_of_layers: 2
num_heads_per_layer: [8, 1]
num_features_per_layer: [1433, 8, 7]
add_skip_connection: False
bias: True
dropout: 0.6
layer_type: IMP3
*********************



/Users/gawaintan/miniforge3/envs/torch/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 8722 (\N&#123;MINUS SIGN&#125;) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)
</code></pre>
<p><img src="https://ptpimg.me/yt72e1.png" alt="请添加图片描述"></p>
<p>漂亮！</p>
<p>我们可以看到以下内容 - 一旦我们通过 GAT 进行前向传递，它就会将维度（节点数、每个特征向量的特征数）&#x3D; 的输入特征向量转换为 因为 Cora 有 7 个(2708, 1433)类(2708, 7)。</p>
<p>这些类是：Genetic Algorithms、Reinforcement Learning等，使其不那么抽象，但最终它适用于任何 7 个类的集合并不重要。</p>
<p>现在，一旦我们获得了 7 维向量，我们就使用 t-SNE 将它们映射到 2D 向量（因为你知道很难绘制 7D 向量）。t-SNE 的技巧在于，它保留了向量之间的关系，因此，粗略地说，如果它们在 7D 空间中接近（但是我们定义“接近度”），那么它们在 2D 空间中也会接近。</p>
<p>现在您可以看到同一类的点（它们具有相同的颜色）聚集在一起！这是一个理想的特性，因为现在训练一个能够正确预测类别的分类器要容易得多。</p>
<hr>
<p>太棒了，现在让我们将注意力转移到注意力上，因为我们毕竟正在处理图注意力网络。</p>
<h1 id="可视化邻居的注意力📣"><a href="#可视化邻居的注意力📣" class="headerlink" title="可视化邻居的注意力📣"></a>可视化邻居的注意力📣</h1><p>所以，你现在希望了解 GAT 的大致工作原理，并且知道在聚合阶段，每个节点都会为其每个邻居分配一个注意力系数（包括它自己，因为我们添加了自边）。</p>
<p>关于我们可以想象什么有什么想法吗？好吧，让我们选择一些节点，看看他们学到了哪些注意力模式！</p>
<p>您可能想到的第一个想法是，如果注意力较大，则将边画得更厚，反之亦然（这也是我想到的最后一个想法）。</p>
<p>我们开始吧！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 获取创建可视化所需的数据</span><br>all_nodes_unnormalized_scores, edge_index, node_labels, gat = gat_forward_pass(model_name, dataset_name)<br><br><span class="hljs-comment"># 我们要可视化其邻近节点的关注度的节点数量</span><br>num_nodes_of_interest = <span class="hljs-number">4</span>  <span class="hljs-comment"># 4 是一个您可以尝试不同值的任意数字</span><br>head_to_visualize = <span class="hljs-number">0</span>  <span class="hljs-comment"># 绘制来自该多头注意力头的注意力（仅最后一层有一个多头）</span><br>gat_layer_id = <span class="hljs-number">1</span>  <span class="hljs-comment"># 绘制来自该 GAT 层的注意力（由于我们的 GAT 只有 2 层，这是最后一层）</span><br><br><span class="hljs-comment"># 构建完整图</span><br><span class="hljs-comment"># node_features 形状 =（N，FIN），其中 N 是节点数，FIN 是输入特征数</span><br>total_num_of_nodes = <span class="hljs-built_in">len</span>(node_features)<br>complete_graph = ig.Graph()<br>complete_graph.add_vertices(total_num_of_nodes)  <span class="hljs-comment"># igraph 使用这种格式创建带有 [0，total_num_of_nodes - 1] ID 的节点</span><br>edge_index_tuples = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(edge_index[<span class="hljs-number">0</span>, :], edge_index[<span class="hljs-number">1</span>, :]))  <span class="hljs-comment"># igraph 需要这种格式</span><br>complete_graph.add_edges(edge_index_tuples)<br><br><span class="hljs-comment"># 选择要绘制的目标节点（具有最高度数的节点 + 随机节点）</span><br><span class="hljs-comment"># 注意：随机节点和具有最高度数的节点之间可能存在重叠 - 但这是非常不可能的</span><br>highest_degree_node_ids = np.argpartition(complete_graph.degree(), -num_nodes_of_interest)[-num_nodes_of_interest:]<br>random_node_ids = np.random.randint(low=<span class="hljs-number">0</span>, high=total_num_of_nodes, size=num_nodes_of_interest)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Highest degree nodes = <span class="hljs-subst">&#123;highest_degree_node_ids&#125;</span>&#x27;</span>)<br><br>target_node_ids = edge_index[<span class="hljs-number">1</span>]<br>source_nodes = edge_index[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># 选择要为其可视化关注度的节点 ID！</span><br><span class="hljs-comment">#</span><br><br><span class="hljs-comment"># 由于在 Jupyter 中无法使用 for 循环，只需设置一些数字</span><br>target_node_id = <span class="hljs-number">306</span>  <span class="hljs-comment"># 306 是第二度数最高的节点</span><br><br><span class="hljs-comment"># 步骤 1：查找目标节点的邻近节点</span><br><span class="hljs-comment"># 注意：对于 CORA，包括自环，因此目标节点是其自身的邻居（Alexandro，yo soy tu madre）</span><br>src_nodes_indices = torch.eq(target_node_ids, target_node_id)<br>source_node_ids = source_nodes[src_nodes_indices].cpu().numpy()<br>size_of_neighborhood = <span class="hljs-built_in">len</span>(source_node_ids)<br><br><span class="hljs-comment"># 步骤 2：获取它们的标签</span><br>labels = node_labels[source_node_ids].cpu().numpy()<br><br><span class="hljs-comment"># 步骤 3：获取边缘的注意力权重（在上面的 GAT 正向传递期间记录了注意力）</span><br><span class="hljs-comment"># attention 形状 =（N，NH，1）-&gt;（N，NH） - 我们只挤压了最后一个维度，它是多余的</span><br>all_attention_weights = gat.gat_net[gat_layer_id].attention_weights.squeeze(dim=-<span class="hljs-number">1</span>)<br>attention_weights = all_attention_weights[src_nodes_indices, head_to_visualize].cpu().numpy()<br><span class="hljs-comment"># 此部分显示了对于 CORA，GAT 学到的注意力权重几乎是常量！ 就像在 GCN 中一样！</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Max attention weight = <span class="hljs-subst">&#123;np.<span class="hljs-built_in">max</span>(attention_weights)&#125;</span> and min = <span class="hljs-subst">&#123;np.<span class="hljs-built_in">min</span>(attention_weights)&#125;</span>&#x27;</span>)<br>attention_weights /= np.<span class="hljs-built_in">max</span>(attention_weights)  <span class="hljs-comment"># 重新缩放最大权重为 1，以便更好地绘制</span><br><br><span class="hljs-comment"># 构建我们想要可视化注意力的邻居图</span><br><span class="hljs-comment"># igraph 约束 - 它与连续范围的 ID 一起使用，因此我们将例如节点 497 映射到 0，12 到 1，等等。</span><br>id_to_igraph_id = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(source_node_ids, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(source_node_ids))))<br>ig_graph = ig.Graph()<br>ig_graph.add_vertices(size_of_neighborhood)<br>ig_graph.add_edges([(id_to_igraph_id[neighbor], id_to_igraph_id[target_node_id]) <span class="hljs-keyword">for</span> neighbor <span class="hljs-keyword">in</span> source_node_ids])<br><br><span class="hljs-comment"># 准备可视化设置字典并绘图</span><br>visual_style = &#123;<br>    <span class="hljs-string">&quot;edge_width&quot;</span>: attention_weights,  <span class="hljs-comment"># 使边缘尽可能粗</span><br>    <span class="hljs-string">&quot;layout&quot;</span>: ig_graph.layout_reingold_tilford_circular()  <span class="hljs-comment"># 树状图的布局</span><br>&#125;<br><span class="hljs-comment"># 这是唯一针对 Cora 的部分，因为 Cora 有 7 个标签</span><br><span class="hljs-keyword">if</span> dataset_name.lower() == DatasetType.CORA.name.lower():<br>    visual_style[<span class="hljs-string">&quot;vertex_color&quot;</span>] = [cora_label_to_color_map[label] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;为您特定的数据集添加自定义颜色方案。 使用 igraph 默认着色。&#x27;</span>)<br><br>ig.plot(ig_graph, **visual_style)<br><br></code></pre></td></tr></table></figure>

<pre><code class="hljs">***** 模型训练元数据: *****
commit_hash: 91fb864b8f9ddefd401bf5399cea779bd3c0a63b
dataset_name: CORA
num_of_epochs: 10000
test_acc: 0.822
num_of_layers: 2
num_heads_per_layer: [8, 1]
num_features_per_layer: [1433, 8, 7]
add_skip_connection: False
bias: True
dropout: 0.6
layer_type: IMP3
*********************

Highest degree nodes = [1986 1701  306 1358]
Max attention weight = 0.012915871106088161 and min = 0.012394174002110958


/var/folders/f0/812mfv7x63vbytjs3yf4gxtc0000gn/T/ipykernel_16269/2448994618.py:6: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.
  data = pickle.load(file)
</code></pre>
<p><img src="https://ptpimg.me/mv5zat.png" alt="请添加图片描述"><br><img src="https://ptpimg.me/855sl2.png" alt="请添加图片描述"><br><img src="https://ptpimg.me/kk5k1q.png" alt="请添加图片描述"><br><img src="https://ptpimg.me/02bw9r.png" alt="请添加图片描述"><br><img src="https://ptpimg.me/8c77s3.png" alt="请添加图片描述"><br><img src="https://ptpimg.me/6pt7d4.png" alt="请添加图片描述"><br><img src="https://ptpimg.me/6q14cf.png" alt="请添加图片描述"><br><img src="https://ptpimg.me/vdku0v.png" alt="请添加图片描述"></p>
<p>瞧，浅蓝色直方图（经过训练的 GAT）与橙色直方图（统一注意力 GAT）完全匹配。</p>
<p>如果之前绘制的边的厚度可视化不能让您信服，我相信熵可以！</p>
<p>这种可视化的想法来自Petar Veličković 向我推荐的<a href="https://www.dgl.ai/blog/2019/02/17/gat.html">这篇博客文章</a>。</p>
<hr>
<p>唷！！！完成了！如果你一直陪我到这里，恭喜你！（成就已解锁 - GAT大师😍）</p>
<p>建议花点时间分析一下这篇博客。这不是一个玩具项目，作者花了大约 3 周的时间才完成，所以不要指望在 30 分钟内理解所有内容，除非您真的熟悉这里提到的大多数概念。</p>
]]></content>
  </entry>
  <entry>
    <title>2021基于Debian的All in One（NAS+软路由）配置教程</title>
    <url>/2020/03/07/localnas/</url>
    <content><![CDATA[<p> @<a href="%E5%9F%BA%E4%BA%8EDebian10%E7%9A%84NAS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE">TOC</a></p>
<h1 id="系统概述"><a href="#系统概述" class="headerlink" title="系统概述"></a>系统概述</h1><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><ul>
<li>作为影迷，有一定的观影需求，同时也有兼职剪辑。考虑苹果新M1的macbook air的剪辑配置，唯一缺陷就是容量太小又不可拓展，所以搭配nas作为存储延伸。</li>
<li>为何选择Debian，因为作为计算机专业，折腾的过程也是学习的过程，linux可以有更多功能选择，不需要装虚拟机就能All in One <del>(boom)</del> ，可以做服务器，我写了一个网站可以挂在上面让大家访问。也可以做软路由，安装***等转发流量就可以全局。</li>
<li>该教程主要为提供思路，记录一些配置过程使用的命令，也作为自己备忘录，具体详细过程无法一一描述，若有建议或者疑问，欢迎大家一起讨论</li>
</ul>
<h2 id="功能实现"><a href="#功能实现" class="headerlink" title="功能实现"></a>功能实现</h2><ul>
<li>挂载硬盘作为nas存储视频等文件</li>
<li>部署网站供大家访问</li>
<li>作为软路由转发流量</li>
</ul>
<h1 id="系统配置简介"><a href="#系统配置简介" class="headerlink" title="系统配置简介"></a>系统配置简介</h1><ol>
<li>梅捷N3150L主板</li>
<li>CPU是N3150（4核6W支持AES 稍弱于J1900但可硬解4k）</li>
<li>4G内存1600HZ</li>
<li>8+14T机械硬盘</li>
<li>U盘16G作为系统盘</li>
<li>TP-link WiFi6的路由器进行DDNS和端口转发</li>
</ol>
<h1 id="Debian10的镜像下载与安装"><a href="#Debian10的镜像下载与安装" class="headerlink" title="Debian10的镜像下载与安装"></a>Debian10的镜像下载与安装</h1><ol>
<li>镜像链接:<a href="https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-10.9.0-amd64-netinst.iso">Debian原网站镜像</a></li>
<li>U盘工具:Ventory</li>
<li>用另一个U盘作为系统盘（可节约一个SATA接口</li>
</ol>
<h1 id="系统配置准备"><a href="#系统配置准备" class="headerlink" title="系统配置准备"></a>系统配置准备</h1><h2 id="oh-my-zsh安装"><a href="#oh-my-zsh安装" class="headerlink" title="oh my zsh安装"></a>oh my zsh安装</h2><p>装机第一件事就是要看得舒服</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt-get install zsh#安装zsh作为shell<br>chsh -s /bin/zsh#激活环境<br><br>sh -c &quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot;<br><span class="hljs-meta prompt_">#</span><span class="language-bash">个性化配置</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">可以记住历史目录，不需要一直<span class="hljs-built_in">cd</span> 如果卡住可能是需要认证rsa.pub的公钥 ssh-kengen生成一下，添加到github的设置-&gt;SSH and GPG keys</span><br>git clone https://github.com/joelthelion/autojump<br>cd autojump<br>./install.py<br><br>git clone https://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions#自动补全命令<br><br>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting#语法高亮<br><br>vim ~/.zshrc 把插件加到文件中<br></code></pre></td></tr></table></figure>
<p>vim ~&#x2F;.zshrc配置文件的plugins 加上autojump zsh-syntax-highlighting zsh-autosuggestions生效，最后再source ~&#x2F;.zshrc重新编译zsh，此时autojump已经生效。其他同理</p>
<h2 id="ssh远程访问"><a href="#ssh远程访问" class="headerlink" title="ssh远程访问"></a>ssh远程访问</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">cd /etc/ssh<br>nano sshd_config<br>//添加一行 PermitRootLogin yes<br>//ctrl x保存退出<br></code></pre></td></tr></table></figure>

<p>将#PasswordAuthentication no的注释去掉，并且将NO修改为YES<br>完成上述更改后，请重新启动SSH服务器：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/etc/init.d/ssh restart 或者service ssh start<br></code></pre></td></tr></table></figure>
<p>添加开机自启动 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">update-rc.d ssh enable<br></code></pre></td></tr></table></figure>
<h2 id="免明文登陆"><a href="#免明文登陆" class="headerlink" title="免明文登陆"></a>免明文登陆</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">ssh-keygen -t rsa<br>ssh-copy-id -i ~/.ssh/id_rsa root@ipp<br></code></pre></td></tr></table></figure>
<h2 id="开机自动登录root"><a href="#开机自动登录root" class="headerlink" title="开机自动登录root"></a>开机自动登录root</h2><ol>
<li>进入root用户，编辑文件&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;getty@.service<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">nano /lib/systemd/system/getty@.service<br>//ctrl x保存<br></code></pre></td></tr></table></figure></li>
<li>设置字段ExecStart</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">ExecStart=-/sbin/agetty --autologin root --noclear %I $TERM//添加或修改这行数据<br><br>//ctrl x保存<br></code></pre></td></tr></table></figure>

<h2 id="白嫖cloudflare的服务穿透内网，前提是需要域名"><a href="#白嫖cloudflare的服务穿透内网，前提是需要域名" class="headerlink" title="白嫖cloudflare的服务穿透内网，前提是需要域名"></a>白嫖cloudflare的服务穿透内网，前提是需要域名</h2><p><a href="https://bra.live/setup-home-server-with-cloudflare-tunnel/">参考链接</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">curl -L &#x27;https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64&#x27; -o /usr/bin/cloudflared<br>chmod +x /usr/bin/cloudflared<br><br>cloudflared tunnel login<br><span class="hljs-meta prompt_">#</span><span class="language-bash">然后会让打开浏览器登陆验证</span><br>A browser window should have opened at the following URL:<br><br>https://dash.cloudflare.com/arg***<br><span class="hljs-meta prompt_">#</span><span class="language-bash">注意：授权一次只能选择一个网站。如果存在多个不同域名的网站，请授权完成后不要关闭网页，点击第二个、第三个要授权的域名，进行多次授权。</span><br><br><br>cloudflared tunnel create &lt;隧道名字&gt;#比如 webserver-1<br><span class="hljs-meta prompt_">#</span><span class="language-bash">然后有uuid要记下</span><br>Tunnel credentials written to /root/.cloudflared/12345-123-123-123-12345.json. cloudflared chose this file based on where your origin certificate was found. Keep this file secret. To revoke these credentials, delete the tunnel.<br><br>Created tunnel webserver-1 with id 12345-123-123-123-12345<br><br>......<br></code></pre></td></tr></table></figure>
<h2 id="rclone使用"><a href="#rclone使用" class="headerlink" title="rclone使用"></a>rclone使用</h2><p>rclone不仅可以挂载网盘还能挂FTP、sftp等等，当作同步的工具也很不错，这里介绍下sftp的挂载</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">一键安装最新的版本，自带的比较老</span><br><br>sudo -v ; curl https://rclone.org/install.sh | sudo bash<br><br>ssh-keygen -q -t rsa -b 4096 -C &quot;rclone key&quot; -N &quot;&quot; -f ~/.ssh/rclone<br>cd ~/.ssh/<br>cat rclone* &gt; rclone-merged <br><span class="hljs-meta prompt_">#</span><span class="language-bash">配置除了地址账号密码这些一切都默认，除了下面这个</span><br><span class="hljs-meta prompt_">key_file&gt; </span><span class="language-bash">~/.ssh/rclone-merged</span><br><br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt install fuse3<br><br>rclone mount -vv alist: /alist --copy-links --no-gzip-encoding --no-check-certificate --allow-other --allow-non-empty --umask 000 --vfs-cache-mode writes  --daemon<br></code></pre></td></tr></table></figure>

<h2 id="Tailscale"><a href="#Tailscale" class="headerlink" title="Tailscale"></a>Tailscale</h2><ul>
<li>需要客户端，不是很方便<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">curl -fsSL https://tailscale.com/install.sh | sh<br>tailscale up<br></code></pre></td></tr></table></figure></li>
</ul>
<h2 id="图形化界面卸载"><a href="#图形化界面卸载" class="headerlink" title="图形化界面卸载"></a>图形化界面卸载</h2><p>图形化界面比较占内存，而我多数时候SSH也用不上，所以将其卸载</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt autoremove gdm3<br>apt autoremove --purge gnome*<br><br>//reboot重启<br></code></pre></td></tr></table></figure>

<h2 id="网路配置"><a href="#网路配置" class="headerlink" title="网路配置"></a>网路配置</h2><ol>
<li>向运营商申请外网IP，一般打电话就行(现在可能不容易了)</li>
<li>申请一个域名，我用的阿里的</li>
<li>因为拨号上网IP不会固定，所以需要路由器的DDNS通过域名绑定IP访问</li>
<li>在路由器的虚拟服务器上面设置端口转发，可以转发被禁的80或者443端口</li>
</ol>
<p>编辑设置：vim &#x2F;etc&#x2F;network&#x2F;interfaces</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">source /etc/network/interfaces.d/*<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">#总的来说是用的enp2s0网口，也就是外接的千兆网卡，分配静态ip</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">The loopback network interface</span><br>auto lo<br>iface lo inet loopback<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">The primary network interface</span><br>allow-hotplug enp2s0<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">#动态ip</span></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">iface enp3s0 inet dhcp</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">iface enp3s0 inet loopback</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">#静态ip</span></span><br>iface enp2s0 inet static<br>address 192.168.1.107<br><span class="hljs-meta prompt_">#</span><span class="language-bash">address 192.168.101.111</span><br>netmask 255.255.255.0<br>gateway 192.168.1.1<br>auto enp2s0<br></code></pre></td></tr></table></figure>

<h2 id="网络自动重连"><a href="#网络自动重连" class="headerlink" title="网络自动重连"></a>网络自动重连</h2><p>写了个脚本自动检测网络，断开则重连，下面是环境需要</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">pip install selenium<br>apt install chrome-driver<br>apt-get install -y libnss3-dev libgconf-2-4 xvfb<br></code></pre></td></tr></table></figure>

<h2 id="磁盘相关命令"><a href="#磁盘相关命令" class="headerlink" title="磁盘相关命令"></a>磁盘相关命令</h2><ol>
<li>磁盘分区 <figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">fdisk -l<br>//查看所有磁盘信息<br>fdisk  /dev/sdb<br>//对sdb磁盘进行分区<br></code></pre></td></tr></table></figure>
 若磁盘大于2T，需要parted命令分区  <figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"> parted /dev/sdb  //分区磁盘sdb<br> mklabel gpt  //parted命令只能针对gpt格式的磁盘进行操作 <br> mkpart ext4 0% 1.5T//将0到1.5T划为一个分区<br>(parted) p //查看所有磁盘信息<br>mkfs -t ext4 /dev/sdb1   //格式化分区sdb1<br></code></pre></td></tr></table></figure></li>
<li>查看当前已挂载磁盘<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">df -h<br></code></pre></td></tr></table></figure></li>
<li>挂载磁盘<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">mount /dev/sdb1 /mnt/fodername1<br>//将磁盘sdb1挂载到相同的逻辑文件/data下，卸载则换为umount<br></code></pre></td></tr></table></figure></li>
<li>开机自动挂载磁盘<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"> vim /etc/fstab<br> //打开fstab文件写入命令<br> UUID=b394c406-5c0e-4e16-9d80-a212c34a8d32 /mnt            ext4    defaults   0<br>/dev/sdb1                               /mnt/Film             ext4              defaults 0<br>/dev/sdb2                               /mnt/Material   		ext4            defaults 0<br><br> <br></code></pre></td></tr></table></figure></li>
<li>磁盘通电时间等详细参数<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt-get install smartmontools<br>//下载磁盘测试工具<br>smartctl -A /dev/sdb<br>//测试sda磁盘<br></code></pre></td></tr></table></figure></li>
<li>磁盘读写速度<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">hdparm -Tt /dev/sda<br>//sda换为测试的硬盘<br></code></pre></td></tr></table></figure></li>
<li>磁盘清理查看<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt install ncdu<br>ncdu / --exclude /foldername<br> //可按照文件占用大小排序查看<br></code></pre></td></tr></table></figure></li>
</ol>
<h1 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h1><h3 id="Docker安装"><a href="#Docker安装" class="headerlink" title="Docker安装"></a>Docker安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">curl -fsSL https://get.docker.com -o get-docker.sh<br>sh get-docker.sh<br></code></pre></td></tr></table></figure>
<h4 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h4><p>比起virtualenv，conda最大优点是可以自动安装指定新版本python，不用本地环境</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">wget -4 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-py39_4.9.2-Linux-x86_64.sh<br><span class="hljs-meta prompt_">#</span><span class="language-bash">第二步安装</span><br>sh Miniconda3-py39_4.9.2-Linux-x86_64.sh -b -p /root/miniconda3<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">第三步配置conda镜像</span><br><br>export PATH=/root/miniconda3/bin:$PATH<br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">alias</span> ohmyzsh=<span class="hljs-string">&quot;mate ~/.oh-my-zsh&quot;</span></span><br><br>vim ~/.zshrc<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment"># 添加下面的内容</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">&gt;&gt;&gt; conda initialize &gt;&gt;&gt;</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">!! Contents within this block are managed by <span class="hljs-string">&#x27;conda init&#x27;</span> !!</span><br>__conda_setup=&quot;$(&#x27;/root/miniconda3/bin/conda&#x27; &#x27;shell.zsh&#x27; &#x27;hook&#x27; 2&gt; /dev/null)&quot;<br>if [ $? -eq 0 ]; then<br>    eval &quot;$__conda_setup&quot;<br>else<br>    if [ -f &quot;/root/miniconda3/etc/profile.d/conda.sh&quot; ]; then<br>        . &quot;/root/miniconda3/etc/profile.d/conda.sh&quot;<br>    else<br>        export PATH=&quot;/root/miniconda3/bin:$PATH&quot;<br>    fi<br>fi<br>unset __conda_setup<br><span class="hljs-meta prompt_"># </span><span class="language-bash">&lt;&lt;&lt; <span class="hljs-string">conda initialize &lt;&lt;&lt;</span></span><br><br>source ~/.zshrc<br><br>conda create -n py39 python=3.9<br>conda activate py39<br></code></pre></td></tr></table></figure>
<h4 id="Jupyter-lab"><a href="#Jupyter-lab" class="headerlink" title="Jupyter lab"></a>Jupyter lab</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">conda install jupyterlab<br><span class="hljs-meta prompt_">#</span><span class="language-bash">创建密码</span><br>jupyter lab password<br><span class="hljs-meta prompt_">#</span><span class="language-bash">生成配置文件</span><br>jupyter lab --generate-config<br><span class="hljs-meta prompt_">#</span><span class="language-bash">编辑文件</span><br>vim /root/.jupyter/jupyter_lab_config.py<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">#修改下面的</span></span><br>c.ServerApp.root_dir = &#x27;&#x27;                  # 设置默认工作目录<br>c.ServerApp.ip = &#x27;*&#x27;                     # 允许访问此服务器的 IP，星号表示任意 IP<br>c.ServerApp.password = &#x27;****************&#x27; # 之前生成的密码 hash 字串在/root/.jupyter/jupyter_server_config.json, 粘贴进去<br>c.ServerApp.open_browser = False         # 运行时不打开本机浏览器<br>c.ServerApp.port = 8888                  # 使用的端口，随意设置，但是要记得你设定的这个端口<br>c.ServerApp.enable_mathjax = True        # 启用 MathJax<br>c.ServerApp.allow_remote_access = True   # 允许远程访问<br>c.ServerApp.allow_root = True            # 允许root权限<br></code></pre></td></tr></table></figure>
<h2 id="Jellyfin安装配置"><a href="#Jellyfin安装配置" class="headerlink" title="Jellyfin安装配置"></a>Jellyfin安装配置</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">docker pull nyanmisaka/jellyfin<br><br>docker run -d -p 8096:8096 -v /jellyfin/config:/config -v /mnt/AllMedia:/media -v /mnt/Other:/Film3 -v /mnt/Film:/Film2 --restart=always nyanmisaka/jellyfin<br></code></pre></td></tr></table></figure>
<ol>
<li>-p 后面是jellyfin服务的端口号，安装时可以指定，这里使用默认的8096；</li>
<li>-v 后面是指定的配置路径，比如 &#x2F;mnt&#x2F;film 就是我原来的影音物理路径，&#x2F;media就是jellyfin的映射路径</li>
<li>可以通过http:&#x2F;&#x2F;本地ip:8096 来访问jellyfin服务了,后期也可以转发端口在外网用域名访问</li>
</ol>
<h2 id="Samba安装配置"><a href="#Samba安装配置" class="headerlink" title="Samba安装配置"></a>Samba安装配置</h2><p>Debian终端</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt install samba<br><br>nano /etc/samba/smb.conf<br><br>//最后加上<br>[share]<br>comment = Provides Filesystem For Anyone<br>path = /share<br>browsable = yes<br>create mask = 0777<br>directory mask = 0777<br>read only = no<br>writable = yes<br>guest ok = yes<br>public = yes<br>forceuser=root<br>forcegroup=root<br><br>//创建共享目录并设置权限<br>mkdir /share<br>chmod -R 0777 /share<br>//客户端<br>apt install smbclient<br>//重启服务<br>systemctl restart smbd.service &amp;&amp; systemctl restart nmbd.service<br></code></pre></td></tr></table></figure>
<p>Windows终端</p>
<p>打开我的电脑，地址栏输入 \192.168.<em><strong>.</strong></em> （NAS所在局域网IP）会看到几个文件名</p>
<ul>
<li>注意，window上面映射地址不是挂载地址，而必须与上面文件累的path路径名称（&#x2F;share）完全一致，包括大小写，不然会提示拼写错误</li>
<li>iPad也可用nPlayer的SMB配置访问这个地址</li>
</ul>
<h2 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h2><p>Samba配置太繁琐了，现在也不用Windows</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt-get install nfs-kernel-server <br>apt-get install nfs-common   #MAC客户端自带，可不用安装<br><br>vim /etc/exports<br><span class="hljs-meta prompt_">#</span><span class="language-bash">添加 *代表所有ip访问</span><br>/mnt *(rw,fsid=0,sync,no_root_squash,no_subtree_check,insecure)<br><br>/mnt/Other *(rw,sync,no_root_squash,no_subtree_check,insecure)<br>/mnt/AllMedia *(rw,sync,no_subtree_check,no_root_squash,insecure)<br>systemctl restart nfs-kernel-service#重启nfs服务<br><span class="hljs-meta prompt_">#</span><span class="language-bash">Mac挂载命令</span><br>mount -t nfs -o nolocks 192.168.101.111:/mnt /Users/gawaintan/NAS<br><br></code></pre></td></tr></table></figure>
<p>注意：*代表所有ip都允许访问，&#x2F;mnt作为父级目录fsid&#x3D;0只能出现一次，no_root_squash授予root权限，谨慎使用，insecure为了我避免客户端permission denied</p>
<h2 id="网口"><a href="#网口" class="headerlink" title="网口"></a>网口</h2><p>我买了块千兆网卡，但是装机插另一个网口了，导致开机默认不启动<br>所以需要设置一下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">vim /etc/network/interfaces<br><br>auto enp2s0   #设置网卡自启动<br>iface wlan0 inet static    #设置网卡使用静态IP<br>address 192.168.101.111<br>netmask 255.255.255.0<br>gateway 192.168.101.1<br></code></pre></td></tr></table></figure>

<h2 id="安装配置aria2"><a href="#安装配置aria2" class="headerlink" title="安装配置aria2"></a>安装配置aria2</h2><p>…不怎么用了</p>
<h2 id="mysql安装配置"><a href="#mysql安装配置" class="headerlink" title="mysql安装配置"></a>mysql安装配置</h2><p>在Debian的默认存储库中不可用，MariaDB是Debian 10中的默认数据库系统，我将介绍如何安装mysql8</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">wget http://repo.mysql.com/mysql-apt-config_0.8.13-1_all.deb <br><span class="hljs-meta prompt_">#</span><span class="language-bash">下载完成后，以具有<span class="hljs-built_in">sudo</span>权限的用户身份安装发行包：</span><br>apt install ./mysql-apt-config_0.8.13-1_all.deb<br><span class="hljs-meta prompt_">#</span><span class="language-bash">选择MySQL Server &amp; Cluster(当前选择：mysql-8.0)确定安装</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">通过运行以下命令更新包列表并安装MySQL服务器包：</span><br>sudo apt update<br>sudo apt install mysql-server<br></code></pre></td></tr></table></figure>
<p>等待安装，完成后用 systemctl status mysql检验安装是否成功<br>运行mysql_secure_installation设置密码，按照喜好选择Y<br>mysql -u root -p输入设置，密码登陆</p>
<h2 id="软路由流量分发"><a href="#软路由流量分发" class="headerlink" title="软路由流量分发"></a>软路由流量分发</h2><h1 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h1><h2 id="局域网网速测试"><a href="#局域网网速测试" class="headerlink" title="局域网网速测试"></a>局域网网速测试</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">Linux端</span><br>apt-get install iperf3<br>iperf3 -s#将linux作为服务器端<br><span class="hljs-meta prompt_">#</span><span class="language-bash">windows端,官网下载iperf3，cmd命令到该目录下</span><br>Iperf3 -c 192.168.101.119<br><br></code></pre></td></tr></table></figure>


<h2 id="网络端口查看"><a href="#网络端口查看" class="headerlink" title="网络端口查看"></a>网络端口查看</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt-get install net-tools #新的系统可能不带该命令，也无法通过install ifconfig下载，只能用该命令<br><br>ethtool enp2s0#查看网口信息<br><br></code></pre></td></tr></table></figure>

<h2 id="screen命令的使用"><a href="#screen命令的使用" class="headerlink" title="screen命令的使用"></a>screen命令的使用</h2><p>方便切换进程，可以在一个进程未完成的时候将其挂起</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">screen<br>screen -ls#展示所有进程<br>screen -d id#detach该进程，可用切换远程终端访问<br>screen -r id #进入该进程<br><br></code></pre></td></tr></table></figure>

<h2 id="定时自动关机"><a href="#定时自动关机" class="headerlink" title="定时自动关机"></a>定时自动关机</h2><p>因为寝室0:30停电，然后设置了主办来电自动开机</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">vim /etc/crontab<br><span class="hljs-meta prompt_">#</span><span class="language-bash">最后添加一行代表0:22自动关机</span><br>22  0    * * *   root    /sbin/halt<br><br></code></pre></td></tr></table></figure>
<h2 id="开机启动管理工具"><a href="#开机启动管理工具" class="headerlink" title="开机启动管理工具"></a>开机启动管理工具</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">apt-get install sysv-rc-conf<br>sysv-rc-conf --level 345 mysql on #mysql可换其他服务<br><span class="hljs-meta prompt_">sysv-rc-conf#</span><span class="language-bash">可查看选择启动权限</span><br></code></pre></td></tr></table></figure>
<p><img src="https://ptpimg.me/83u06a.jpg" alt="请添加图片描述"></p>
<h2 id="小工具集合"><a href="#小工具集合" class="headerlink" title="小工具集合"></a>小工具集合</h2><ol>
<li>htop用于观察系统占用资源情况</li>
<li>ncdu &#x2F;目录 可将该目录下所有文件从大到小排序</li>
</ol>
<h2 id="Alist"><a href="#Alist" class="headerlink" title="Alist"></a>Alist</h2><p><a href="https://alist.nn.ci/zh/guide/install/script.html">https://alist.nn.ci/zh/guide/install/script.html</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><br>curl -fsSL &quot;https://alist.nn.ci/v3.sh&quot; | bash -s install<br></code></pre></td></tr></table></figure>


]]></content>
  </entry>
  <entry>
    <title>斯坦福汽车识别</title>
    <url>/2022/11/07/StanfordCars/</url>
    <content><![CDATA[<h1 id="斯坦福汽车分类"><a href="#斯坦福汽车分类" class="headerlink" title="斯坦福汽车分类"></a>斯坦福汽车分类</h1><p>这是一个使用斯坦福汽车数据集进行汽车分类的深度学习项目。我将使用迁移学习在ImageNet上预训练的深度网络，并对数据集进行微调，为了减少训练时间我把数据集。</p>
<p>数据来源：<a href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html">https://ai.stanford.edu/~jkrause/cars/car_dataset.html</a></p>
<h1 id="1-数据描述"><a href="#1-数据描述" class="headerlink" title="1. 数据描述"></a>1. 数据描述</h1><p>斯坦福汽车数据集包含 195 类汽车的 16,185 张图像。数据被分成 8,144 张训练图像和 8,041 张测试图像，每个类也被分成大约 50-50。类通常处于品牌、型号和年份级别，例如。2012 款特斯拉 Model S 或 2012 款宝马 M3 轿跑车。平均而言，训练集中每个类别有 41.5 张图像，测试集中有 40.5 张图像。</p>
<h1 id="2-设置环境并加载数据"><a href="#2-设置环境并加载数据" class="headerlink" title="2. 设置环境并加载数据"></a>2. 设置环境并加载数据</h1><h2 id="2-1-下载读取数据"><a href="#2-1-下载读取数据" class="headerlink" title="2.1 下载读取数据"></a>2.1 下载读取数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#提取类别名：</span><br><span class="hljs-keyword">import</span> scipy.io<br> <br>data = scipy.io.loadmat(<span class="hljs-string">&#x27;data/cars_annos.mat&#x27;</span>)<br>class_names = data[<span class="hljs-string">&#x27;class_names&#x27;</span>]<br>f_class = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./label_map.txt&#x27;</span>,<span class="hljs-string">&#x27;w&#x27;</span>)<br> <br>num = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(class_names.shape[<span class="hljs-number">1</span>]):<br>    class_name = <span class="hljs-built_in">str</span>(class_names[<span class="hljs-number">0</span>,j][<span class="hljs-number">0</span>]).replace(<span class="hljs-string">&#x27; &#x27;</span>,<span class="hljs-string">&#x27;_&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(num,class_name)<br>    f_class.write( <span class="hljs-built_in">str</span>(num) + <span class="hljs-string">&#x27; &#x27;</span> + class_name + <span class="hljs-string">&#x27;\n&#x27;</span>)<br>    num = num + <span class="hljs-number">1</span><br>f_class.close()<br><br><br></code></pre></td></tr></table></figure>

<pre><code class="hljs">1 AM_General_Hummer_SUV_2000
2 Acura_RL_Sedan_2012
3 Acura_TL_Sedan_2012
4 Acura_TL_Type-S_2008
5 Acura_TSX_Sedan_2012
6 Acura_Integra_Type_R_2001
7 Acura_ZDX_Hatchback_2012
8 Aston_Martin_V8_Vantage_Convertible_2012
9 Aston_Martin_V8_Vantage_Coupe_2012
10 Aston_Martin_Virage_Convertible_2012
11 Aston_Martin_Virage_Coupe_2012
12 Audi_RS_4_Convertible_2008
13 Audi_A5_Coupe_2012
14 Audi_TTS_Coupe_2012
15 Audi_R8_Coupe_2012
16 Audi_V8_Sedan_1994
17 Audi_100_Sedan_1994
18 Audi_100_Wagon_1994
19 Audi_TT_Hatchback_2011
20 Audi_S6_Sedan_2011
21 Audi_S5_Convertible_2012
22 Audi_S5_Coupe_2012
23 Audi_S4_Sedan_2012
24 Audi_S4_Sedan_2007
25 Audi_TT_RS_Coupe_2012
26 BMW_ActiveHybrid_5_Sedan_2012
27 BMW_1_Series_Convertible_2012
28 BMW_1_Series_Coupe_2012
29 BMW_3_Series_Sedan_2012
30 BMW_3_Series_Wagon_2012
31 BMW_6_Series_Convertible_2007
32 BMW_X5_SUV_2007
33 BMW_X6_SUV_2012
34 BMW_M3_Coupe_2012
35 BMW_M5_Sedan_2010
36 BMW_M6_Convertible_2010
37 BMW_X3_SUV_2012
38 BMW_Z4_Convertible_2012
39 Bentley_Continental_Supersports_Conv._Convertible_2012
40 Bentley_Arnage_Sedan_2009
41 Bentley_Mulsanne_Sedan_2011
42 Bentley_Continental_GT_Coupe_2012
43 Bentley_Continental_GT_Coupe_2007
44 Bentley_Continental_Flying_Spur_Sedan_2007
45 Bugatti_Veyron_16.4_Convertible_2009
46 Bugatti_Veyron_16.4_Coupe_2009
47 Buick_Regal_GS_2012
48 Buick_Rainier_SUV_2007
49 Buick_Verano_Sedan_2012
50 Buick_Enclave_SUV_2012
51 Cadillac_CTS-V_Sedan_2012
52 Cadillac_SRX_SUV_2012
53 Cadillac_Escalade_EXT_Crew_Cab_2007
54 Chevrolet_Silverado_1500_Hybrid_Crew_Cab_2012
55 Chevrolet_Corvette_Convertible_2012
56 Chevrolet_Corvette_ZR1_2012
57 Chevrolet_Corvette_Ron_Fellows_Edition_Z06_2007
58 Chevrolet_Traverse_SUV_2012
59 Chevrolet_Camaro_Convertible_2012
60 Chevrolet_HHR_SS_2010
61 Chevrolet_Impala_Sedan_2007
62 Chevrolet_Tahoe_Hybrid_SUV_2012
63 Chevrolet_Sonic_Sedan_2012
64 Chevrolet_Express_Cargo_Van_2007
65 Chevrolet_Avalanche_Crew_Cab_2012
66 Chevrolet_Cobalt_SS_2010
67 Chevrolet_Malibu_Hybrid_Sedan_2010
68 Chevrolet_TrailBlazer_SS_2009
69 Chevrolet_Silverado_2500HD_Regular_Cab_2012
70 Chevrolet_Silverado_1500_Classic_Extended_Cab_2007
71 Chevrolet_Express_Van_2007
72 Chevrolet_Monte_Carlo_Coupe_2007
73 Chevrolet_Malibu_Sedan_2007
74 Chevrolet_Silverado_1500_Extended_Cab_2012
75 Chevrolet_Silverado_1500_Regular_Cab_2012
76 Chrysler_Aspen_SUV_2009
77 Chrysler_Sebring_Convertible_2010
78 Chrysler_Town_and_Country_Minivan_2012
79 Chrysler_300_SRT-8_2010
80 Chrysler_Crossfire_Convertible_2008
81 Chrysler_PT_Cruiser_Convertible_2008
82 Daewoo_Nubira_Wagon_2002
83 Dodge_Caliber_Wagon_2012
84 Dodge_Caliber_Wagon_2007
85 Dodge_Caravan_Minivan_1997
86 Dodge_Ram_Pickup_3500_Crew_Cab_2010
87 Dodge_Ram_Pickup_3500_Quad_Cab_2009
88 Dodge_Sprinter_Cargo_Van_2009
89 Dodge_Journey_SUV_2012
90 Dodge_Dakota_Crew_Cab_2010
91 Dodge_Dakota_Club_Cab_2007
92 Dodge_Magnum_Wagon_2008
93 Dodge_Challenger_SRT8_2011
94 Dodge_Durango_SUV_2012
95 Dodge_Durango_SUV_2007
96 Dodge_Charger_Sedan_2012
97 Dodge_Charger_SRT-8_2009
98 Eagle_Talon_Hatchback_1998
99 FIAT_500_Abarth_2012
100 FIAT_500_Convertible_2012
101 Ferrari_FF_Coupe_2012
102 Ferrari_California_Convertible_2012
103 Ferrari_458_Italia_Convertible_2012
104 Ferrari_458_Italia_Coupe_2012
105 Fisker_Karma_Sedan_2012
106 Ford_F-450_Super_Duty_Crew_Cab_2012
107 Ford_Mustang_Convertible_2007
108 Ford_Freestar_Minivan_2007
109 Ford_Expedition_EL_SUV_2009
110 Ford_Edge_SUV_2012
111 Ford_Ranger_SuperCab_2011
112 Ford_GT_Coupe_2006
113 Ford_F-150_Regular_Cab_2012
114 Ford_F-150_Regular_Cab_2007
115 Ford_Focus_Sedan_2007
116 Ford_E-Series_Wagon_Van_2012
117 Ford_Fiesta_Sedan_2012
118 GMC_Terrain_SUV_2012
119 GMC_Savana_Van_2012
120 GMC_Yukon_Hybrid_SUV_2012
121 GMC_Acadia_SUV_2012
122 GMC_Canyon_Extended_Cab_2012
123 Geo_Metro_Convertible_1993
124 HUMMER_H3T_Crew_Cab_2010
125 HUMMER_H2_SUT_Crew_Cab_2009
126 Honda_Odyssey_Minivan_2012
127 Honda_Odyssey_Minivan_2007
128 Honda_Accord_Coupe_2012
129 Honda_Accord_Sedan_2012
130 Hyundai_Veloster_Hatchback_2012
131 Hyundai_Santa_Fe_SUV_2012
132 Hyundai_Tucson_SUV_2012
133 Hyundai_Veracruz_SUV_2012
134 Hyundai_Sonata_Hybrid_Sedan_2012
135 Hyundai_Elantra_Sedan_2007
136 Hyundai_Accent_Sedan_2012
137 Hyundai_Genesis_Sedan_2012
138 Hyundai_Sonata_Sedan_2012
139 Hyundai_Elantra_Touring_Hatchback_2012
140 Hyundai_Azera_Sedan_2012
141 Infiniti_G_Coupe_IPL_2012
142 Infiniti_QX56_SUV_2011
143 Isuzu_Ascender_SUV_2008
144 Jaguar_XK_XKR_2012
145 Jeep_Patriot_SUV_2012
146 Jeep_Wrangler_SUV_2012
147 Jeep_Liberty_SUV_2012
148 Jeep_Grand_Cherokee_SUV_2012
149 Jeep_Compass_SUV_2012
150 Lamborghini_Reventon_Coupe_2008
151 Lamborghini_Aventador_Coupe_2012
152 Lamborghini_Gallardo_LP_570-4_Superleggera_2012
153 Lamborghini_Diablo_Coupe_2001
154 Land_Rover_Range_Rover_SUV_2012
155 Land_Rover_LR2_SUV_2012
156 Lincoln_Town_Car_Sedan_2011
157 MINI_Cooper_Roadster_Convertible_2012
158 Maybach_Landaulet_Convertible_2012
159 Mazda_Tribute_SUV_2011
160 McLaren_MP4-12C_Coupe_2012
161 Mercedes-Benz_300-Class_Convertible_1993
162 Mercedes-Benz_C-Class_Sedan_2012
163 Mercedes-Benz_SL-Class_Coupe_2009
164 Mercedes-Benz_E-Class_Sedan_2012
165 Mercedes-Benz_S-Class_Sedan_2012
166 Mercedes-Benz_Sprinter_Van_2012
167 Mitsubishi_Lancer_Sedan_2012
168 Nissan_Leaf_Hatchback_2012
169 Nissan_NV_Passenger_Van_2012
170 Nissan_Juke_Hatchback_2012
171 Nissan_240SX_Coupe_1998
172 Plymouth_Neon_Coupe_1999
173 Porsche_Panamera_Sedan_2012
174 Ram_C/V_Cargo_Van_Minivan_2012
175 Rolls-Royce_Phantom_Drophead_Coupe_Convertible_2012
176 Rolls-Royce_Ghost_Sedan_2012
177 Rolls-Royce_Phantom_Sedan_2012
178 Scion_xD_Hatchback_2012
179 Spyker_C8_Convertible_2009
180 Spyker_C8_Coupe_2009
181 Suzuki_Aerio_Sedan_2007
182 Suzuki_Kizashi_Sedan_2012
183 Suzuki_SX4_Hatchback_2012
184 Suzuki_SX4_Sedan_2012
185 Tesla_Model_S_Sedan_2012
186 Toyota_Sequoia_SUV_2012
187 Toyota_Camry_Sedan_2012
188 Toyota_Corolla_Sedan_2012
189 Toyota_4Runner_SUV_2012
190 Volkswagen_Golf_Hatchback_2012
191 Volkswagen_Golf_Hatchback_1991
192 Volkswagen_Beetle_Hatchback_2012
193 Volvo_C30_Hatchback_2012
194 Volvo_240_Sedan_1993
195 Volvo_XC90_SUV_2007
196 smart_fortwo_Convertible_2012
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#提取 序号, 图片名, 类别, 属于测试集还是训练集(0,1表示)</span><br><span class="hljs-keyword">import</span> scipy.io<br> <br>data = scipy.io.loadmat(<span class="hljs-string">&#x27;data/cars_annos.mat&#x27;</span>)<br>annotations = data[<span class="hljs-string">&#x27;annotations&#x27;</span>]<br>f_train = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/mat2txt.txt&#x27;</span>,<span class="hljs-string">&#x27;w&#x27;</span>)<br><br>num = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(annotations.shape[<span class="hljs-number">1</span>]):<br>    name = <span class="hljs-built_in">str</span>(annotations[<span class="hljs-number">0</span>,i][<span class="hljs-number">0</span>])[<span class="hljs-number">2</span>:-<span class="hljs-number">2</span>]<br>    test  = <span class="hljs-built_in">int</span>(annotations[<span class="hljs-number">0</span>,i][<span class="hljs-number">6</span>])<br>    clas = <span class="hljs-built_in">int</span>(annotations[<span class="hljs-number">0</span>,i][<span class="hljs-number">5</span>])<br><br>    name = <span class="hljs-built_in">str</span>(name)<br>    clas = <span class="hljs-built_in">str</span>(clas)<br>    test = <span class="hljs-built_in">str</span>(test)<br>    f_train.write(<span class="hljs-built_in">str</span>(num) + <span class="hljs-string">&#x27; &#x27;</span> + name + <span class="hljs-string">&#x27; &#x27;</span> + clas + <span class="hljs-string">&#x27; &#x27;</span> + test+<span class="hljs-string">&#x27;\n&#x27;</span>)<br>    num = num + <span class="hljs-number">1</span><br> <br>f_train.close()<br><br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#按分类重写文件夹</span><br><span class="hljs-comment"># coding=utf-8</span><br><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> scipy.io <span class="hljs-keyword">as</span> scio<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cub2dang</span>():<br>    <span class="hljs-keyword">if</span> sys.getdefaultencoding() != <span class="hljs-string">&#x27;utf-8&#x27;</span>:<br>        reload(sys)<br>        sys.setdefaultencoding(<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>    data = scio.loadmat(<span class="hljs-string">&#x27;data/cars_annos.mat&#x27;</span>)<br>   <br>    newPath_train = <span class="hljs-string">&quot;data/train&quot;</span><br>    newPath_test = <span class="hljs-string">&quot;data/test&quot;</span><br>    images = data[<span class="hljs-string">&#x27;annotations&#x27;</span>][<span class="hljs-number">0</span>]<br>    classes = data[<span class="hljs-string">&#x27;class_names&#x27;</span>][<span class="hljs-number">0</span>]<br>    num_images = images.size<br>    <span class="hljs-built_in">print</span>(num_images)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">int</span>(num_images/<span class="hljs-number">2</span>)):<br>        <br>        image_path = os.path.join(<span class="hljs-string">&#x27;data/&#x27;</span>,images[i][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])<br>        <br>        file_name = images[i][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]  <span class="hljs-comment"># 文件名</span><br>        file_name = file_name.split(<span class="hljs-string">&#x27;/&#x27;</span>)[<span class="hljs-number">1</span>].encode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>        classid = images[i][<span class="hljs-number">5</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]  <span class="hljs-comment"># 类别</span><br>        <span class="hljs-comment"># classid=np.array2string(classid)</span><br>        classid = classid.astype(np.int32)<br>        <span class="hljs-built_in">id</span> = classes[classid-<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]<br>        file_name_new = os.path.join(<span class="hljs-built_in">id</span>, file_name.decode())<br><br>        istest = images[i][<span class="hljs-number">6</span>][<span class="hljs-number">0</span>]  <span class="hljs-comment"># train/test</span><br>        <span class="hljs-keyword">if</span> istest:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(os.path.join(newPath_test, <span class="hljs-built_in">id</span>)):<br>                os.makedirs(os.path.join(newPath_test, <span class="hljs-built_in">id</span>))<br>            shutil.copy(image_path, os.path.join(newPath_test, file_name_new))<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/car_test.txt&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                f.write(<span class="hljs-string">&#x27;&#123;&#125; &#123;&#125;\n&#x27;</span>.<span class="hljs-built_in">format</span>(file_name_new, classid))<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> istest:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(os.path.join(newPath_train, <span class="hljs-built_in">id</span>)):<br>                os.makedirs(os.path.join(newPath_train, <span class="hljs-built_in">id</span>))<br>            shutil.copy(image_path, os.path.join(newPath_train, file_name_new))<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/car_train.txt&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                f.write(<span class="hljs-string">&#x27;&#123;&#125; &#123;&#125;\n&#x27;</span>.<span class="hljs-built_in">format</span>(file_name_new, classid))<br>    <span class="hljs-built_in">print</span>(i)<br>cub2dang()<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">16185
8091
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment">#!python -m pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu                                                                                                    ✔  14:46:26</span><br><span class="hljs-comment">#!pip install torchvision==0.14.0</span><br><br></code></pre></td></tr></table></figure>

<h2 id="2-2-导入包"><a href="#2-2-导入包" class="headerlink" title="2.2 导入包"></a>2.2 导入包</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> PIL.Image <span class="hljs-keyword">as</span> Image<br><span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> display<br><br><span class="hljs-comment">#print(torch.backends.mps.is_built())</span><br>device = torch.device(<span class="hljs-string">&quot;mps&quot;</span>)<br><span class="hljs-built_in">print</span>(device)<br><br><span class="hljs-comment">#print(torch.cuda.get_device_name(device))</span><br></code></pre></td></tr></table></figure>

<pre><code class="hljs">mps
</code></pre>
<h1 id="3-建模"><a href="#3-建模" class="headerlink" title="3. 建模"></a>3. 建模</h1><h2 id="3-1-加载数据"><a href="#3-1-加载数据" class="headerlink" title="3.1 加载数据"></a>3.1 加载数据</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">dataset_dir = <span class="hljs-string">&quot;data/&quot;</span><br><br><br>width, height = <span class="hljs-number">224</span>, <span class="hljs-number">224</span><br>train_tfms = transforms.Compose([transforms.Resize((width, height)),<br>                                 torchvision.transforms.AutoAugment(),<br>                                 transforms.RandomHorizontalFlip(),<br>                                 transforms.RandomRotation(<span class="hljs-number">15</span>),<br>                                 transforms.ToTensor(),<br>                                 transforms.Normalize([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])])<br>test_tfms = transforms.Compose([transforms.Resize((width, height)),<br>                                transforms.ToTensor(),<br>                                transforms.Normalize([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># create datasets</span><br>dataset = torchvision.datasets.ImageFolder(root = dataset_dir + <span class="hljs-string">&quot;train&quot;</span>, transform = train_tfms)<br>trainloader = torch.utils.data.DataLoader(dataset, batch_size = <span class="hljs-number">32</span>, shuffle = <span class="hljs-literal">True</span>, num_workers = <span class="hljs-number">2</span>)<br><br>dataset2 = torchvision.datasets.ImageFolder(root = dataset_dir + <span class="hljs-string">&quot;test&quot;</span>, transform = test_tfms)<br>testloader = torch.utils.data.DataLoader(dataset2, batch_size = <span class="hljs-number">32</span>, shuffle = <span class="hljs-literal">False</span>, num_workers = <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>

<h2 id="3-2-定义训练模型函数"><a href="#3-2-定义训练模型函数" class="headerlink" title="3.2 定义训练模型函数"></a>3.2 定义训练模型函数</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_model</span>(<span class="hljs-params">model, criterion, optimizer, scheduler, n_epochs=<span class="hljs-number">5</span></span>):<br>    <br>  losses = []<br>  accuracies = []<br>  test_accuracies = []<br><br>  <span class="hljs-comment"># 将模型初始化设为训练模式</span><br>  model.train()<br>  <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> tqdm.tqdm(<span class="hljs-built_in">range</span>(n_epochs)):<br>    since = time.time()<br>    running_loss = <span class="hljs-number">0.0</span><br>    running_correct = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader, <span class="hljs-number">0</span>):<br><br>      <span class="hljs-comment"># 获取输入并将其分配给mps</span><br>      inputs, labels = data<br>      inputs = inputs.to(device)<br>      labels = labels.to(device)<br>      optimizer.zero_grad()<br>            <br>      <span class="hljs-comment"># forward + backward + optimize</span><br>      outputs = model(inputs)<br>      _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>      loss = criterion(outputs, labels)<br>      loss.backward()<br>      optimizer.step()<br>            <br>      <span class="hljs-comment"># 计算loss/acc </span><br>      running_loss += loss.item()<br>      running_correct += (labels == predicted).<span class="hljs-built_in">sum</span>().item()<br><br>    epoch_duration = time.time() - since<br>    epoch_loss = running_loss / <span class="hljs-built_in">len</span>(trainloader)<br>    epoch_acc = <span class="hljs-number">100</span> / <span class="hljs-number">32</span> * running_correct / <span class="hljs-built_in">len</span>(trainloader)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch %s, duration: %d s, loss: %.4f, acc: %.4f&quot;</span> % (epoch + <span class="hljs-number">1</span>, epoch_duration, epoch_loss, epoch_acc))<br>        <br>    losses.append(epoch_loss)<br>    accuracies.append(epoch_acc)<br>        <br>    <span class="hljs-comment"># 将模式转化为评估模式使用test数据集</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    test_acc = eval_model(model)<br>    test_accuracies.append(test_acc)<br>        <br>    <span class="hljs-comment"># 在验证后将模式改回训练</span><br>    model.train()<br>    scheduler.step(test_acc)<br>    <br>    since = time.time()<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br>  <span class="hljs-keyword">return</span> model, losses, accuracies, test_accuracies<br></code></pre></td></tr></table></figure>

<h2 id="3-3-定义模型评价函数"><a href="#3-3-定义模型评价函数" class="headerlink" title="3.3 定义模型评价函数"></a>3.3 定义模型评价函数</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">eval_model</span>(<span class="hljs-params">model</span>):<br>  correct = <span class="hljs-number">0.0</span><br>  total = <span class="hljs-number">0.0</span><br>  <span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(testloader, <span class="hljs-number">0</span>):<br>      images, labels = data<br>      images = images.to(device)<br>      labels = labels.to(device)<br>      outputs = model_ft(images)<br>      _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br><br>      total += labels.size(<span class="hljs-number">0</span>)<br>      correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br>  test_acc = <span class="hljs-number">100.0</span> * correct / total<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy of the network on the test images: %d %%&#x27;</span> % (test_acc))<br>  <span class="hljs-keyword">return</span> test_acc<br></code></pre></td></tr></table></figure>

<h1 id="4-使用-ResNet34-实现¶"><a href="#4-使用-ResNet34-实现¶" class="headerlink" title="4. 使用 ResNet34 实现¶"></a>4. 使用 ResNet34 实现¶</h1><h2 id="4-1-定义模型参数"><a href="#4-1-定义模型参数" class="headerlink" title="4.1 定义模型参数"></a>4.1 定义模型参数</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#ResNet34:</span><br>NUM_CAR_CLASSES = <span class="hljs-number">98</span><br><br>model_ft = models.resnet34(weights = <span class="hljs-literal">True</span>)<br><br>num_ftrs = model_ft.fc.in_features<br>model_ft.fc = nn.Linear(num_ftrs, NUM_CAR_CLASSES)<br>model_ft = model_ft.to(device)<br><br>criterion = nn.CrossEntropyLoss()<br><br>optimizer = optim.SGD(model_ft.parameters(), lr = <span class="hljs-number">0.01</span>, momentum = <span class="hljs-number">0.9</span>)<br><br>lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = <span class="hljs-string">&#x27;max&#x27;</span>, patience = <span class="hljs-number">3</span>, threshold = <span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">/Users/gawaintan/miniforge3/envs/FastAi/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
</code></pre>
<h2 id="4-2-训练"><a href="#4-2-训练" class="headerlink" title="4.2 训练"></a>4.2 训练</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ResNet:</span><br>model_ft_res, training_losses_res, training_accs_res, test_accs_res = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=<span class="hljs-number">12</span>)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">  0%|                                                                                                                                                                                                                  | 0/12 [00:00&lt;?, ?it/s]

Epoch 1, duration: 109 s, loss: 4.1009, acc: 9.3994


  8%|████████████████▊                                                                                                                                                                                        | 1/12 [02:34&lt;28:22, 154.73s/it]

Accuracy of the network on the test images: 24 %
Epoch 2, duration: 113 s, loss: 2.3972, acc: 34.3994


 17%|█████████████████████████████████▌                                                                                                                                                                       | 2/12 [05:15&lt;26:25, 158.51s/it]

Accuracy of the network on the test images: 34 %
Epoch 3, duration: 117 s, loss: 1.7940, acc: 48.6328


 25%|██████████████████████████████████████████████████▎                                                                                                                                                      | 3/12 [07:58&lt;24:03, 160.39s/it]

Accuracy of the network on the test images: 35 %
Epoch 4, duration: 114 s, loss: 1.4076, acc: 58.3984


 33%|███████████████████████████████████████████████████████████████████                                                                                                                                      | 4/12 [10:36&lt;21:16, 159.59s/it]

Accuracy of the network on the test images: 48 %
Epoch 5, duration: 119 s, loss: 1.1524, acc: 64.6973


 42%|███████████████████████████████████████████████████████████████████████████████████▊                                                                                                                     | 5/12 [13:22&lt;18:52, 161.84s/it]

Accuracy of the network on the test images: 48 %
Epoch 6, duration: 119 s, loss: 0.9919, acc: 69.3848


 50%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 6/12 [16:06&lt;16:14, 162.44s/it]

Accuracy of the network on the test images: 61 %
Epoch 7, duration: 122 s, loss: 0.8873, acc: 72.2656


 58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                   | 7/12 [18:54&lt;13:41, 164.33s/it]

Accuracy of the network on the test images: 61 %
Epoch 8, duration: 123 s, loss: 0.7274, acc: 77.3193


 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 8/12 [21:42&lt;11:01, 165.34s/it]

Accuracy of the network on the test images: 64 %
Epoch 9, duration: 127 s, loss: 0.4055, acc: 87.5000


 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                  | 9/12 [24:30&lt;08:19, 166.45s/it]

Accuracy of the network on the test images: 80 %
Epoch 10, duration: 127 s, loss: 0.2865, acc: 91.0400


 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 10/12 [27:22&lt;05:35, 167.97s/it]

Accuracy of the network on the test images: 81 %
Epoch 11, duration: 131 s, loss: 0.2480, acc: 92.3828


 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 11/12 [30:20&lt;02:51, 171.06s/it]

Accuracy of the network on the test images: 82 %
Epoch 12, duration: 139 s, loss: 0.2195, acc: 93.5547


100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [33:26&lt;00:00, 167.24s/it]

Accuracy of the network on the test images: 82 %
Finished Training
</code></pre>
<p>该模型在12个epoch训练后训练准确度到了94%，测试准确度到了82%。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 画统计图</span><br>f, axarr = plt.subplots(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>, figsize = (<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>].plot(training_losses_res)<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>].set_title(<span class="hljs-string">&quot;Training loss&quot;</span>)<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>].plot(training_accs_res)<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>].set_title(<span class="hljs-string">&quot;Training acc&quot;</span>)<br>axarr[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>].plot(test_accs_res)<br>axarr[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>].set_title(<span class="hljs-string">&quot;Test acc&quot;</span>)<br><br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Test acc&#39;)
</code></pre>
<p><img src="https://ptpimg.me/qqpd2g.png" alt="在这里插入图片描述"><br>)</p>
<h2 id="4-3-在单张图片上评估模型"><a href="#4-3-在单张图片上评估模型" class="headerlink" title="4.3 在单张图片上评估模型"></a>4.3 在单张图片上评估模型</h2><p>这个是按实际场景预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 关联文件和它的类名</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_classes</span>(<span class="hljs-params"><span class="hljs-built_in">dir</span></span>):<br>    classes = os.listdir(<span class="hljs-built_in">dir</span>)<br>    classes.sort()<br>    class_to_idx = &#123;classes[i]: i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(classes))&#125;<br>    <span class="hljs-keyword">return</span> classes, class_to_idx<br>classes, c_to_idx = find_classes(dataset_dir + <span class="hljs-string">&quot;train&quot;</span>)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义函数读取图片</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">single_img_eval</span>(<span class="hljs-params">model_ft, imgdir</span>):<br><br>  <span class="hljs-comment"># 把模式切换到评估</span><br>  model_ft.<span class="hljs-built_in">eval</span>()<br><br>  <span class="hljs-comment"># transforms输入的图片</span><br>  loader = transforms.Compose([transforms.Resize((<span class="hljs-number">400</span>, <span class="hljs-number">400</span>)),<br>                                  transforms.ToTensor(),<br>                                  transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br>  image = Image.<span class="hljs-built_in">open</span>(dataset_dir + imgdir)<br>  image = loader(image).<span class="hljs-built_in">float</span>()<br>  <span class="hljs-comment">#这里会默认cpu，若是cuda或者mps一定要加to(device)</span><br>  image = torch.autograd.Variable(image, requires_grad=<span class="hljs-literal">True</span>).to(device) <br>  <br>  image = image.unsqueeze(<span class="hljs-number">0</span>)<br>  <span class="hljs-comment">#image = image.mps()</span><br>  output = model_ft(image)<br>  conf, predicted = torch.<span class="hljs-built_in">max</span>(output.data, <span class="hljs-number">1</span>)<br><br>  display(Image.<span class="hljs-built_in">open</span>(dataset_dir + imgdir))<br>  <span class="hljs-built_in">print</span>(classes[predicted.item()], <span class="hljs-string">&quot;confidence: &quot;</span>, conf.item())<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">single_img_eval(model_ft_res, <span class="hljs-string">&quot;test/Chevrolet Traverse SUV 2012/004695.jpg&quot;</span>)<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/5672w0.png" alt="在这里插入图片描述"></p>
<pre><code class="hljs">Buick Verano Sedan 2012 confidence:  5.017297267913818
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">single_img_eval(model_ft_res, <span class="hljs-string">&quot;test/FIAT 500 Abarth 2012/008089.jpg&quot;</span>)<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/qloo1w.png" alt="在这里插入图片描述"></p>
<pre><code class="hljs">FIAT 500 Abarth 2012 confidence:  11.281584739685059
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">single_img_eval(model_ft_res, <span class="hljs-string">&quot;test/Aston Martin V8 Vantage Convertible 2012/000623.jpg&quot;</span>)<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/2jj563.png" alt="在这里插入图片描述"></p>
<pre><code class="hljs">Aston Martin V8 Vantage Convertible 2012 confidence:  9.173359870910645
</code></pre>
<p>我们从 ResNet34 采用的网络已成功对三辆汽车中的两辆进行了高置信度分类。对于第一辆车，该网络未能区分Chevrolet和Buick两类车。</p>
<h2 id="4-4-保存模型以备将来使用"><a href="#4-4-保存模型以备将来使用" class="headerlink" title="4.4 保存模型以备将来使用"></a>4.4 保存模型以备将来使用</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">torch.save(model_ft_res.state_dict(), <span class="hljs-string">&#x27;car_model_resnet.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h1 id="5-使用-GoogLeNet-实现"><a href="#5-使用-GoogLeNet-实现" class="headerlink" title="5. 使用 GoogLeNet 实现"></a>5. 使用 GoogLeNet 实现</h1><h2 id="5-1-定义模型参数"><a href="#5-1-定义模型参数" class="headerlink" title="5.1 定义模型参数"></a>5.1 定义模型参数</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># GoogLeNet:</span><br>NUM_CAR_CLASSES = <span class="hljs-number">98</span><br><br>model_ft = models.googlenet(weights = <span class="hljs-literal">True</span>)<br><br>num_ftrs = model_ft.fc.in_features<br>model_ft.fc = nn.Linear(num_ftrs, NUM_CAR_CLASSES)<br>model_ft = model_ft.to(device)<br><br>optimizer = optim.SGD(model_ft.parameters(), lr = <span class="hljs-number">0.01</span>, momentum = <span class="hljs-number">0.9</span>)<br><br>lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = <span class="hljs-string">&#x27;max&#x27;</span>, patience = <span class="hljs-number">3</span>, threshold = <span class="hljs-number">0.9</span>)<br><br></code></pre></td></tr></table></figure>

<h2 id="5-2-训练"><a href="#5-2-训练" class="headerlink" title="5.2 训练"></a>5.2 训练</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># GoogLeNet:</span><br>model_ft_google, training_losses_google, training_accs_google, test_accs_google = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=<span class="hljs-number">12</span>)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">  0%|                                                                                                                                                                                                                  | 0/12 [00:00&lt;?, ?it/s]

Epoch 1, duration: 168 s, loss: 3.0864, acc: 23.5596


  8%|████████████████▊                                                                                                                                                                                        | 1/12 [03:22&lt;37:07, 202.47s/it]

Accuracy of the network on the test images: 39 %
Epoch 2, duration: 164 s, loss: 2.0752, acc: 43.7256


 17%|█████████████████████████████████▌                                                                                                                                                                       | 2/12 [07:01&lt;35:22, 212.23s/it]

Accuracy of the network on the test images: 51 %
Epoch 3, duration: 164 s, loss: 1.5181, acc: 56.3721


 25%|██████████████████████████████████████████████████▎                                                                                                                                                      | 3/12 [10:22&lt;31:03, 207.08s/it]

Accuracy of the network on the test images: 62 %
Epoch 4, duration: 182 s, loss: 1.1773, acc: 65.8691


 33%|███████████████████████████████████████████████████████████████████                                                                                                                                      | 4/12 [14:01&lt;28:15, 211.89s/it]

Accuracy of the network on the test images: 66 %
Epoch 5, duration: 130 s, loss: 0.9473, acc: 71.5088


 42%|███████████████████████████████████████████████████████████████████████████████████▊                                                                                                                     | 5/12 [16:49&lt;22:52, 196.12s/it]

Accuracy of the network on the test images: 69 %
Epoch 6, duration: 106 s, loss: 0.6231, acc: 82.9834


 50%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 6/12 [19:15&lt;17:54, 179.04s/it]

Accuracy of the network on the test images: 79 %
Epoch 7, duration: 135 s, loss: 0.5321, acc: 86.5234


 58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                   | 7/12 [22:10&lt;14:47, 177.47s/it]

Accuracy of the network on the test images: 80 %
Epoch 8, duration: 137 s, loss: 0.4982, acc: 86.7920


 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 8/12 [25:08&lt;11:50, 177.72s/it]

Accuracy of the network on the test images: 81 %
Epoch 9, duration: 147 s, loss: 0.4649, acc: 88.9404


 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                  | 9/12 [28:16&lt;09:03, 181.11s/it]

Accuracy of the network on the test images: 81 %
Epoch 10, duration: 154 s, loss: 0.4419, acc: 89.3799


 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 10/12 [31:34&lt;06:12, 186.29s/it]

Accuracy of the network on the test images: 81 %
Epoch 11, duration: 172 s, loss: 0.4061, acc: 89.9170


 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 11/12 [35:12&lt;03:15, 195.96s/it]

Accuracy of the network on the test images: 81 %
Epoch 12, duration: 156 s, loss: 0.4121, acc: 89.9170


100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [38:28&lt;00:00, 192.34s/it]

Accuracy of the network on the test images: 81 %
Finished Training
</code></pre>
<p>同样，我们观察到网络在epoch12 达到其峰值性能（90% 的训练准确率和 81% 的测试准确率）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># plot the stats</span><br><br>f, axarr = plt.subplots(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>, figsize = (<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>].plot(training_losses_google)<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>].set_title(<span class="hljs-string">&quot;Training loss&quot;</span>)<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>].plot(training_accs_google)<br>axarr[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>].set_title(<span class="hljs-string">&quot;Training acc&quot;</span>)<br>axarr[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>].plot(test_accs_google)<br>axarr[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>].set_title(<span class="hljs-string">&quot;Test acc&quot;</span>)<br><br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Test acc&#39;)
</code></pre>
<p><img src="https://ptpimg.me/qqpd2g.png" alt="在这里插入图片描述"></p>
<h2 id="5-3-在单幅图像上评估模型"><a href="#5-3-在单幅图像上评估模型" class="headerlink" title="5.3 在单幅图像上评估模型"></a>5.3 在单幅图像上评估模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">single_img_eval(model_ft_google, <span class="hljs-string">&quot;test/Chevrolet Traverse SUV 2012/004695.jpg&quot;</span>)<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/5672w0.png" alt="在这里插入图片描述"></p>
<pre><code class="hljs">Chevrolet Impala Sedan 2007 confidence:  4.615828037261963
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">single_img_eval(model_ft_google, <span class="hljs-string">&quot;test/FIAT 500 Abarth 2012/008089.jpg&quot;</span>)<br></code></pre></td></tr></table></figure>



<p><img src="https://ptpimg.me/qloo1w.png" alt="在这里插入图片描述"></p>
<pre><code class="hljs">FIAT 500 Abarth 2012 confidence:  6.266000747680664
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">single_img_eval(model_ft_google,  <span class="hljs-string">&quot;test/Aston Martin V8 Vantage Convertible 2012/000623.jpg&quot;</span>)<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/2jj563.png" alt="在这里插入图片描述"></p>
<pre><code class="hljs">Aston Martin V8 Vantage Convertible 2012 confidence:  6.059011459350586
</code></pre>
<p>对比ResNet34该网络识别出后两个，第一个也是识别错了，但是更接近一些，只是confidence低一些。</p>
<h2 id="5-4-保存模型以备后用"><a href="#5-4-保存模型以备后用" class="headerlink" title="5.4 保存模型以备后用"></a>5.4 保存模型以备后用</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">torch.save(model_ft_google.state_dict(), <span class="hljs-string">&#x27;car_model_googlenet.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h1 id="6-结论"><a href="#6-结论" class="headerlink" title="6. 结论"></a>6. 结论</h1><p>在这个项目中，我们在预训练的最先进的 ResNet34 和 GoogLeNet 网络上实施了“现成的”迁移学习技术。我们通过用未经训练的层替换它们的最后一个完全连接层来采用这些网络，然后冻结更深的层并使用我们的数据训练最后一层：斯坦福汽车数据，使用随机梯度下降。我们使用自适应学习率来优化训练过程。我们还对训练数据进行了扩充以避免过度拟合。</p>
<p>我们的结果不错，采用的两种网络都具有高性能：来自 ResNet34 的网络具有 93% 的训练准确率和 85% 的测试准确率；来自 GoogLeNet 的网络具有 90% 的训练准确率和 84% 的测试准确率。</p>
<p>最后，我们还使用单个图像来模拟真实生产场景来评估模型，并且模型表现良好。</p>
<h1 id="7-未来优化"><a href="#7-未来优化" class="headerlink" title="7. 未来优化"></a>7. 未来优化</h1><p>迁移学习的下一步将是在预训练网络中更深入：可能训练更多的新层，或者微调一些更深的层。也许这可以将性能提升到更高的水平并解决敞篷车与轿跑车的问题。</p>
<p>此外，我们希望将迁移学习用于图像分类以外的任务，也许是一些自然语言处理。</p>
]]></content>
  </entry>
  <entry>
    <title>Mac使用指南指令备忘录</title>
    <url>/2021/05/11/m1/</url>
    <content><![CDATA[<p>@[TOC](m1 Mac使用指南指令备忘录 )<br>M1用到现在也小半年了，踩了些坑，也有一些使用心得，这里主要提供思路方法，具体方法可以自行搜索了解</p>
<h1 id="硬件外设"><a href="#硬件外设" class="headerlink" title="硬件外设"></a>硬件外设</h1><p>首先是用的Macbook air丐版8+256</p>
<ol>
<li>显示器，HKC的C299Q，看中它长屏方便剪辑和分屏，90%的DCI-P色域看电影还行，不打游戏所以VA的曲面屏还是挺合适</li>
<li>键盘，将就用之前ipad配的逻辑K380</li>
<li>鼠标，罗技M720</li>
<li>硬盘，在家组了个NAS，4T用来放电影和剪辑素材之类的大文件</li>
<li>拓展坞，飞利浦的五合一Type-c+Hdim1.4+3*USB3.0基本满足需求。</li>
<li>Ipad air3随航当拓展屏很好用</li>
</ol>
<h2 id="外接显示器HiDpi"><a href="#外接显示器HiDpi" class="headerlink" title="外接显示器HiDpi"></a>外接显示器HiDpi</h2><p>强制开启Hidpi<br>有条件上4k显示器的当然最好，接上显示器就会出现调节界面，主要针对非4K屏幕<br>hidpi是macos优化显示效果的一种技术，需要硬件达到视网膜屏幕标准，具体技术可以自行了解，主要问题是非4k比如我现在用的带鱼屏1080*2560会出现字体发虚的情况<br>参考国外一个大神软件虚拟显示器的方法<br><a href="https://github.com/waydabber/BetterDummy">BetterDummy</a><br>主要方法是通过软件虚拟一个支持hidpi的显示器，再把这个显示器投到自己的上面。带鱼屏的话注意选21.5:9，21.3:9是没Hidpi的。<br>系统需要更新到Monetery<br><img src="https://ptpimg.me/789b29.png" alt="在这里插入图片描述"></p>
<h1 id="homebrew"><a href="#homebrew" class="headerlink" title="homebrew"></a>homebrew</h1><p>homebrew是Mac上一个软件管理工具，可以理解为开源Appstore，直接brew install即可安装指定软件，最好安装前先用Brew search查询是否存在对应版本</p>
<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs C">export HOMEBREW_BREW_GIT_REMOTE=<span class="hljs-string">&quot;...&quot;</span>  <span class="hljs-meta"># put your Git mirror of Homebrew/brew here</span><br>export HOMEBREW_CORE_GIT_REMOTE=<span class="hljs-string">&quot;...&quot;</span>  <span class="hljs-meta"># put your Git mirror of Homebrew/homebrew-core here</span><br>/bin/bash -c <span class="hljs-string">&quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;</span><br></code></pre></td></tr></table></figure>

<h1 id="必备网站"><a href="#必备网站" class="headerlink" title="必备网站"></a>必备网站</h1><ol>
<li><a href="https://isapplesiliconready.com/">Is apple Silicon ready？</a>对应软件官方是否已经适配m1平台<br><img src="https://ptpimg.me/145r82.png" alt="软件适配"></li>
<li><a href="https://www.macwk.com/">MacWk</a>一个免费的破解软件下载网站</li>
<li><a href="https://www.applegamingwiki.com/wiki/Home">m1游戏适配情况</a>介绍游戏在不同环境下运行情况，点进去有详细测评<br><img src="https://ptpimg.me/2tyf73.png" alt="m1"></li>
</ol>
<h1 id="软件推荐"><a href="#软件推荐" class="headerlink" title="软件推荐"></a>软件推荐</h1><h2 id="Parallels-Desktop"><a href="#Parallels-Desktop" class="headerlink" title="Parallels Desktop"></a>Parallels Desktop</h2><h2 id="Silicon"><a href="#Silicon" class="headerlink" title="Silicon"></a>Silicon</h2><h2 id="Bob"><a href="#Bob" class="headerlink" title="Bob"></a>Bob</h2><h2 id="IINA"><a href="#IINA" class="headerlink" title="IINA"></a>IINA</h2><h2 id="iterm2远程"><a href="#iterm2远程" class="headerlink" title="iterm2远程"></a>iterm2远程</h2><p>Iterm2比Mac自带terminal更好用，装机必备软件之一<br>cmd+O调出profile 保存帐号-&gt;cmd+option+F 调出password manage保存密码</p>
<h1 id="mysql和redis启动"><a href="#mysql和redis启动" class="headerlink" title="mysql和redis启动"></a>mysql和redis启动</h1><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">brew service start mysql<br><br>redis-server<br></code></pre></td></tr></table></figure>



<h1 id="OhMyZsh设置"><a href="#OhMyZsh设置" class="headerlink" title="OhMyZsh设置"></a>OhMyZsh设置</h1><p>可以在Mac和Debian本地分别设置<br><a href="https://blog.51cto.com/u_15127596/4297531">参考细节</a><br>推荐插件 extract、 zsh-syntax-highlighting、autojump、zsh-autosuggestions</p>
<h1 id="磁盘读写查询"><a href="#磁盘读写查询" class="headerlink" title="磁盘读写查询"></a>磁盘读写查询</h1><figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs C">smartctl 盘查看读写次数<br><br></code></pre></td></tr></table></figure>
<p>这个磁盘过度读写的问题最好是使用原生软件<br><img src="https://ptpimg.me/e63381.png" alt="2021-11-22"></p>
<h1 id="tensorfow安装配置"><a href="#tensorfow安装配置" class="headerlink" title="tensorfow安装配置"></a>tensorfow安装配置</h1><h2 id="python环境"><a href="#python环境" class="headerlink" title="python环境"></a>python环境</h2><p>电脑自带python但是3.9有点高，可以自己选择对应版本<br>点击下载<a href="https://github.com/conda-forge/miniforge/#download">miniforge</a><br>安装命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">bash Miniforge3-MacOSX-arm64.sh<br><br>nano ~/.bash_profile<br>export PATH=&quot;/Users/Cyberbolt/miniforge3/bin:$PATH&quot; <br><br>source $HOME/.bash_profile<br></code></pre></td></tr></table></figure>
<h2 id="在虚拟环境安装-TensorFlow"><a href="#在虚拟环境安装-TensorFlow" class="headerlink" title="在虚拟环境安装 TensorFlow"></a>在虚拟环境安装 TensorFlow</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">conda create -n py39 python=3.9<br>conda activate py39<br><br>conda install -c apple tensorflow-deps<br>python -m pip install tensorflow-macos<br>python -m pip install tensorflow-metal<br></code></pre></td></tr></table></figure>
<h1 id="未完待补充"><a href="#未完待补充" class="headerlink" title="未完待补充"></a>未完待补充</h1>]]></content>
  </entry>
  <entry>
    <title>重装系统</title>
    <url>/2020/03/07/%E9%87%8D%E8%A3%85%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h1 id="WIN10迁移C盘和崩溃还原系统总结"><a href="#WIN10迁移C盘和崩溃还原系统总结" class="headerlink" title="WIN10迁移C盘和崩溃还原系统总结"></a>WIN10迁移C盘和崩溃还原系统总结</h1><p>这几天为了清理C盘一直动系统的文件，导致经常重启，其中主要还是迁移C盘Users数据到其他非系统盘操作不当导致开机系统加载不了用户信息，下面具体记录这两方面。</p>
<ol>
<li><p>迁移资料的关键还是利用硬链接将物理地址位于其他盘的Users用户信息映射到C盘的逻辑名上。下面只简单记录一下命令。</p>
</li>
<li><p><strong>最关键的还是利用系统的保命文件———Backup.wim重刷系统</strong><br>一个通过Dism++文件创建的镜像文件，尽量将此文件放于非系统盘，有此文件基本可以不用借助任何外部工具无限重刷回原系统。</p>
</li>
</ol>
<p>上面两者都需要通过高级重启进入一个纯命令行的Dos界面，在此可以几乎不受权限限制对文件<strong>删除复制</strong>等操作<br><strong>进入 <em>系统设置 -&gt; 升级&amp;安全 -&gt; 恢复 -&gt; 高级重启 -&gt; 立刻重启</em> 来重启电脑到恢复模式；</strong><br><img src="https://ptpimg.me/edeyq3.png" alt="在这里插入图片描述"><br>后面就是选择 <em><strong>疑难解答-&gt;高级-&gt;命令提示符</strong></em>（现在不便具体演示，网上有很多相关教程）</p>
<p><strong>注意</strong>：在Dos环境下盘符名称可能和平时不一样(我的OS就变成F盘了)，首先就是平时被隐藏的X盘，其他最好先通过 <strong>diskpart</strong>命令进入管理磁盘工具，通过<strong>list volume</strong>查看所有盘符信息，<strong>exit</strong>退出。同时利用<strong>cd 对应硬盘</strong> 进入后再用<strong>dir</strong>命令确认文件是否正确。</p>
<h2 id="C盘Users迁移其他盘"><a href="#C盘Users迁移其他盘" class="headerlink" title="C盘Users迁移其他盘"></a>C盘Users迁移其他盘</h2><p>有几种方法可用，原则就是要先保证在非现用户使用环境下进行，为了避免各种权限要求，我是直接开机进入Dos命令行：</p>
<ol>
<li>将Users复制与其他盘.<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">复制C:\Users下的所有文件到D:\Users <br><br><span class="hljs-comment">// 参数说明：此命令为Windows的“强制文件拷贝”命令。</span><br><span class="hljs-comment">//      /E 表示拷贝文件时包含子目录（包括空目录）</span><br><span class="hljs-comment">//      /COPYALL 表示拷贝所有文件信息</span><br><span class="hljs-comment">//      /XJ 表示不包括Junction points（默认是包括的）</span><br><span class="hljs-comment">//      /XD &quot;F:\Users\Administrator&quot; 表示不包括指定的目录,此处指定目录为：&quot;F:\Users\Administrator&quot;</span><br>robocopy <span class="hljs-string">&quot;F:\Users&quot;</span> <span class="hljs-string">&quot;D:\Users&quot;</span> /E /COPYALL /XJ /XD <span class="hljs-string">&quot;F:\Users\Administrator&quot;</span><br></code></pre></td></tr></table></figure></li>
<li>删除用户文件<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//参数说明：此命令删除指定目录。</span><br><span class="hljs-comment">//      /S 删除指定目录及其中的所有文件,用于删除目录树。</span><br><span class="hljs-comment">//      /Q 安静模式,删除时不询问。 </span><br>rmdir  <span class="hljs-string">&quot;F:\Users&quot;</span> /S /Q　　<br></code></pre></td></tr></table></figure></li>
<li>硬链接将C盘新Users链接到所备份的文件<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 参数说明：此命令创建符号连接。</span><br><span class="hljs-comment">//      /J 连接类型为目录连接</span><br>mklink  /J <span class="hljs-string">&quot;F:\Users&quot;</span> <span class="hljs-string">&quot;D:\Users&quot;</span><br></code></pre></td></tr></table></figure>
期间可能复制一部分文件不成功，我看不太重要就强制继续，删除可能不干净，也可采用ren 命令将Users文件夹重命名，保证和硬链接不冲突即可，后面再处理，不用自己创建新的Users，mklink会自动生成，自己要创建可用<strong>md</strong>命令。</li>
</ol>
<h2 id="备份以及还原系统"><a href="#备份以及还原系统" class="headerlink" title="备份以及还原系统"></a>备份以及还原系统</h2><h4 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h4><p>有几种方式，我用的dism++ 备份，也可采用命令行.</p>
<ol>
<li>命令行：<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">  <span class="hljs-comment">//初始备份（例如：把 C 分区的系统备份到 D 分区的 1文件夹中，备份文件名为Backup.wim）：</span><br>    Dism /Capture-Image /ImageFile:D:\<span class="hljs-number">1</span>\Backup.wim /CaptureDir:C:\ /Name:Backup<span class="hljs-number">-1</span> /Description:<span class="hljs-number">0000</span><span class="hljs-number">-00</span><span class="hljs-number">-00</span><br><span class="hljs-comment">// 命令解释：</span><br><span class="hljs-comment">//    /Capture-Image - 指定捕获映像。</span><br><span class="hljs-comment">//    /ImageFile: - 指定映像文件路径。                </span><br><span class="hljs-comment">//    /CaptureDir: - 指定捕获目录。</span><br><span class="hljs-comment">//    /Name: - 指定名称。此项不能省略。</span><br><span class="hljs-comment">//    /Description: - 指定描述。描述是为了说明这次备份的具体情况，我们这里用了时间。此项可省略。</span><br></code></pre></td></tr></table></figure></li>
<li>利用软件dism++<br><strong>选择恢复-&gt;系统备份</strong><br><img src="https://ptpimg.me/36404v.png" alt="在这里插入图片描述"><br>选择保存的硬盘并输入保存的名字：<br><img src="https://ptpimg.me/28h841.png" alt="在这里插入图片描述"><br>等待完成即可。<br><strong>注</strong>：最好备份前清理C盘，保证电脑最好状态，这也是个人用电脑的好习惯。</li>
</ol>
<h2 id="系统还原"><a href="#系统还原" class="headerlink" title="系统还原"></a>系统还原</h2><p>具体参考以下<br> <a href="https://answers.microsoft.com/zh-hans/windows/forum/windows_10-update/%E7%94%A8-dism/a3ea0d10-036c-41ff-8bb9-350c2bda525b">用 DISM 命令备份与还原 Windows 系统</a>.<br>关键指令：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//系统还原（例如：把 D:\Backup.wim 中备份还原到 C分区）：</span><br>    Dism /Apply-Image /ImageFile:D:\Backup.wim/Index:<span class="hljs-number">1</span> /ApplyDir:C:\<br> <span class="hljs-comment">//   命令解释：</span><br> <span class="hljs-comment">//   /Apply-Image - 指定应用映像。</span><br> <span class="hljs-comment">//   /ApplyDir: - 指定应用目录。</span><br> <span class="hljs-comment">//  /Index: - 指定索引。此项不能省略。 </span><br></code></pre></td></tr></table></figure>
<p><strong>因 Dism 安装 WIM 映像不会像 Ghost 那样格式化磁盘，个人就遇上第一次成功还原后，后面还原遇上无法访问的 错误5，所以先格式化系统盘是最稳妥的。</strong><br>格式化指令：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><code class="hljs c">format C:/q<br><span class="hljs-comment">//    /Q  执行快速格式化。</span><br></code></pre></td></tr></table></figure>
<p>格式化需谨慎，尽量多<strong>dir</strong>命令查看确认分区是否正确，毕竟系统格式化了马上就还原，资料格式化就啥也没了。</p>
<p>格式化完成再按上述命令完成还原，几乎不会有问题，一般等待十几分钟，完成后就可以关闭命令窗口重启电脑，过会就会看见熟悉输入密码页面了。</p>
<p>到此一个完整还原周期完成，平时尽量养成将数据置于非系统盘之下的习惯，这样除了减小C盘容量压力，也可使重装系统带来的影响最小，某种程度保证自己电脑使用稳定性。</p>
<p> 第一次文档记录，为以后系统崩溃提供解决办法，也是向大家分享折腾了两天的错误经验，虽然都是可以google到的方法，但收集信息排错需要时间精力。<strong>格式化C区-&gt;dos还原系统</strong>是个人使用最快捷方便的恢复操作，<br>若有错误或纰漏多多指正，还有，小白谨慎使用以上方法，我不能保证错误操作对系统不会造成损失。</p>
]]></content>
  </entry>
  <entry>
    <title>机器学习-文本处理之电影评论多分类情感分析</title>
    <url>/2022/09/02/motionanalys/</url>
    <content><![CDATA[<h1 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h1><p>文本处理是许多ML应用程序中最常见的任务之一。以下是此类应用的一些示例</p>
<ul>
<li>语言翻译：将句子从一种语言翻译成另一种语言</li>
<li>情绪分析：从文本语料库中确定对任何主题或产品等的情绪是积极的、消极的还是中性的</li>
<li>垃圾邮件过滤：检测未经请求和不需要的电子邮件&#x2F;消息。</li>
</ul>
<p>这些应用程序处理大量文本以执行分类或翻译，并且涉及大量后端工作。将文本转换为算法可以消化的内容是一个复杂的过程。在本文中，我们将讨论文本处理中涉及的步骤。</p>
<h1 id="二、数据预处理"><a href="#二、数据预处理" class="headerlink" title="二、数据预处理"></a>二、数据预处理</h1><ul>
<li>分词——将句子转化为词语</li>
<li>去除多余的标点符号</li>
<li>去除停用词——高频出现的“的、了”之类的词，他们对语义分析没帮助</li>
<li>词干提取——通过删除不必要的字符（通常是后缀），将单词缩减为词根。</li>
<li>词形还原——通过确定词性并利用语言的详细数据库来消除屈折变化的另一种方法。</li>
</ul>
<p>我们可以使用python进行许多文本预处理操作。</p>
<p>NLTK（Natural Language Toolkit），自然语言处理工具包，在NLP（自然语言处理）领域中，最常使用的一个Python库。自带语料库，词性分类库。自带分类，分词功能。 </p>
<p><strong>分词（Tokenize）</strong>：word_tokenize生成一个词的列表</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br>sentence=<span class="hljs-string">&quot;I Love China !&quot;</span><br>tokens=nltk.word_tokenize(sentence)<br>tokens<br></code></pre></td></tr></table></figure>
<p>[‘I’, ‘Love’, ‘China’, ‘!’]<br><strong>中文分词–jieba</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> jieba<br><span class="hljs-meta">&gt;&gt;&gt; </span>seg_list=jieba.cut(<span class="hljs-string">&quot;我正在学习机器学习&quot;</span>,cut_all=<span class="hljs-literal">True</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;全模式：&quot;</span>,<span class="hljs-string">&quot;/&quot;</span>.join(seg_list))<br>全模式： 我/正在/学习/学习机/机器/学习<br><span class="hljs-meta">&gt;&gt;&gt; </span>seg_list=jieba.cut(<span class="hljs-string">&quot;我正在学习机器学习&quot;</span>,cut_all=<span class="hljs-literal">False</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;精确模式：&quot;</span>,<span class="hljs-string">&quot;/&quot;</span>.join(seg_list))<br>精确模式： 我/正在/学习/机器/学习<br></code></pre></td></tr></table></figure>

<h1 id="三、特征提取"><a href="#三、特征提取" class="headerlink" title="三、特征提取"></a>三、特征提取</h1><p>在文本处理中，文本中的单词表示离散的、分类的特征。我们如何以算法可以使用的方式对这些数据进行编码？从文本数据到实值向量的映射称为特征提取。用数字表示文本的最简单的技术之一是<strong>Bag of Words</strong>。</p>
<h2 id="Bag-of-Words"><a href="#Bag-of-Words" class="headerlink" title="Bag of Words"></a>Bag of Words</h2><p>我们在文本语料库中列出一些独特的单词，称为词汇表。然后我们可以将每个句子或文档表示为一个向量，每个单词表示为1表示现在，0表示不在词汇表中。另一种表示法是计算每个单词在文档中出现的次数。最流行的方法是使用术语频率逆文档频率（<strong>TF-IDF</strong>）技术。</p>
<ul>
<li><strong>Term Frequency (TF)</strong>&#x3D;（术语t出现在•文档中的次数）&#x2F;（文档中的术语数量）</li>
<li><strong>Inverse Document Frequency (IDF)</strong>&#x3D;log(N&#x2F;n)，其中，N是文档数量，n是术语t出现在文档中的数量。稀有词的IDF较高，而频繁词的IDF可能较低。因此具有突出显示不同单词的效果。</li>
<li>我们计算一个项的<strong>TF-IDF</strong>值为&#x3D;TF*IDF</li>
</ul>
<p><img src="https://ptpimg.me/4ix0bu.png"></p>
<pre><code class="hljs">TF(&#39;beautiful&#39;,Document1) = 2/10, IDF(&#39;beautiful&#39;)=log(2/2) = 0
TF(‘day’,Document1) = 5/10,  IDF(‘day’)=log(2/1) = 0.30
TF-IDF(‘beautiful’, Document1) = (2/10)*0 = 0
TF-IDF(‘day’, Document1) = (5/10)*0.30 = 0.15
</code></pre>
<p>正如您在Document1中看到的，TF-IDF方法严重惩罚了“beautiful”一词，但对“day”赋予了更大的权重。这是由于IDF部分，它为不同的单词赋予了更多的权重。换句话说，从整个语料库的上下文来看，“day”是Document1的一个重要词。Python scikit学习库为文本数据挖掘提供了有效的工具，并提供了计算给定文本语料库的文本词汇表TF-IDF的函数。</p>
<p>使用BOW的一个主要缺点是它放弃了词序，从而忽略了上下文，进而忽略了文档中单词的含义。对于自然语言处理（NLP），保持单词的上下文是至关重要的。为了解决这个问题，我们使用另一种称为单词嵌入的方法。</p>
<h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><p>它是文本的一种表示形式，其中具有相同含义的单词具有相似的表示形式。换句话说，它表示坐标系中的单词，在坐标系中，基于关系语料库的相关单词被放在更近的位置。</p>
<h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><p>Word2vec将大量文本作为输入，并生成一个向量空间，每个唯一的单词在该空间中分配一个对应的向量。词向量定位在向量空间中，使得在语料库中共享公共上下文的词在该空间中彼此非常接近。Word2Vec非常擅长捕捉意义，并在诸如计算a到b的类比问题以及c到？的类比问题等任务中演示它？。例如，男人对女人就像叔叔对女人一样？（a）使用基于余弦距离的简单矢量偏移方法。例如，这里有三个单词对的向量偏移量来说明性别关系：<br><img src="https://ptpimg.me/i136y0.png" alt="性别关系的向量偏移量"></p>
<p>这种向量组合也让我们回答“国王-男人+女人&#x3D;？”提问并得出结果“女王”！当你认为所有这些知识仅仅来自于在上下文中查看大量单词，而没有提供关于它们的语义的其他信息时，所有这些都是非常值得注意的。</p>
<h4 id="Glove"><a href="#Glove" class="headerlink" title="Glove"></a>Glove</h4><p>单词表示的全局向量（GloVe）算法是word2vec方法的扩展，用于有效学习单词向量。glove使用整个文本语料库中的统计信息构建一个显式的单词上下文或单词共现矩阵。结果是一个学习模型，可能会导致更好的单词嵌入。</p>
<p><img src="https://ptpimg.me/0nux0t.png" alt="在这里插入图片描述"></p>
<pre><code class="hljs">Target words: ice, steam
Probe words: solid, gas, water, fashion
</code></pre>
<p>让P(k | w)是单词k出现在单词W的上下文中的概率W.考虑一个与ice有密切关系的词，而不是与steam有关的词，例如solid。P(solid | ice)相对较高，P(solid | steam)相对较低。因此，P(solid | ice)&#x2F; P(solid | steam)的比率将很大。如果我们用一个词，比如气体，它与steam有关，但与ice无关，那么P(gas | ice) &#x2F; P(gas | steam) 的比值就会变小。对于一个既与ice有关又与water有关的词，例如water，我们预计其比率接近1。</p>
<p>单词嵌入将每个单词编码成一个向量，该向量捕获文本语料库中单词之间的某种关系和相似性。这意味着即使是大小写、拼写、标点符号等单词的变体也会自动学习。反过来，这意味着可能不再需要上述一些文本清理步骤。</p>
<h1 id="四、电影评论情感分析实例"><a href="#四、电影评论情感分析实例" class="headerlink" title="四、电影评论情感分析实例"></a>四、电影评论情感分析实例</h1><p>根据问题空间和可用数据的不同，有多种方法为各种基于文本的应用程序构建ML模型。<br>用于垃圾邮件过滤的经典ML方法，如“朴素贝叶斯”或“支持向量机”，已被广泛使用。深度学习技术对于自然语言处理问题（如情感分析和语言翻译）有更好的效果。深度学习模型的训练速度非常慢，并且可以看出，对于简单的文本分类问题，经典的ML方法也能以更快的训练时间给出类似的结果。<br>让我们使用目前讨论的技术在Kaggle提供的烂番茄电影评论数据集上构建一个情感分析器。</p>
<h2 id="电影评论情感分析"><a href="#电影评论情感分析" class="headerlink" title="电影评论情感分析"></a>电影评论情感分析</h2><p><img src="https://ptpimg.me/1blyr8.png"></p>
<p>对于电影评论情绪分析，我们将使用Kaggle提供的烂番茄电影评论数据集。在这里，我们根据电影评论的情绪，以五个值为尺度给短语贴上标签：消极的，有些消极的，中性的，有些积极的，积极的。数据集由选项卡分隔的文件组成，其中包含来自数据集的短语ID。每个短语都有一个短语。每个句子都有一个句子ID。重复的短语（如短&#x2F;常用词）仅在数据中包含一次。情绪标签包括：</p>
<ul>
<li>0 - <em>negative</em></li>
<li>1 - <em>somewhat negative</em></li>
<li>2 - <em>neutral</em></li>
<li>3 - <em>somewhat positive</em></li>
<li>4 - <em>positive</em></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>%matplotlib inline<br><br></code></pre></td></tr></table></figure>

<h2 id="1-初始化数据"><a href="#1-初始化数据" class="headerlink" title="1. 初始化数据"></a><a id='1'>1. 初始化数据</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_train = pd.read_csv(<span class="hljs-string">&quot;/Users/gawaintan/workSpace/movie-review-sentiment-analysis-kernels-only/train.tsv&quot;</span>, sep=<span class="hljs-string">&#x27;\t&#x27;</span>)<br>df_train.head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PhraseId</th>
      <th>SentenceId</th>
      <th>Phrase</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>A series</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>A</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1</td>
      <td>series</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_test = pd.read_csv(<span class="hljs-string">&quot;/Users/gawaintan/workSpace/movie-review-sentiment-analysis-kernels-only/test.tsv&quot;</span>, sep=<span class="hljs-string">&#x27;\t&#x27;</span>)<br>df_test.head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PhraseId</th>
      <th>SentenceId</th>
      <th>Phrase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>156061</td>
      <td>8545</td>
      <td>An intermittently pleasing but mostly routine ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>156062</td>
      <td>8545</td>
      <td>An intermittently pleasing but mostly routine ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>156063</td>
      <td>8545</td>
      <td>An</td>
    </tr>
    <tr>
      <th>3</th>
      <td>156064</td>
      <td>8545</td>
      <td>intermittently pleasing but mostly routine effort</td>
    </tr>
    <tr>
      <th>4</th>
      <td>156065</td>
      <td>8545</td>
      <td>intermittently pleasing but mostly routine</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="1-1-每个情绪类别中的评论分布"><a href="#1-1-每个情绪类别中的评论分布" class="headerlink" title="1.1 每个情绪类别中的评论分布"></a><a id='1.1'>1.1 每个情绪类别中的评论分布</a></h2><p>在这里，训练数据集包含了电影评论中占主导地位的中性短语，然后是有些积极的，然后是有些消极的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_train.Sentiment.value_counts()<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">2    79582
3    32927
1    27273
4     9206
0     7072
Name: Sentiment, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_train.info()<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 156060 entries, 0 to 156059
Data columns (total 4 columns):
 #   Column      Non-Null Count   Dtype 
---  ------      --------------   ----- 
 0   PhraseId    156060 non-null  int64 
 1   SentenceId  156060 non-null  int64 
 2   Phrase      156060 non-null  object
 3   Sentiment   156060 non-null  int64 
dtypes: int64(3), object(1)
memory usage: 4.8+ MB
</code></pre>
<h2 id="1-2-删除不重要的列"><a href="#1-2-删除不重要的列" class="headerlink" title="1.2 删除不重要的列"></a><a id='1.2'>1.2 删除不重要的列</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_train_1 = df_train.drop([<span class="hljs-string">&#x27;PhraseId&#x27;</span>,<span class="hljs-string">&#x27;SentenceId&#x27;</span>],axis=<span class="hljs-number">1</span>)<br>df_train_1.head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Phrase</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A series</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>series</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



<p>Let’s check the phrase length of each of the movie reviews.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_train_1[<span class="hljs-string">&#x27;phrase_len&#x27;</span>] = [<span class="hljs-built_in">len</span>(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> df_train_1.Phrase]<br>df_train_1.head(<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Phrase</th>
      <th>Sentiment</th>
      <th>phrase_len</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
      <td>188</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>2</td>
      <td>77</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A series</td>
      <td>2</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="1-3-各情感类别下评论时长的总体分布"><a href="#1-3-各情感类别下评论时长的总体分布" class="headerlink" title="1.3 各情感类别下评论时长的总体分布"></a><a id='1.3'>1.3 各情感类别下评论时长的总体分布</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">fig,ax = plt.subplots(figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>plt.boxplot(df_train_1.phrase_len)<br>plt.show()<br></code></pre></td></tr></table></figure>


<p><img src="https://i-blog.csdnimg.cn/blog_migrate/72e054ceb9fb8ebddc1a279dcefa8606.png"></p>
<p>从上面的箱线图中，有些评论的长度超过 100 个字符。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_train_1[df_train_1.phrase_len &gt; <span class="hljs-number">100</span>].head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Phrase</th>
      <th>Sentiment</th>
      <th>phrase_len</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
      <td>188</td>
    </tr>
    <tr>
      <th>27</th>
      <td>is also good for the gander , some of which oc...</td>
      <td>2</td>
      <td>110</td>
    </tr>
    <tr>
      <th>28</th>
      <td>is also good for the gander , some of which oc...</td>
      <td>2</td>
      <td>108</td>
    </tr>
    <tr>
      <th>116</th>
      <td>A positively thrilling combination of ethnogra...</td>
      <td>3</td>
      <td>152</td>
    </tr>
    <tr>
      <th>117</th>
      <td>A positively thrilling combination of ethnogra...</td>
      <td>4</td>
      <td>150</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_train_1[df_train_1.phrase_len &gt; <span class="hljs-number">100</span>].loc[<span class="hljs-number">0</span>].Phrase<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&#39;A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .&#39;
</code></pre>
<h2 id="1-4-创建负面和正面电影评论的词云"><a href="#1-4-创建负面和正面电影评论的词云" class="headerlink" title="1.4 创建负面和正面电影评论的词云"></a><a id='1.4'>1.4 创建负面和正面电影评论的词云</a></h2><h3 id="Word-Cloud"><a href="#Word-Cloud" class="headerlink" title="Word Cloud"></a>Word Cloud</h3><p>wordcloud 是文本文件集合中常用词的图形表示。这张图片中每个词的高度是该词在整个文本中出现频率的指标。在进行文本分析时，此类图表非常有用。</p>
<h2 id="1-4-1-筛选出正面和负面的影评"><a href="#1-4-1-筛选出正面和负面的影评" class="headerlink" title="1.4.1 筛选出正面和负面的影评"></a><a id='1.4.1'>1.4.1 筛选出正面和负面的影评</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">neg_phrases = df_train_1[df_train_1.Sentiment == <span class="hljs-number">0</span>]<br>neg_words = []<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> neg_phrases.Phrase:<br>    neg_words.append(t)<br>neg_words[:<span class="hljs-number">4</span>]<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">[&#39;would have a hard time sitting through this one&#39;,
 &#39;have a hard time sitting through this one&#39;,
 &#39;Aggressive self-glorification and a manipulative whitewash&#39;,
 &#39;self-glorification and a manipulative whitewash&#39;]
</code></pre>
<p>**pandas.Series.str.cat ** : 使用给定的分隔符连接系列&#x2F;索引中的字符串。这里我们给一个空格作为分隔符，因此，它将连接每个索引中由空格分隔的所有字符串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">neg_text = pd.Series(neg_words).<span class="hljs-built_in">str</span>.cat(sep=<span class="hljs-string">&#x27; &#x27;</span>)<br>neg_text[:<span class="hljs-number">100</span>]<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&#39;would have a hard time sitting through this one have a hard time sitting through this one Aggressive&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> neg_phrases.Phrase[:<span class="hljs-number">300</span>]:<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;good&#x27;</span> <span class="hljs-keyword">in</span> t:<br>        <span class="hljs-built_in">print</span>(t)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">&#39;s not a particularly good film
covers huge , heavy topics in a bland , surfacey way that does n&#39;t offer any insight into why , for instance , good things happen to bad people .
huge , heavy topics in a bland , surfacey way that does n&#39;t offer any insight into why , for instance , good things happen to bad people
a bland , surfacey way that does n&#39;t offer any insight into why , for instance , good things happen to bad people
</code></pre>
<p>所以，我们可以很清楚地看到，即使文本包含“好”这样的词，也是一种负面情绪，因为它表明这部电影不是一部好电影。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pos_phrases = df_train_1[df_train_1.Sentiment == <span class="hljs-number">4</span>] <span class="hljs-comment">## 4 is positive sentiment</span><br>pos_string = []<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> pos_phrases.Phrase:<br>    pos_string.append(t)<br>pos_text = pd.Series(pos_string).<span class="hljs-built_in">str</span>.cat(sep=<span class="hljs-string">&#x27; &#x27;</span>)<br>pos_text[:<span class="hljs-number">100</span>]<br>    <br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&#39;This quiet , introspective and entertaining independent is worth seeking . quiet , introspective and&#39;
</code></pre>
<h2 id="1-4-2-负面分类影评的词云"><a href="#1-4-2-负面分类影评的词云" class="headerlink" title="1.4.2 负面分类影评的词云"></a><a id='1.4.2'>1.4.2 负面分类影评的词云</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> wordcloud <span class="hljs-keyword">import</span> WordCloud<br>wordcloud = WordCloud(width=<span class="hljs-number">1600</span>, height=<span class="hljs-number">800</span>, max_font_size=<span class="hljs-number">200</span>).generate(neg_text)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.imshow(wordcloud, interpolation=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>plt.axis(<span class="hljs-string">&quot;off&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/wm153z.png" alt="在这里插入图片描述"></p>
<p>一些大的词可以解释得相当中性，例如“film”、“moive”等。我们可以看到一些较小的词在负面电影评论中是有意义的，例如“bad movie”、“dull” 、“boring”等。</p>
<p>然而，在对这部电影的负面分类情绪中，也有一些像“好”这样的词。让我们更深入地了解这些单词&#x2F;文本：</p>
<h2 id="1-4-3-正分类影评的词云"><a href="#1-4-3-正分类影评的词云" class="headerlink" title="1.4.3 正分类影评的词云"></a><a id='1.4.3'>1.4.3 正分类影评的词云</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">wordcloud = WordCloud(width=<span class="hljs-number">1600</span>, height=<span class="hljs-number">800</span>, max_font_size=<span class="hljs-number">200</span>).generate(pos_text)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.imshow(wordcloud, interpolation=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/mqvx0x.png" alt="在这里插入图片描述"></p>
<p>我再次看到一些大尺寸的中性词，“movie”，“film”，但像“good”，“nest”，“fascinating”这样的正面词也很突出。</p>
<h2 id="1-5-所有5个情感类别的总词频"><a href="#1-5-所有5个情感类别的总词频" class="headerlink" title="1.5 所有5个情感类别的总词频"></a><a id='1.5'>1.5 所有5个情感类别的总词频</a></h2><p>我们需要 Term Frequency 数据来查看电影评论中使用了哪些词以及使用了多少次。让我们继续使用 CountVectorizer 来计算词频：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>cvector = CountVectorizer(min_df = <span class="hljs-number">0.0</span>, max_df = <span class="hljs-number">1.0</span>, ngram_range=(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>))<br>cvector.fit(df_train_1.Phrase)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">CountVectorizer(min_df=0.0, ngram_range=(1, 2))
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">len</span>(cvector.get_feature_names())<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">94644
</code></pre>
<p>看起来 count vectorizer 已经从语料库中提取了 94644 个单词。可以使用以下代码块获取每个类的词频。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">All_matrix=[]<br>All_words=[]<br>All_labels=[<span class="hljs-string">&#x27;negative&#x27;</span>,<span class="hljs-string">&#x27;some-negative&#x27;</span>,<span class="hljs-string">&#x27;neutral&#x27;</span>,<span class="hljs-string">&#x27;some-positive&#x27;</span>,<span class="hljs-string">&#x27;positive&#x27;</span>]<br>neg_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">0</span>].Phrase)<br>term_freq_df= pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>([(word, neg_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvector.vocabulary_.items()], key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;negative&#x27;</span>])<br>term_freq_df=term_freq_df.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>):<br>    All_matrix.append(cvector.transform(df_train_1[df_train_1.Sentiment == i].Phrase))<br>    All_words.append(All_matrix[i-<span class="hljs-number">1</span>].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>))<br>    aa=pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>([(word,All_words[i-<span class="hljs-number">1</span>][<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvector.vocabulary_.items()], key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,All_labels[i]])<br>    <br>    term_freq_df=term_freq_df.join(aa.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>),how=<span class="hljs-string">&#x27;left&#x27;</span>,lsuffix=<span class="hljs-string">&#x27;_A&#x27;</span>)<br><br>    <br><br>term_freq_df[<span class="hljs-string">&#x27;total&#x27;</span>] = term_freq_df[<span class="hljs-string">&#x27;negative&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-negative&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;neutral&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-positive&#x27;</span>] +  term_freq_df[<span class="hljs-string">&#x27;positive&#x27;</span>] <br>term_freq_df.sort_values(by=<span class="hljs-string">&#x27;total&#x27;</span>, ascending=<span class="hljs-literal">False</span>).head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>negative</th>
      <th>some-negative</th>
      <th>neutral</th>
      <th>some-positive</th>
      <th>positive</th>
      <th>total</th>
    </tr>
    <tr>
      <th>Terms</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>the</th>
      <td>3462</td>
      <td>10885</td>
      <td>20619</td>
      <td>12459</td>
      <td>4208</td>
      <td>51633</td>
    </tr>
    <tr>
      <th>of</th>
      <td>2277</td>
      <td>6660</td>
      <td>12287</td>
      <td>8405</td>
      <td>3073</td>
      <td>32702</td>
    </tr>
    <tr>
      <th>and</th>
      <td>2549</td>
      <td>6204</td>
      <td>10241</td>
      <td>9180</td>
      <td>4003</td>
      <td>32177</td>
    </tr>
    <tr>
      <th>to</th>
      <td>1916</td>
      <td>5571</td>
      <td>8295</td>
      <td>5411</td>
      <td>1568</td>
      <td>22761</td>
    </tr>
    <tr>
      <th>in</th>
      <td>1038</td>
      <td>2965</td>
      <td>5562</td>
      <td>3365</td>
      <td>1067</td>
      <td>13997</td>
    </tr>
    <tr>
      <th>is</th>
      <td>1372</td>
      <td>3362</td>
      <td>3703</td>
      <td>3489</td>
      <td>1550</td>
      <td>13476</td>
    </tr>
    <tr>
      <th>that</th>
      <td>1139</td>
      <td>2982</td>
      <td>3677</td>
      <td>3280</td>
      <td>1260</td>
      <td>12338</td>
    </tr>
    <tr>
      <th>it</th>
      <td>1086</td>
      <td>3067</td>
      <td>3791</td>
      <td>2927</td>
      <td>863</td>
      <td>11734</td>
    </tr>
    <tr>
      <th>as</th>
      <td>757</td>
      <td>2184</td>
      <td>2941</td>
      <td>2037</td>
      <td>732</td>
      <td>8651</td>
    </tr>
    <tr>
      <th>with</th>
      <td>452</td>
      <td>1533</td>
      <td>2471</td>
      <td>2365</td>
      <td>929</td>
      <td>7750</td>
    </tr>
  </tbody>
</table>
</div>



<p>我们可以清楚地看到，像“the”、“in”、“it”等词的频率要高得多，它们对影评的情绪没有任何意义。另一方面，诸如“悲观可笑”之类的词它们在文档中的出现频率非常低，但似乎与电影的情绪有很大关系。</p>
<h2 id="1-6-电影评论分词展示"><a href="#1-6-电影评论分词展示" class="headerlink" title="1.6 电影评论分词展示"></a><a id='1.6'>1.6 电影评论分词展示</a></h2><p>Next, let’s explore about how different the tokens in two different classes(positive, negative).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>cvec = CountVectorizer(stop_words=<span class="hljs-string">&#x27;english&#x27;</span>,max_features=<span class="hljs-number">10000</span>)<br>cvec.fit(df_train_1.Phrase)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">CountVectorizer(max_features=10000, stop_words=&#39;english&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">0</span>].Phrase)<br>som_neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">1</span>].Phrase)<br>neu_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">2</span>].Phrase)<br>som_pos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">3</span>].Phrase)<br>pos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">4</span>].Phrase)<br><br>neg_words = neg_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>neg_words_freq = [(word, neg_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>neg_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(neg_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;negative&#x27;</span>])<br><br>neg_tf_df = neg_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br><br>som_neg_words = som_neg_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>som_neg_words_freq = [(word, som_neg_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>som_neg_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(som_neg_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;some-negative&#x27;</span>])<br>som_neg_tf_df = som_neg_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>neu_words = neu_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>neu_words_freq = [(word, neu_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>neu_words_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(neu_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;neutral&#x27;</span>])<br>neu_words_tf_df = neu_words_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>som_pos_words = som_pos_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>som_pos_words_freq = [(word, som_pos_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>som_pos_words_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(som_pos_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;some-positive&#x27;</span>])<br>som_pos_words_tf_df = som_pos_words_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>pos_words = pos_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>pos_words_freq = [(word, pos_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>pos_words_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(pos_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;positive&#x27;</span>])<br>pos_words_tf_df = pos_words_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>term_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=<span class="hljs-number">1</span>)<br><br>term_freq_df[<span class="hljs-string">&#x27;total&#x27;</span>] = term_freq_df[<span class="hljs-string">&#x27;negative&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-negative&#x27;</span>] \<br>                                 + term_freq_df[<span class="hljs-string">&#x27;neutral&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-positive&#x27;</span>] \<br>                                 +  term_freq_df[<span class="hljs-string">&#x27;positive&#x27;</span>] <br>        <br>term_freq_df.sort_values(by=<span class="hljs-string">&#x27;total&#x27;</span>, ascending=<span class="hljs-literal">False</span>).head(<span class="hljs-number">15</span>)<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>negative</th>
      <th>some-negative</th>
      <th>neutral</th>
      <th>some-positive</th>
      <th>positive</th>
      <th>total</th>
    </tr>
    <tr>
      <th>Terms</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>film</th>
      <td>480</td>
      <td>1281</td>
      <td>2175</td>
      <td>1848</td>
      <td>949</td>
      <td>6733</td>
    </tr>
    <tr>
      <th>movie</th>
      <td>793</td>
      <td>1463</td>
      <td>2054</td>
      <td>1344</td>
      <td>587</td>
      <td>6241</td>
    </tr>
    <tr>
      <th>like</th>
      <td>332</td>
      <td>942</td>
      <td>1167</td>
      <td>599</td>
      <td>150</td>
      <td>3190</td>
    </tr>
    <tr>
      <th>story</th>
      <td>153</td>
      <td>532</td>
      <td>954</td>
      <td>664</td>
      <td>236</td>
      <td>2539</td>
    </tr>
    <tr>
      <th>rrb</th>
      <td>131</td>
      <td>498</td>
      <td>1112</td>
      <td>551</td>
      <td>146</td>
      <td>2438</td>
    </tr>
    <tr>
      <th>good</th>
      <td>100</td>
      <td>334</td>
      <td>519</td>
      <td>974</td>
      <td>334</td>
      <td>2261</td>
    </tr>
    <tr>
      <th>lrb</th>
      <td>119</td>
      <td>452</td>
      <td>878</td>
      <td>512</td>
      <td>137</td>
      <td>2098</td>
    </tr>
    <tr>
      <th>time</th>
      <td>153</td>
      <td>420</td>
      <td>752</td>
      <td>464</td>
      <td>130</td>
      <td>1919</td>
    </tr>
    <tr>
      <th>characters</th>
      <td>167</td>
      <td>455</td>
      <td>614</td>
      <td>497</td>
      <td>149</td>
      <td>1882</td>
    </tr>
    <tr>
      <th>comedy</th>
      <td>174</td>
      <td>341</td>
      <td>578</td>
      <td>475</td>
      <td>245</td>
      <td>1813</td>
    </tr>
    <tr>
      <th>just</th>
      <td>216</td>
      <td>598</td>
      <td>550</td>
      <td>282</td>
      <td>82</td>
      <td>1728</td>
    </tr>
    <tr>
      <th>life</th>
      <td>77</td>
      <td>200</td>
      <td>729</td>
      <td>544</td>
      <td>168</td>
      <td>1718</td>
    </tr>
    <tr>
      <th>does</th>
      <td>135</td>
      <td>566</td>
      <td>519</td>
      <td>375</td>
      <td>79</td>
      <td>1674</td>
    </tr>
    <tr>
      <th>little</th>
      <td>109</td>
      <td>492</td>
      <td>580</td>
      <td>339</td>
      <td>85</td>
      <td>1605</td>
    </tr>
    <tr>
      <th>funny</th>
      <td>73</td>
      <td>257</td>
      <td>267</td>
      <td>639</td>
      <td>347</td>
      <td>1583</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="1-6-1-负面影评中最常用的50个词"><a href="#1-6-1-负面影评中最常用的50个词" class="headerlink" title="1.6.1 负面影评中最常用的50个词"></a><a id='1.6.1'>1.6.1 负面影评中最常用的50个词</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">y_pos = np.arange(<span class="hljs-number">50</span>)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.bar(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;negative&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;negative&#x27;</span>][:<span class="hljs-number">50</span>], align=<span class="hljs-string">&#x27;center&#x27;</span>, alpha=<span class="hljs-number">0.5</span>)<br>plt.xticks(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;negative&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;negative&#x27;</span>][:<span class="hljs-number">50</span>].index,rotation=<span class="hljs-string">&#x27;vertical&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Frequency&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Top 50 negative tokens&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Top 50 tokens in negative movie reviews&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Top 50 tokens in negative movie reviews&#39;)
</code></pre>
<p><img src="https://ptpimg.me/yw0h81.png" alt="在这里插入图片描述"></p>
<p>我们可以看到一些负面词，如“坏”、“最差”、“沉闷”是一些高频词。但是，存在有像“电影”、“电影”、“分钟”这样的中性词支配频率图。</p>
<p>我们再看一下条形图上的前 50 个正面标记</p>
<h2 id="1-6-2-正面影评中最常用的50个词"><a href="#1-6-2-正面影评中最常用的50个词" class="headerlink" title="1.6.2 正面影评中最常用的50个词"></a><a id='1.6.2'>1.6.2 正面影评中最常用的50个词</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">y_pos = np.arange(<span class="hljs-number">50</span>)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.bar(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;positive&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;positive&#x27;</span>][:<span class="hljs-number">50</span>], align=<span class="hljs-string">&#x27;center&#x27;</span>, alpha=<span class="hljs-number">0.5</span>)<br>plt.xticks(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;positive&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;positive&#x27;</span>][:<span class="hljs-number">50</span>].index,rotation=<span class="hljs-string">&#x27;vertical&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Frequency&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Top 50 positive tokens&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Top 50 tokens in positive movie reviews&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Top 50 tokens in positive movie reviews&#39;)
</code></pre>
<p><img src="https://ptpimg.me/e5x807.png" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-HLxcm1VK-1640793547488)(sentiment-analysis-countvectorizer-tf-idf_files/sentiment-analysis-countvectorizer-tf-idf_51_1.png)]"></p>
<p>Once again, there are some neutral words like “film”, “movie”, are quite high up in the rank.</p>
<h2 id="2-传统的监督机器学习模型"><a href="#2-传统的监督机器学习模型" class="headerlink" title="2. 传统的监督机器学习模型"></a><a id='2'>2. 传统的监督机器学习模型</a></h2><h2 id="2-1-特征工程"><a href="#2-1-特征工程" class="headerlink" title="2.1 特征工程"></a><a id='2.1'>2.1 特征工程</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">phrase = np.array(df_train_1[<span class="hljs-string">&#x27;Pﬁhrase&#x27;</span>])<br>sentiments = np.array(df_train_1[<span class="hljs-string">&#x27;Sentiment&#x27;</span>])<br><span class="hljs-comment"># build train and test datasets</span><br><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split    <br>phrase_train, phrase_test, sentiments_train, sentiments_test = train_test_split(phrase, sentiments, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure>

<p>Next, we will try to see how different are the tokens in 4 different classes(positive,some positive,neutral, some negative, negative). </p>
<h2 id="2-2-CountVectorizer-TF-IDF-的实现"><a href="#2-2-CountVectorizer-TF-IDF-的实现" class="headerlink" title="2.2 CountVectorizer &amp; TF-IDF 的实现"></a><a id='2.2'>2.2 CountVectorizer &amp; TF-IDF 的实现</h2><h2 id="2-2-1-CountVectorizer"><a href="#2-2-1-CountVectorizer" class="headerlink" title="2.2.1 CountVectorizer"></a><a id='2.2.1'>2.2.1 CountVectorizer</a></h2><p>众所周知，所有机器学习算法都擅长数字；我们必须在不丢失大量信息的情况下将文本数据提取或转换为数字。进行这种转换的一种方法是词袋 (BOW)，它为每个词提供一个数字，但效率非常低。因此，一种方法是通过CountVectorizer：它计算文档中的单词数，即将文本文档集合转换为文档中每个单词出现次数的矩阵。 </p>
<p>例如：如果我们有如下 3 个文本文档的集合，那么 CountVectorizer 会将其转换为文档中每个单词出现的单独计数，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">cv1 = CountVectorizer()<br>x_traincv = cv1.fit_transform([<span class="hljs-string">&quot;Hi How are you How are you doing&quot;</span>,<span class="hljs-string">&quot;Hi what&#x27;s up&quot;</span>,<span class="hljs-string">&quot;Wow that&#x27;s awesome&quot;</span>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">x_traincv_df = pd.DataFrame(x_traincv.toarray(),columns=<span class="hljs-built_in">list</span>(cv1.get_feature_names()))<br>x_traincv_df<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">/Users/gawaintan/miniforge3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>are</th>
      <th>awesome</th>
      <th>doing</th>
      <th>hi</th>
      <th>how</th>
      <th>that</th>
      <th>up</th>
      <th>what</th>
      <th>wow</th>
      <th>you</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>现在，在 CountVectorizer 的情况下，我们只是在计算文档中的单词数量，很多时候，“are”、“you”、“hi”等单词的数量非常大，这将支配我们的机器学习算法的结果。</p>
<h2 id="2-2-2-TF-IDF-与-CountVectorizer-有何不同？"><a href="#2-2-2-TF-IDF-与-CountVectorizer-有何不同？" class="headerlink" title="2.2.2 TF-IDF 与 CountVectorizer 有何不同？"></a><a id='2.2.2'>2.2.2 TF-IDF 与 CountVectorizer 有何不同？</a></h2><p>因此，TF-IDF（代表Term-Frequency-Inverse-Document Frequency）降低了几乎所有文档中出现的常见词的权重，并更加重视出现在文档子集中的词。TF-IDF 的工作原理是通过分配较低的权重来惩罚这些常用词，同时重视特定文档中的一些稀有词。</p>
<h2 id="2-2-3-CountVectorizer参数设置"><a href="#2-2-3-CountVectorizer参数设置" class="headerlink" title="2.2.3 CountVectorizer参数设置"></a><a id='2.2.3'>2.2.3 CountVectorizer参数设置</a></h2><p>对于 CountVectorizer 这一次，停用词不会有太大帮助，因为相同的高频词，例如“the”、“to”，在两个类中的出现频率相同。如果这些停用词支配两个类，我将无法获得有意义的结果。因此，我决定删除停用词，并且还将使用 countvectorizer 将 max_features 限制为 10,000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer, TfidfVectorizer<br><br><span class="hljs-comment">## Build Bag-Of-Words on train phrases</span><br>cv = CountVectorizer(stop_words=<span class="hljs-string">&#x27;english&#x27;</span>,max_features=<span class="hljs-number">10000</span>)<br>cv_train_features = cv.fit_transform(phrase_train)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># build TFIDF features on train reviews</span><br>tv = TfidfVectorizer(min_df=<span class="hljs-number">0.0</span>, max_df=<span class="hljs-number">1.0</span>, ngram_range=(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),<br>                     sublinear_tf=<span class="hljs-literal">True</span>)<br>tv_train_features = tv.fit_transform(phrase_train)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># transform test reviews into features</span><br>cv_test_features = cv.transform(phrase_test)<br>tv_test_features = tv.transform(phrase_test)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;BOW model:&gt; Train features shape:&#x27;</span>, cv_train_features.shape, <span class="hljs-string">&#x27; Test features shape:&#x27;</span>, cv_test_features.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;TFIDF model:&gt; Train features shape:&#x27;</span>, tv_train_features.shape, <span class="hljs-string">&#x27; Test features shape:&#x27;</span>, tv_test_features.shape)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">BOW model:&gt; Train features shape: (124848, 10000)  Test features shape: (31212, 10000)
TFIDF model:&gt; Train features shape: (124848, 93697)  Test features shape: (31212, 93697)
</code></pre>
<h2 id="2-3-模型训练、预测和性能评估"><a href="#2-3-模型训练、预测和性能评估" class="headerlink" title="2.3 模型训练、预测和性能评估"></a><a id='2.3'>2.3 模型训练、预测和性能评估</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">####Evaluation metrics</span><br><br><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder<br><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> clone<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> label_binarize<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> interp<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve, auc <br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_metrics</span>(<span class="hljs-params">true_labels, predicted_labels</span>):<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.accuracy_score(true_labels, <br>                                               predicted_labels),<br>                        <span class="hljs-number">4</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Precision:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.precision_score(true_labels, <br>                                               predicted_labels,<br>                                               average=<span class="hljs-string">&#x27;weighted&#x27;</span>),<br>                        <span class="hljs-number">4</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Recall:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.recall_score(true_labels, <br>                                               predicted_labels,<br>                                               average=<span class="hljs-string">&#x27;weighted&#x27;</span>),<br>                        <span class="hljs-number">4</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;F1 Score:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.f1_score(true_labels, <br>                                               predicted_labels,<br>                                               average=<span class="hljs-string">&#x27;weighted&#x27;</span>),<br>                        <span class="hljs-number">4</span>))<br>                        <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_predict_model</span>(<span class="hljs-params">classifier, </span><br><span class="hljs-params">                        train_features, train_labels, </span><br><span class="hljs-params">                        test_features, test_labels</span>):<br>    <span class="hljs-comment"># build model    </span><br>    classifier.fit(train_features, train_labels)<br>    <span class="hljs-comment"># predict using model</span><br>    predictions = classifier.predict(test_features) <br>    <span class="hljs-keyword">return</span> predictions    <br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_confusion_matrix</span>(<span class="hljs-params">true_labels, predicted_labels, classes=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]</span>):<br>    <br>    total_classes = <span class="hljs-built_in">len</span>(classes)<br>    level_labels = [total_classes*[<span class="hljs-number">0</span>], <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(total_classes))]<br><br>    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, <br>                                  labels=classes)<br>    cm_frame = pd.DataFrame(data=cm, <br>                            columns=pd.MultiIndex(levels=[[<span class="hljs-string">&#x27;Predicted:&#x27;</span>], classes], <br>                                                  codes=level_labels), <br>                            index=pd.MultiIndex(levels=[[<span class="hljs-string">&#x27;Actual:&#x27;</span>], classes], <br>                                                codes=level_labels)) <br>    <span class="hljs-built_in">print</span>(cm_frame) <br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_classification_report</span>(<span class="hljs-params">true_labels, predicted_labels, classes=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]</span>):<br><br>    report = metrics.classification_report(y_true=true_labels, <br>                                           y_pred=predicted_labels, <br>                                           labels=classes) <br>    <span class="hljs-built_in">print</span>(report)<br>    <br>    <br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_model_performance_metrics</span>(<span class="hljs-params">true_labels, predicted_labels, classes=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Model Performance metrics:&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span>*<span class="hljs-number">30</span>)<br>    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nModel Classification report:&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span>*<span class="hljs-number">30</span>)<br>    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, <br>                                  classes=classes)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nPrediction Confusion Matrix:&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span>*<span class="hljs-number">30</span>)<br>    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, <br>                             classes=classes)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_model_decision_surface</span>(<span class="hljs-params">clf, train_features, train_labels,</span><br><span class="hljs-params">                                plot_step=<span class="hljs-number">0.02</span>, cmap=plt.cm.RdYlBu,</span><br><span class="hljs-params">                                markers=<span class="hljs-literal">None</span>, alphas=<span class="hljs-literal">None</span>, colors=<span class="hljs-literal">None</span></span>):<br>    <br>    <span class="hljs-keyword">if</span> train_features.shape[<span class="hljs-number">1</span>] != <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;X_train should have exactly 2 columnns!&quot;</span>)<br>    <br>    x_min, x_max = train_features[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">min</span>() - plot_step, train_features[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>() + plot_step<br>    y_min, y_max = train_features[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">min</span>() - plot_step, train_features[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">max</span>() + plot_step<br>    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),<br>                         np.arange(y_min, y_max, plot_step))<br><br>    clf_est = clone(clf)<br>    clf_est.fit(train_features,train_labels)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf_est, <span class="hljs-string">&#x27;predict_proba&#x27;</span>):<br>        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">else</span>:<br>        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    <br>    Z = Z.reshape(xx.shape)<br>    cs = plt.contourf(xx, yy, Z, cmap=cmap)<br>    <br>    le = LabelEncoder()<br>    y_enc = le.fit_transform(train_labels)<br>    n_classes = <span class="hljs-built_in">len</span>(le.classes_)<br>    plot_colors = <span class="hljs-string">&#x27;&#x27;</span>.join(colors) <span class="hljs-keyword">if</span> colors <span class="hljs-keyword">else</span> [<span class="hljs-literal">None</span>] * n_classes<br>    label_names = le.classes_<br>    markers = markers <span class="hljs-keyword">if</span> markers <span class="hljs-keyword">else</span> [<span class="hljs-literal">None</span>] * n_classes<br>    alphas = alphas <span class="hljs-keyword">if</span> alphas <span class="hljs-keyword">else</span> [<span class="hljs-literal">None</span>] * n_classes<br>    <span class="hljs-keyword">for</span> i, color <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(n_classes), plot_colors):<br>        idx = np.where(y_enc == i)<br>        plt.scatter(train_features[idx, <span class="hljs-number">0</span>], train_features[idx, <span class="hljs-number">1</span>], c=color,<br>                    label=label_names[i], cmap=cmap, edgecolors=<span class="hljs-string">&#x27;black&#x27;</span>, <br>                    marker=markers[i], alpha=alphas[i])<br>    plt.legend()<br>    plt.show()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_model_roc_curve</span>(<span class="hljs-params">clf, features, true_labels, label_encoder=<span class="hljs-literal">None</span>, class_names=<span class="hljs-literal">None</span></span>):<br>    <br>    <span class="hljs-comment">## Compute ROC curve and ROC area for each class</span><br>    fpr = <span class="hljs-built_in">dict</span>()<br>    tpr = <span class="hljs-built_in">dict</span>()<br>    roc_auc = <span class="hljs-built_in">dict</span>()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;classes_&#x27;</span>):<br>        class_labels = clf.classes_<br>    <span class="hljs-keyword">elif</span> label_encoder:<br>        class_labels = label_encoder.classes_<br>    <span class="hljs-keyword">elif</span> class_names:<br>        class_labels = class_names<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Unable to derive prediction classes, please specify class_names!&#x27;</span>)<br>    n_classes = <span class="hljs-built_in">len</span>(class_labels)<br>    y_test = label_binarize(true_labels, classes=class_labels)<br>    <span class="hljs-keyword">if</span> n_classes == <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;predict_proba&#x27;</span>):<br>            prob = clf.predict_proba(features)<br>            y_score = prob[:, prob.shape[<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>] <br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;decision_function&#x27;</span>):<br>            prob = clf.decision_function(features)<br>            y_score = prob[:, prob.shape[<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> AttributeError(<span class="hljs-string">&quot;Estimator doesn&#x27;t have a probability or confidence scoring system!&quot;</span>)<br>        <br>        fpr, tpr, _ = roc_curve(y_test, y_score)      <br>        roc_auc = auc(fpr, tpr)<br>        plt.plot(fpr, tpr, label=<span class="hljs-string">&#x27;ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br>                                 <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(roc_auc),<br>                 linewidth=<span class="hljs-number">2.5</span>)<br>        <br>    <span class="hljs-keyword">elif</span> n_classes &gt; <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;predict_proba&#x27;</span>):<br>            y_score = clf.predict_proba(features)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;decision_function&#x27;</span>):<br>            y_score = clf.decision_function(features)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> AttributeError(<span class="hljs-string">&quot;Estimator doesn&#x27;t have a probability or confidence scoring system!&quot;</span>)<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_classes):<br>            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])<br>            roc_auc[i] = auc(fpr[i], tpr[i])<br><br>        <span class="hljs-comment">## Compute micro-average ROC curve and ROC area</span><br>        fpr[<span class="hljs-string">&quot;micro&quot;</span>], tpr[<span class="hljs-string">&quot;micro&quot;</span>], _ = roc_curve(y_test.ravel(), y_score.ravel())<br>        roc_auc[<span class="hljs-string">&quot;micro&quot;</span>] = auc(fpr[<span class="hljs-string">&quot;micro&quot;</span>], tpr[<span class="hljs-string">&quot;micro&quot;</span>])<br><br>        <span class="hljs-comment">## Compute macro-average ROC curve and ROC area</span><br>        <span class="hljs-comment"># First aggregate all false positive rates</span><br>        all_fpr = np.unique(np.concatenate([fpr[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_classes)]))<br>        <span class="hljs-comment"># Then interpolate all ROC curves at this points</span><br>        mean_tpr = np.zeros_like(all_fpr)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_classes):<br>            mean_tpr += interp(all_fpr, fpr[i], tpr[i])<br>        <span class="hljs-comment"># Finally average it and compute AUC</span><br>        mean_tpr /= n_classes<br>        fpr[<span class="hljs-string">&quot;macro&quot;</span>] = all_fpr<br>        tpr[<span class="hljs-string">&quot;macro&quot;</span>] = mean_tpr<br>        roc_auc[<span class="hljs-string">&quot;macro&quot;</span>] = auc(fpr[<span class="hljs-string">&quot;macro&quot;</span>], tpr[<span class="hljs-string">&quot;macro&quot;</span>])<br><br>        <span class="hljs-comment">## Plot ROC curves</span><br>        plt.figure(figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">4</span>))<br>        plt.plot(fpr[<span class="hljs-string">&quot;micro&quot;</span>], tpr[<span class="hljs-string">&quot;micro&quot;</span>],<br>                 label=<span class="hljs-string">&#x27;micro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br>                       <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(roc_auc[<span class="hljs-string">&quot;micro&quot;</span>]), linewidth=<span class="hljs-number">3</span>)<br><br>        plt.plot(fpr[<span class="hljs-string">&quot;macro&quot;</span>], tpr[<span class="hljs-string">&quot;macro&quot;</span>],<br>                 label=<span class="hljs-string">&#x27;macro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br>                       <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(roc_auc[<span class="hljs-string">&quot;macro&quot;</span>]), linewidth=<span class="hljs-number">3</span>)<br><br>        <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(class_labels):<br>            plt.plot(fpr[i], tpr[i], label=<span class="hljs-string">&#x27;ROC curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span><br>                                           <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(label, roc_auc[i]), <br>                     linewidth=<span class="hljs-number">2</span>, linestyle=<span class="hljs-string">&#x27;:&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Number of classes should be atleast 2 or more&#x27;</span>)<br>        <br>    plt.plot([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;k--&#x27;</span>)<br>    plt.xlim([<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>])<br>    plt.ylim([<span class="hljs-number">0.0</span>, <span class="hljs-number">1.05</span>])<br>    plt.xlabel(<span class="hljs-string">&#x27;False Positive Rate&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;True Positive Rate&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Receiver Operating Characteristic (ROC) Curve&#x27;</span>)<br>    plt.legend(loc=<span class="hljs-string">&quot;lower right&quot;</span>)<br>    plt.show()<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier, LogisticRegression<br><br>lr = LogisticRegression(penalty=<span class="hljs-string">&#x27;l2&#x27;</span>, max_iter=<span class="hljs-number">100</span>, C=<span class="hljs-number">1</span>)<br>sgd = SGDClassifier(loss=<span class="hljs-string">&#x27;hinge&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-3-1-CountVectorizer-上的逻辑回归模型"><a href="#2-3-1-CountVectorizer-上的逻辑回归模型" class="headerlink" title="2.3.1 CountVectorizer 上的逻辑回归模型"></a><a id='2.3.1'>2.3.1 CountVectorizer 上的逻辑回归模型</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Logistic Regression model on BOW features</span><br>lr_bow_predictions = train_predict_model(classifier=lr, <br>                                             train_features=cv_train_features, train_labels=sentiments_train,<br>                                             test_features=cv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_bow_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br>                                    <br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.6369
Precision: 0.6177
Recall: 0.6369
F1 Score: 0.6132

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.55      0.28      0.37      1426
           1       0.53      0.36      0.43      5428
           2       0.68      0.87      0.77     15995
           3       0.57      0.45      0.50      6603
           4       0.56      0.34      0.42      1760

    accuracy                           0.64     31212
   macro avg       0.58      0.46      0.50     31212
weighted avg       0.62      0.64      0.61     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        393   626    349    53    5
        1        251  1967   2936   255   19
        2         57   862  13982  1031   63
        3         15   236   3023  2941  388
        4          1    23    253   888  595
</code></pre>
<h2 id="2-3-2-基于-TF-IDF-特征的逻辑回归模型"><a href="#2-3-2-基于-TF-IDF-特征的逻辑回归模型" class="headerlink" title="2.3.2 基于 TF-IDF 特征的逻辑回归模型"></a><a id='2.3.2'>2.3.2 基于 TF-IDF 特征的逻辑回归模型</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Logistic Regression model on TF-IDF features</span><br>lr_tfidf_predictions = train_predict_model(classifier=lr, <br>                                               train_features=tv_train_features, train_labels=sentiments_train,<br>                                               test_features=tv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_tfidf_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.6455
Precision: 0.6314
Recall: 0.6455
F1 Score: 0.6189

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.60      0.22      0.32      1426
           1       0.56      0.38      0.45      5428
           2       0.67      0.89      0.77     15995
           3       0.60      0.47      0.53      6603
           4       0.60      0.29      0.39      1760

    accuracy                           0.65     31212
   macro avg       0.61      0.45      0.49     31212
weighted avg       0.63      0.65      0.62     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        312   681    408    22    3
        1        177  2051   3066   125    9
        2         29   793  14193   944   36
        3          2   109   3115  3088  289
        4          0     9    281   966  504
</code></pre>
<h2 id="2-3-3-基于Countvectorizer的SGD模型"><a href="#2-3-3-基于Countvectorizer的SGD模型" class="headerlink" title="2.3.3 基于Countvectorizer的SGD模型"></a><a id='2.3.3'>2.3.3 基于Countvectorizer的SGD模型</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SGD model on Countvectorizer</span><br>sgd_bow_predictions = train_predict_model(classifier=sgd, <br>                                             train_features=cv_train_features, train_labels=sentiments_train,<br>                                             test_features=cv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_bow_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.5988
Precision: 0.5776
Recall: 0.5988
F1 Score: 0.5455

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.52      0.23      0.32      1426
           1       0.54      0.19      0.28      5428
           2       0.62      0.93      0.74     15995
           3       0.54      0.30      0.38      6603
           4       0.52      0.29      0.37      1760

    accuracy                           0.60     31212
   macro avg       0.55      0.39      0.42     31212
weighted avg       0.58      0.60      0.55     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        332   392    646    49    7
        1        234  1025   3909   230   30
        2         56   371  14874   637   57
        3         18   106   4156  1956  367
        4          4    15    502   735  504
</code></pre>
<h2 id="2-3-4-基于TF-IDF的SGD模型"><a href="#2-3-4-基于TF-IDF的SGD模型" class="headerlink" title="2.3.4 基于TF-IDF的SGD模型"></a><a id='2.3.4'>2.3.4 基于TF-IDF的SGD模型</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SGD model on TF-IDF</span><br>sgd_tfidf_predictions = train_predict_model(classifier=sgd, <br>                                                train_features=tv_train_features, train_labels=sentiments_train,<br>                                                test_features=tv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_tfidf_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.5594
Precision: 0.5543
Recall: 0.5594
F1 Score: 0.4666

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.60      0.11      0.18      1426
           1       0.52      0.09      0.16      5428
           2       0.56      0.97      0.71     15995
           3       0.55      0.16      0.25      6603
           4       0.59      0.15      0.24      1760

    accuracy                           0.56     31212
   macro avg       0.56      0.30      0.31     31212
weighted avg       0.55      0.56      0.47     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                       
                   0    1      2     3    4
Actual: 0        152  241   1020    13    0
        1         83  512   4759    67    7
        2         17  193  15447   315   23
        3          2   38   5328  1085  150
        4          0    2    993   502  263
</code></pre>
<h2 id="2-3-5-基于TF-IDF的随机森林模型"><a href="#2-3-5-基于TF-IDF的随机森林模型" class="headerlink" title="2.3.5 基于TF-IDF的随机森林模型"></a><a id='2.3.5'>2.3.5 基于TF-IDF的随机森林模型</a></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br>rfc = RandomForestClassifier(n_jobs=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># RandomForest model on TF-IDF</span><br>rfc_tfidf_predictions = train_predict_model(classifier=rfc, <br>                                                train_features=tv_train_features, train_labels=sentiments_train,<br>                                                test_features=tv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=rfc_tfidf_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.6423
Precision: 0.6267
Recall: 0.6423
F1 Score: 0.6274

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.47      0.36      0.41      1426
           1       0.56      0.42      0.48      5428
           2       0.70      0.84      0.76     15995
           3       0.58      0.46      0.51      6603
           4       0.50      0.40      0.45      1760

    accuracy                           0.64     31212
   macro avg       0.56      0.50      0.52     31212
weighted avg       0.63      0.64      0.63     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        520   605    283    17    1
        1        465  2281   2539   133   10
        2        101  1094  13479  1258   63
        3          8   115   2793  3057  630
        4          2     6    217   825  710
</code></pre>
<p><strong>基于TF-IDF的逻辑回归模型优于其他机器学习算法</strong>. </p>
]]></content>
  </entry>
</search>
