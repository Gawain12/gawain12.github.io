

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Gawain">
  <meta name="keywords" content="Share">
  
    <meta name="description" content="ä¸€ã€èƒŒæ™¯æ–‡æœ¬å¤„ç†æ˜¯è®¸å¤šMLåº”ç”¨ç¨‹åºä¸­æœ€å¸¸è§çš„ä»»åŠ¡ä¹‹ä¸€ã€‚ä»¥ä¸‹æ˜¯æ­¤ç±»åº”ç”¨çš„ä¸€äº›ç¤ºä¾‹  è¯­è¨€ç¿»è¯‘ï¼šå°†å¥å­ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ æƒ…ç»ªåˆ†æï¼šä»æ–‡æœ¬è¯­æ–™åº“ä¸­ç¡®å®šå¯¹ä»»ä½•ä¸»é¢˜æˆ–äº§å“ç­‰çš„æƒ…ç»ªæ˜¯ç§¯æçš„ã€æ¶ˆæçš„è¿˜æ˜¯ä¸­æ€§çš„ åƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼šæ£€æµ‹æœªç»è¯·æ±‚å’Œä¸éœ€è¦çš„ç”µå­é‚®ä»¶&#x2F;æ¶ˆæ¯ã€‚  è¿™äº›åº”ç”¨ç¨‹åºå¤„ç†å¤§é‡æ–‡æœ¬ä»¥æ‰§è¡Œåˆ†ç±»æˆ–ç¿»è¯‘ï¼Œå¹¶ä¸”æ¶‰åŠå¤§é‡åç«¯å·¥ä½œã€‚å°†æ–‡æœ¬è½¬æ¢ä¸ºç®—æ³•å¯ä»¥æ¶ˆåŒ–çš„å†…å®¹æ˜¯ä¸€ä¸ªå¤æ‚çš„è¿‡ç¨‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†">
<meta property="og:type" content="article">
<meta property="og:title" content="æœºå™¨å­¦ä¹ -æ–‡æœ¬å¤„ç†ä¹‹ç”µå½±è¯„è®ºå¤šåˆ†ç±»æƒ…æ„Ÿåˆ†æ">
<meta property="og:url" content="https://gawain12.github.io/2022/09/02/motionanalys/index.html">
<meta property="og:site_name" content="Gawain&#39;s notes">
<meta property="og:description" content="ä¸€ã€èƒŒæ™¯æ–‡æœ¬å¤„ç†æ˜¯è®¸å¤šMLåº”ç”¨ç¨‹åºä¸­æœ€å¸¸è§çš„ä»»åŠ¡ä¹‹ä¸€ã€‚ä»¥ä¸‹æ˜¯æ­¤ç±»åº”ç”¨çš„ä¸€äº›ç¤ºä¾‹  è¯­è¨€ç¿»è¯‘ï¼šå°†å¥å­ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ æƒ…ç»ªåˆ†æï¼šä»æ–‡æœ¬è¯­æ–™åº“ä¸­ç¡®å®šå¯¹ä»»ä½•ä¸»é¢˜æˆ–äº§å“ç­‰çš„æƒ…ç»ªæ˜¯ç§¯æçš„ã€æ¶ˆæçš„è¿˜æ˜¯ä¸­æ€§çš„ åƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼šæ£€æµ‹æœªç»è¯·æ±‚å’Œä¸éœ€è¦çš„ç”µå­é‚®ä»¶&#x2F;æ¶ˆæ¯ã€‚  è¿™äº›åº”ç”¨ç¨‹åºå¤„ç†å¤§é‡æ–‡æœ¬ä»¥æ‰§è¡Œåˆ†ç±»æˆ–ç¿»è¯‘ï¼Œå¹¶ä¸”æ¶‰åŠå¤§é‡åç«¯å·¥ä½œã€‚å°†æ–‡æœ¬è½¬æ¢ä¸ºç®—æ³•å¯ä»¥æ¶ˆåŒ–çš„å†…å®¹æ˜¯ä¸€ä¸ªå¤æ‚çš„è¿‡ç¨‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ptpimg.me/4ix0bu.png">
<meta property="og:image" content="https://ptpimg.me/i136y0.png">
<meta property="og:image" content="https://ptpimg.me/0nux0t.png">
<meta property="og:image" content="https://ptpimg.me/1blyr8.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/72e054ceb9fb8ebddc1a279dcefa8606.png">
<meta property="og:image" content="https://ptpimg.me/wm153z.png">
<meta property="og:image" content="https://ptpimg.me/mqvx0x.png">
<meta property="og:image" content="https://ptpimg.me/yw0h81.png">
<meta property="og:image" content="https://ptpimg.me/e5x807.png">
<meta property="article:published_time" content="2022-09-01T17:29:04.000Z">
<meta property="article:modified_time" content="2025-03-17T18:00:27.519Z">
<meta property="article:author" content="Gawain">
<meta property="article:tag" content="ml">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://ptpimg.me/4ix0bu.png">
  
  
  
  <title>æœºå™¨å­¦ä¹ -æ–‡æœ¬å¤„ç†ä¹‹ç”µå½±è¯„è®ºå¤šåˆ†ç±»æƒ…æ„Ÿåˆ†æ - Gawain&#39;s notes</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"gawain12.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"FeJdeqy6cDDAySGfsLP8g1bl-MdYXbMMI","app_key":"Hj6SxzGjyvHq8tHLJTqtcyHZ","server_url":"https://fejdeqy6.api.lncldglobal.com","path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Gawain&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>å½’æ¡£</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-category-fill"></i>
                <span>ä¹¦å½±éŸ³è®°å½•</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/books/" target="_self">
                    <i class="icofont-abc"></i>
                    <span>ğŸ“–æ–‡å­¦</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/movies/" target="_self">
                    <i class="icofont-love"></i>
                    <span>ğŸ¬ç”µå½±</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/songs/" target="_self">
                    <i class="icofont-notebook"></i>
                    <span>ğŸµéŸ³ä¹</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/remark/" target="_self">
                
                <span>ç•™è¨€æ¿</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>å…³äº</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="æœºå™¨å­¦ä¹ -æ–‡æœ¬å¤„ç†ä¹‹ç”µå½±è¯„è®ºå¤šåˆ†ç±»æƒ…æ„Ÿåˆ†æ"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-09-02 01:29" pubdate>
          2022å¹´9æœˆ2æ—¥ å‡Œæ™¨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.6k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          48 åˆ†é’Ÿ
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">æœºå™¨å­¦ä¹ -æ–‡æœ¬å¤„ç†ä¹‹ç”µå½±è¯„è®ºå¤šåˆ†ç±»æƒ…æ„Ÿåˆ†æ</h1>
            
              <p id="updated-time" class="note note-info" style="">
                
                  
                    æœ¬æ–‡æœ€åæ›´æ–°äº 2025å¹´3æœˆ18æ—¥ å‡Œæ™¨
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="ä¸€ã€èƒŒæ™¯"><a href="#ä¸€ã€èƒŒæ™¯" class="headerlink" title="ä¸€ã€èƒŒæ™¯"></a>ä¸€ã€èƒŒæ™¯</h1><p>æ–‡æœ¬å¤„ç†æ˜¯è®¸å¤šMLåº”ç”¨ç¨‹åºä¸­æœ€å¸¸è§çš„ä»»åŠ¡ä¹‹ä¸€ã€‚ä»¥ä¸‹æ˜¯æ­¤ç±»åº”ç”¨çš„ä¸€äº›ç¤ºä¾‹</p>
<ul>
<li>è¯­è¨€ç¿»è¯‘ï¼šå°†å¥å­ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€</li>
<li>æƒ…ç»ªåˆ†æï¼šä»æ–‡æœ¬è¯­æ–™åº“ä¸­ç¡®å®šå¯¹ä»»ä½•ä¸»é¢˜æˆ–äº§å“ç­‰çš„æƒ…ç»ªæ˜¯ç§¯æçš„ã€æ¶ˆæçš„è¿˜æ˜¯ä¸­æ€§çš„</li>
<li>åƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼šæ£€æµ‹æœªç»è¯·æ±‚å’Œä¸éœ€è¦çš„ç”µå­é‚®ä»¶&#x2F;æ¶ˆæ¯ã€‚</li>
</ul>
<p>è¿™äº›åº”ç”¨ç¨‹åºå¤„ç†å¤§é‡æ–‡æœ¬ä»¥æ‰§è¡Œåˆ†ç±»æˆ–ç¿»è¯‘ï¼Œå¹¶ä¸”æ¶‰åŠå¤§é‡åç«¯å·¥ä½œã€‚å°†æ–‡æœ¬è½¬æ¢ä¸ºç®—æ³•å¯ä»¥æ¶ˆåŒ–çš„å†…å®¹æ˜¯ä¸€ä¸ªå¤æ‚çš„è¿‡ç¨‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºæ–‡æœ¬å¤„ç†ä¸­æ¶‰åŠçš„æ­¥éª¤ã€‚</p>
<h1 id="äºŒã€æ•°æ®é¢„å¤„ç†"><a href="#äºŒã€æ•°æ®é¢„å¤„ç†" class="headerlink" title="äºŒã€æ•°æ®é¢„å¤„ç†"></a>äºŒã€æ•°æ®é¢„å¤„ç†</h1><ul>
<li>åˆ†è¯â€”â€”å°†å¥å­è½¬åŒ–ä¸ºè¯è¯­</li>
<li>å»é™¤å¤šä½™çš„æ ‡ç‚¹ç¬¦å·</li>
<li>å»é™¤åœç”¨è¯â€”â€”é«˜é¢‘å‡ºç°çš„â€œçš„ã€äº†â€ä¹‹ç±»çš„è¯ï¼Œä»–ä»¬å¯¹è¯­ä¹‰åˆ†ææ²¡å¸®åŠ©</li>
<li>è¯å¹²æå–â€”â€”é€šè¿‡åˆ é™¤ä¸å¿…è¦çš„å­—ç¬¦ï¼ˆé€šå¸¸æ˜¯åç¼€ï¼‰ï¼Œå°†å•è¯ç¼©å‡ä¸ºè¯æ ¹ã€‚</li>
<li>è¯å½¢è¿˜åŸâ€”â€”é€šè¿‡ç¡®å®šè¯æ€§å¹¶åˆ©ç”¨è¯­è¨€çš„è¯¦ç»†æ•°æ®åº“æ¥æ¶ˆé™¤å±ˆæŠ˜å˜åŒ–çš„å¦ä¸€ç§æ–¹æ³•ã€‚</li>
</ul>
<p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨pythonè¿›è¡Œè®¸å¤šæ–‡æœ¬é¢„å¤„ç†æ“ä½œã€‚</p>
<p>NLTKï¼ˆNatural Language Toolkitï¼‰ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·åŒ…ï¼Œåœ¨NLPï¼ˆè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰é¢†åŸŸä¸­ï¼Œæœ€å¸¸ä½¿ç”¨çš„ä¸€ä¸ªPythonåº“ã€‚è‡ªå¸¦è¯­æ–™åº“ï¼Œè¯æ€§åˆ†ç±»åº“ã€‚è‡ªå¸¦åˆ†ç±»ï¼Œåˆ†è¯åŠŸèƒ½ã€‚ </p>
<p><strong>åˆ†è¯ï¼ˆTokenizeï¼‰</strong>ï¼šword_tokenizeç”Ÿæˆä¸€ä¸ªè¯çš„åˆ—è¡¨</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br>sentence=<span class="hljs-string">&quot;I Love China !&quot;</span><br>tokens=nltk.word_tokenize(sentence)<br>tokens<br></code></pre></td></tr></table></figure>
<p>[â€˜Iâ€™, â€˜Loveâ€™, â€˜Chinaâ€™, â€˜!â€™]<br><strong>ä¸­æ–‡åˆ†è¯â€“jieba</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> jieba<br><span class="hljs-meta">&gt;&gt;&gt; </span>seg_list=jieba.cut(<span class="hljs-string">&quot;æˆ‘æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ &quot;</span>,cut_all=<span class="hljs-literal">True</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;å…¨æ¨¡å¼ï¼š&quot;</span>,<span class="hljs-string">&quot;/&quot;</span>.join(seg_list))<br>å…¨æ¨¡å¼ï¼š æˆ‘/æ­£åœ¨/å­¦ä¹ /å­¦ä¹ æœº/æœºå™¨/å­¦ä¹ <br><span class="hljs-meta">&gt;&gt;&gt; </span>seg_list=jieba.cut(<span class="hljs-string">&quot;æˆ‘æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ &quot;</span>,cut_all=<span class="hljs-literal">False</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;ç²¾ç¡®æ¨¡å¼ï¼š&quot;</span>,<span class="hljs-string">&quot;/&quot;</span>.join(seg_list))<br>ç²¾ç¡®æ¨¡å¼ï¼š æˆ‘/æ­£åœ¨/å­¦ä¹ /æœºå™¨/å­¦ä¹ <br></code></pre></td></tr></table></figure>

<h1 id="ä¸‰ã€ç‰¹å¾æå–"><a href="#ä¸‰ã€ç‰¹å¾æå–" class="headerlink" title="ä¸‰ã€ç‰¹å¾æå–"></a>ä¸‰ã€ç‰¹å¾æå–</h1><p>åœ¨æ–‡æœ¬å¤„ç†ä¸­ï¼Œæ–‡æœ¬ä¸­çš„å•è¯è¡¨ç¤ºç¦»æ•£çš„ã€åˆ†ç±»çš„ç‰¹å¾ã€‚æˆ‘ä»¬å¦‚ä½•ä»¥ç®—æ³•å¯ä»¥ä½¿ç”¨çš„æ–¹å¼å¯¹è¿™äº›æ•°æ®è¿›è¡Œç¼–ç ï¼Ÿä»æ–‡æœ¬æ•°æ®åˆ°å®å€¼å‘é‡çš„æ˜ å°„ç§°ä¸ºç‰¹å¾æå–ã€‚ç”¨æ•°å­—è¡¨ç¤ºæ–‡æœ¬çš„æœ€ç®€å•çš„æŠ€æœ¯ä¹‹ä¸€æ˜¯<strong>Bag of Words</strong>ã€‚</p>
<h2 id="Bag-of-Words"><a href="#Bag-of-Words" class="headerlink" title="Bag of Words"></a>Bag of Words</h2><p>æˆ‘ä»¬åœ¨æ–‡æœ¬è¯­æ–™åº“ä¸­åˆ—å‡ºä¸€äº›ç‹¬ç‰¹çš„å•è¯ï¼Œç§°ä¸ºè¯æ±‡è¡¨ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªå¥å­æˆ–æ–‡æ¡£è¡¨ç¤ºä¸ºä¸€ä¸ªå‘é‡ï¼Œæ¯ä¸ªå•è¯è¡¨ç¤ºä¸º1è¡¨ç¤ºç°åœ¨ï¼Œ0è¡¨ç¤ºä¸åœ¨è¯æ±‡è¡¨ä¸­ã€‚å¦ä¸€ç§è¡¨ç¤ºæ³•æ˜¯è®¡ç®—æ¯ä¸ªå•è¯åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°ã€‚æœ€æµè¡Œçš„æ–¹æ³•æ˜¯ä½¿ç”¨æœ¯è¯­é¢‘ç‡é€†æ–‡æ¡£é¢‘ç‡ï¼ˆ<strong>TF-IDF</strong>ï¼‰æŠ€æœ¯ã€‚</p>
<ul>
<li><strong>Term Frequency (TF)</strong>&#x3D;ï¼ˆæœ¯è¯­tå‡ºç°åœ¨â€¢æ–‡æ¡£ä¸­çš„æ¬¡æ•°ï¼‰&#x2F;ï¼ˆæ–‡æ¡£ä¸­çš„æœ¯è¯­æ•°é‡ï¼‰</li>
<li><strong>Inverse Document Frequency (IDF)</strong>&#x3D;log(N&#x2F;n)ï¼Œå…¶ä¸­ï¼ŒNæ˜¯æ–‡æ¡£æ•°é‡ï¼Œnæ˜¯æœ¯è¯­tå‡ºç°åœ¨æ–‡æ¡£ä¸­çš„æ•°é‡ã€‚ç¨€æœ‰è¯çš„IDFè¾ƒé«˜ï¼Œè€Œé¢‘ç¹è¯çš„IDFå¯èƒ½è¾ƒä½ã€‚å› æ­¤å…·æœ‰çªå‡ºæ˜¾ç¤ºä¸åŒå•è¯çš„æ•ˆæœã€‚</li>
<li>æˆ‘ä»¬è®¡ç®—ä¸€ä¸ªé¡¹çš„<strong>TF-IDF</strong>å€¼ä¸º&#x3D;TF*IDF</li>
</ul>
<p><img src="https://ptpimg.me/4ix0bu.png" srcset="/img/loading.gif" lazyload></p>
<pre><code class="hljs">TF(&#39;beautiful&#39;,Document1) = 2/10, IDF(&#39;beautiful&#39;)=log(2/2) = 0
TF(â€˜dayâ€™,Document1) = 5/10,  IDF(â€˜dayâ€™)=log(2/1) = 0.30
TF-IDF(â€˜beautifulâ€™, Document1) = (2/10)*0 = 0
TF-IDF(â€˜dayâ€™, Document1) = (5/10)*0.30 = 0.15
</code></pre>
<p>æ­£å¦‚æ‚¨åœ¨Document1ä¸­çœ‹åˆ°çš„ï¼ŒTF-IDFæ–¹æ³•ä¸¥é‡æƒ©ç½šäº†â€œbeautifulâ€ä¸€è¯ï¼Œä½†å¯¹â€œdayâ€èµ‹äºˆäº†æ›´å¤§çš„æƒé‡ã€‚è¿™æ˜¯ç”±äºIDFéƒ¨åˆ†ï¼Œå®ƒä¸ºä¸åŒçš„å•è¯èµ‹äºˆäº†æ›´å¤šçš„æƒé‡ã€‚æ¢å¥è¯è¯´ï¼Œä»æ•´ä¸ªè¯­æ–™åº“çš„ä¸Šä¸‹æ–‡æ¥çœ‹ï¼Œâ€œdayâ€æ˜¯Document1çš„ä¸€ä¸ªé‡è¦è¯ã€‚Python scikitå­¦ä¹ åº“ä¸ºæ–‡æœ¬æ•°æ®æŒ–æ˜æä¾›äº†æœ‰æ•ˆçš„å·¥å…·ï¼Œå¹¶æä¾›äº†è®¡ç®—ç»™å®šæ–‡æœ¬è¯­æ–™åº“çš„æ–‡æœ¬è¯æ±‡è¡¨TF-IDFçš„å‡½æ•°ã€‚</p>
<p>ä½¿ç”¨BOWçš„ä¸€ä¸ªä¸»è¦ç¼ºç‚¹æ˜¯å®ƒæ”¾å¼ƒäº†è¯åºï¼Œä»è€Œå¿½ç•¥äº†ä¸Šä¸‹æ–‡ï¼Œè¿›è€Œå¿½ç•¥äº†æ–‡æ¡£ä¸­å•è¯çš„å«ä¹‰ã€‚å¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ï¼Œä¿æŒå•è¯çš„ä¸Šä¸‹æ–‡æ˜¯è‡³å…³é‡è¦çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨å¦ä¸€ç§ç§°ä¸ºå•è¯åµŒå…¥çš„æ–¹æ³•ã€‚</p>
<h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><p>å®ƒæ˜¯æ–‡æœ¬çš„ä¸€ç§è¡¨ç¤ºå½¢å¼ï¼Œå…¶ä¸­å…·æœ‰ç›¸åŒå«ä¹‰çš„å•è¯å…·æœ‰ç›¸ä¼¼çš„è¡¨ç¤ºå½¢å¼ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒè¡¨ç¤ºåæ ‡ç³»ä¸­çš„å•è¯ï¼Œåœ¨åæ ‡ç³»ä¸­ï¼ŒåŸºäºå…³ç³»è¯­æ–™åº“çš„ç›¸å…³å•è¯è¢«æ”¾åœ¨æ›´è¿‘çš„ä½ç½®ã€‚</p>
<h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><p>Word2vecå°†å¤§é‡æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå‘é‡ç©ºé—´ï¼Œæ¯ä¸ªå”¯ä¸€çš„å•è¯åœ¨è¯¥ç©ºé—´ä¸­åˆ†é…ä¸€ä¸ªå¯¹åº”çš„å‘é‡ã€‚è¯å‘é‡å®šä½åœ¨å‘é‡ç©ºé—´ä¸­ï¼Œä½¿å¾—åœ¨è¯­æ–™åº“ä¸­å…±äº«å…¬å…±ä¸Šä¸‹æ–‡çš„è¯åœ¨è¯¥ç©ºé—´ä¸­å½¼æ­¤éå¸¸æ¥è¿‘ã€‚Word2Vecéå¸¸æ“…é•¿æ•æ‰æ„ä¹‰ï¼Œå¹¶åœ¨è¯¸å¦‚è®¡ç®—aåˆ°bçš„ç±»æ¯”é—®é¢˜ä»¥åŠcåˆ°ï¼Ÿçš„ç±»æ¯”é—®é¢˜ç­‰ä»»åŠ¡ä¸­æ¼”ç¤ºå®ƒï¼Ÿã€‚ä¾‹å¦‚ï¼Œç”·äººå¯¹å¥³äººå°±åƒå”å”å¯¹å¥³äººä¸€æ ·ï¼Ÿï¼ˆaï¼‰ä½¿ç”¨åŸºäºä½™å¼¦è·ç¦»çš„ç®€å•çŸ¢é‡åç§»æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæœ‰ä¸‰ä¸ªå•è¯å¯¹çš„å‘é‡åç§»é‡æ¥è¯´æ˜æ€§åˆ«å…³ç³»ï¼š<br><img src="https://ptpimg.me/i136y0.png" srcset="/img/loading.gif" lazyload alt="æ€§åˆ«å…³ç³»çš„å‘é‡åç§»é‡"></p>
<p>è¿™ç§å‘é‡ç»„åˆä¹Ÿè®©æˆ‘ä»¬å›ç­”â€œå›½ç‹-ç”·äºº+å¥³äºº&#x3D;ï¼Ÿâ€æé—®å¹¶å¾—å‡ºç»“æœâ€œå¥³ç‹â€ï¼å½“ä½ è®¤ä¸ºæ‰€æœ‰è¿™äº›çŸ¥è¯†ä»…ä»…æ¥è‡ªäºåœ¨ä¸Šä¸‹æ–‡ä¸­æŸ¥çœ‹å¤§é‡å•è¯ï¼Œè€Œæ²¡æœ‰æä¾›å…³äºå®ƒä»¬çš„è¯­ä¹‰çš„å…¶ä»–ä¿¡æ¯æ—¶ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ˜¯éå¸¸å€¼å¾—æ³¨æ„çš„ã€‚</p>
<h4 id="Glove"><a href="#Glove" class="headerlink" title="Glove"></a>Glove</h4><p>å•è¯è¡¨ç¤ºçš„å…¨å±€å‘é‡ï¼ˆGloVeï¼‰ç®—æ³•æ˜¯word2vecæ–¹æ³•çš„æ‰©å±•ï¼Œç”¨äºæœ‰æ•ˆå­¦ä¹ å•è¯å‘é‡ã€‚gloveä½¿ç”¨æ•´ä¸ªæ–‡æœ¬è¯­æ–™åº“ä¸­çš„ç»Ÿè®¡ä¿¡æ¯æ„å»ºä¸€ä¸ªæ˜¾å¼çš„å•è¯ä¸Šä¸‹æ–‡æˆ–å•è¯å…±ç°çŸ©é˜µã€‚ç»“æœæ˜¯ä¸€ä¸ªå­¦ä¹ æ¨¡å‹ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ›´å¥½çš„å•è¯åµŒå…¥ã€‚</p>
<p><img src="https://ptpimg.me/0nux0t.png" srcset="/img/loading.gif" lazyload alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<pre><code class="hljs">Target words: ice, steam
Probe words: solid, gas, water, fashion
</code></pre>
<p>è®©P(k | w)æ˜¯å•è¯kå‡ºç°åœ¨å•è¯Wçš„ä¸Šä¸‹æ–‡ä¸­çš„æ¦‚ç‡W.è€ƒè™‘ä¸€ä¸ªä¸iceæœ‰å¯†åˆ‡å…³ç³»çš„è¯ï¼Œè€Œä¸æ˜¯ä¸steamæœ‰å…³çš„è¯ï¼Œä¾‹å¦‚solidã€‚P(solid | ice)ç›¸å¯¹è¾ƒé«˜ï¼ŒP(solid | steam)ç›¸å¯¹è¾ƒä½ã€‚å› æ­¤ï¼ŒP(solid | ice)&#x2F; P(solid | steam)çš„æ¯”ç‡å°†å¾ˆå¤§ã€‚å¦‚æœæˆ‘ä»¬ç”¨ä¸€ä¸ªè¯ï¼Œæ¯”å¦‚æ°”ä½“ï¼Œå®ƒä¸steamæœ‰å…³ï¼Œä½†ä¸iceæ— å…³ï¼Œé‚£ä¹ˆP(gas | ice) &#x2F; P(gas | steam) çš„æ¯”å€¼å°±ä¼šå˜å°ã€‚å¯¹äºä¸€ä¸ªæ—¢ä¸iceæœ‰å…³åˆä¸wateræœ‰å…³çš„è¯ï¼Œä¾‹å¦‚waterï¼Œæˆ‘ä»¬é¢„è®¡å…¶æ¯”ç‡æ¥è¿‘1ã€‚</p>
<p>å•è¯åµŒå…¥å°†æ¯ä¸ªå•è¯ç¼–ç æˆä¸€ä¸ªå‘é‡ï¼Œè¯¥å‘é‡æ•è·æ–‡æœ¬è¯­æ–™åº“ä¸­å•è¯ä¹‹é—´çš„æŸç§å…³ç³»å’Œç›¸ä¼¼æ€§ã€‚è¿™æ„å‘³ç€å³ä½¿æ˜¯å¤§å°å†™ã€æ‹¼å†™ã€æ ‡ç‚¹ç¬¦å·ç­‰å•è¯çš„å˜ä½“ä¹Ÿä¼šè‡ªåŠ¨å­¦ä¹ ã€‚åè¿‡æ¥ï¼Œè¿™æ„å‘³ç€å¯èƒ½ä¸å†éœ€è¦ä¸Šè¿°ä¸€äº›æ–‡æœ¬æ¸…ç†æ­¥éª¤ã€‚</p>
<h1 id="å››ã€ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æå®ä¾‹"><a href="#å››ã€ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æå®ä¾‹" class="headerlink" title="å››ã€ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æå®ä¾‹"></a>å››ã€ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æå®ä¾‹</h1><p>æ ¹æ®é—®é¢˜ç©ºé—´å’Œå¯ç”¨æ•°æ®çš„ä¸åŒï¼Œæœ‰å¤šç§æ–¹æ³•ä¸ºå„ç§åŸºäºæ–‡æœ¬çš„åº”ç”¨ç¨‹åºæ„å»ºMLæ¨¡å‹ã€‚<br>ç”¨äºåƒåœ¾é‚®ä»¶è¿‡æ»¤çš„ç»å…¸MLæ–¹æ³•ï¼Œå¦‚â€œæœ´ç´ è´å¶æ–¯â€æˆ–â€œæ”¯æŒå‘é‡æœºâ€ï¼Œå·²è¢«å¹¿æ³›ä½¿ç”¨ã€‚æ·±åº¦å­¦ä¹ æŠ€æœ¯å¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†é—®é¢˜ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æå’Œè¯­è¨€ç¿»è¯‘ï¼‰æœ‰æ›´å¥½çš„æ•ˆæœã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦éå¸¸æ…¢ï¼Œå¹¶ä¸”å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºç®€å•çš„æ–‡æœ¬åˆ†ç±»é—®é¢˜ï¼Œç»å…¸çš„MLæ–¹æ³•ä¹Ÿèƒ½ä»¥æ›´å¿«çš„è®­ç»ƒæ—¶é—´ç»™å‡ºç±»ä¼¼çš„ç»“æœã€‚<br>è®©æˆ‘ä»¬ä½¿ç”¨ç›®å‰è®¨è®ºçš„æŠ€æœ¯åœ¨Kaggleæä¾›çš„çƒ‚ç•ªèŒ„ç”µå½±è¯„è®ºæ•°æ®é›†ä¸Šæ„å»ºä¸€ä¸ªæƒ…æ„Ÿåˆ†æå™¨ã€‚</p>
<h2 id="ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æ"><a href="#ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æ" class="headerlink" title="ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æ"></a>ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æ</h2><p><img src="https://ptpimg.me/1blyr8.png" srcset="/img/loading.gif" lazyload></p>
<p>å¯¹äºç”µå½±è¯„è®ºæƒ…ç»ªåˆ†æï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Kaggleæä¾›çš„çƒ‚ç•ªèŒ„ç”µå½±è¯„è®ºæ•°æ®é›†ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ ¹æ®ç”µå½±è¯„è®ºçš„æƒ…ç»ªï¼Œä»¥äº”ä¸ªå€¼ä¸ºå°ºåº¦ç»™çŸ­è¯­è´´ä¸Šæ ‡ç­¾ï¼šæ¶ˆæçš„ï¼Œæœ‰äº›æ¶ˆæçš„ï¼Œä¸­æ€§çš„ï¼Œæœ‰äº›ç§¯æçš„ï¼Œç§¯æçš„ã€‚æ•°æ®é›†ç”±é€‰é¡¹å¡åˆ†éš”çš„æ–‡ä»¶ç»„æˆï¼Œå…¶ä¸­åŒ…å«æ¥è‡ªæ•°æ®é›†çš„çŸ­è¯­IDã€‚æ¯ä¸ªçŸ­è¯­éƒ½æœ‰ä¸€ä¸ªçŸ­è¯­ã€‚æ¯ä¸ªå¥å­éƒ½æœ‰ä¸€ä¸ªå¥å­IDã€‚é‡å¤çš„çŸ­è¯­ï¼ˆå¦‚çŸ­&#x2F;å¸¸ç”¨è¯ï¼‰ä»…åœ¨æ•°æ®ä¸­åŒ…å«ä¸€æ¬¡ã€‚æƒ…ç»ªæ ‡ç­¾åŒ…æ‹¬ï¼š</p>
<ul>
<li>0 - <em>negative</em></li>
<li>1 - <em>somewhat negative</em></li>
<li>2 - <em>neutral</em></li>
<li>3 - <em>somewhat positive</em></li>
<li>4 - <em>positive</em></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>%matplotlib inline<br><br></code></pre></td></tr></table></figure>

<h2 id="1-åˆå§‹åŒ–æ•°æ®"><a href="#1-åˆå§‹åŒ–æ•°æ®" class="headerlink" title="1. åˆå§‹åŒ–æ•°æ®"></a><a id='1'>1. åˆå§‹åŒ–æ•°æ®</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train = pd.read_csv(<span class="hljs-string">&quot;/Users/gawaintan/workSpace/movie-review-sentiment-analysis-kernels-only/train.tsv&quot;</span>, sep=<span class="hljs-string">&#x27;\t&#x27;</span>)<br>df_train.head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PhraseId</th>
      <th>SentenceId</th>
      <th>Phrase</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>A series</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>A</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1</td>
      <td>series</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">df_test = pd.read_csv(<span class="hljs-string">&quot;/Users/gawaintan/workSpace/movie-review-sentiment-analysis-kernels-only/test.tsv&quot;</span>, sep=<span class="hljs-string">&#x27;\t&#x27;</span>)<br>df_test.head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PhraseId</th>
      <th>SentenceId</th>
      <th>Phrase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>156061</td>
      <td>8545</td>
      <td>An intermittently pleasing but mostly routine ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>156062</td>
      <td>8545</td>
      <td>An intermittently pleasing but mostly routine ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>156063</td>
      <td>8545</td>
      <td>An</td>
    </tr>
    <tr>
      <th>3</th>
      <td>156064</td>
      <td>8545</td>
      <td>intermittently pleasing but mostly routine effort</td>
    </tr>
    <tr>
      <th>4</th>
      <td>156065</td>
      <td>8545</td>
      <td>intermittently pleasing but mostly routine</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="1-1-æ¯ä¸ªæƒ…ç»ªç±»åˆ«ä¸­çš„è¯„è®ºåˆ†å¸ƒ"><a href="#1-1-æ¯ä¸ªæƒ…ç»ªç±»åˆ«ä¸­çš„è¯„è®ºåˆ†å¸ƒ" class="headerlink" title="1.1 æ¯ä¸ªæƒ…ç»ªç±»åˆ«ä¸­çš„è¯„è®ºåˆ†å¸ƒ"></a><a id='1.1'>1.1 æ¯ä¸ªæƒ…ç»ªç±»åˆ«ä¸­çš„è¯„è®ºåˆ†å¸ƒ</a></h2><p>åœ¨è¿™é‡Œï¼Œè®­ç»ƒæ•°æ®é›†åŒ…å«äº†ç”µå½±è¯„è®ºä¸­å ä¸»å¯¼åœ°ä½çš„ä¸­æ€§çŸ­è¯­ï¼Œç„¶åæ˜¯æœ‰äº›ç§¯æçš„ï¼Œç„¶åæ˜¯æœ‰äº›æ¶ˆæçš„ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train.Sentiment.value_counts()<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">2    79582
3    32927
1    27273
4     9206
0     7072
Name: Sentiment, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train.info()<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 156060 entries, 0 to 156059
Data columns (total 4 columns):
 #   Column      Non-Null Count   Dtype 
---  ------      --------------   ----- 
 0   PhraseId    156060 non-null  int64 
 1   SentenceId  156060 non-null  int64 
 2   Phrase      156060 non-null  object
 3   Sentiment   156060 non-null  int64 
dtypes: int64(3), object(1)
memory usage: 4.8+ MB
</code></pre>
<h2 id="1-2-åˆ é™¤ä¸é‡è¦çš„åˆ—"><a href="#1-2-åˆ é™¤ä¸é‡è¦çš„åˆ—" class="headerlink" title="1.2 åˆ é™¤ä¸é‡è¦çš„åˆ—"></a><a id='1.2'>1.2 åˆ é™¤ä¸é‡è¦çš„åˆ—</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train_1 = df_train.drop([<span class="hljs-string">&#x27;PhraseId&#x27;</span>,<span class="hljs-string">&#x27;SentenceId&#x27;</span>],axis=<span class="hljs-number">1</span>)<br>df_train_1.head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Phrase</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A series</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>series</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



<p>Letâ€™s check the phrase length of each of the movie reviews.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train_1[<span class="hljs-string">&#x27;phrase_len&#x27;</span>] = [<span class="hljs-built_in">len</span>(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> df_train_1.Phrase]<br>df_train_1.head(<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Phrase</th>
      <th>Sentiment</th>
      <th>phrase_len</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
      <td>188</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>2</td>
      <td>77</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A series</td>
      <td>2</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="1-3-å„æƒ…æ„Ÿç±»åˆ«ä¸‹è¯„è®ºæ—¶é•¿çš„æ€»ä½“åˆ†å¸ƒ"><a href="#1-3-å„æƒ…æ„Ÿç±»åˆ«ä¸‹è¯„è®ºæ—¶é•¿çš„æ€»ä½“åˆ†å¸ƒ" class="headerlink" title="1.3 å„æƒ…æ„Ÿç±»åˆ«ä¸‹è¯„è®ºæ—¶é•¿çš„æ€»ä½“åˆ†å¸ƒ"></a><a id='1.3'>1.3 å„æƒ…æ„Ÿç±»åˆ«ä¸‹è¯„è®ºæ—¶é•¿çš„æ€»ä½“åˆ†å¸ƒ</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">fig,ax = plt.subplots(figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>plt.boxplot(df_train_1.phrase_len)<br>plt.show()<br></code></pre></td></tr></table></figure>


<p><img src="https://i-blog.csdnimg.cn/blog_migrate/72e054ceb9fb8ebddc1a279dcefa8606.png" srcset="/img/loading.gif" lazyload></p>
<p>ä»ä¸Šé¢çš„ç®±çº¿å›¾ä¸­ï¼Œæœ‰äº›è¯„è®ºçš„é•¿åº¦è¶…è¿‡ 100 ä¸ªå­—ç¬¦ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train_1[df_train_1.phrase_len &gt; <span class="hljs-number">100</span>].head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Phrase</th>
      <th>Sentiment</th>
      <th>phrase_len</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A series of escapades demonstrating the adage ...</td>
      <td>1</td>
      <td>188</td>
    </tr>
    <tr>
      <th>27</th>
      <td>is also good for the gander , some of which oc...</td>
      <td>2</td>
      <td>110</td>
    </tr>
    <tr>
      <th>28</th>
      <td>is also good for the gander , some of which oc...</td>
      <td>2</td>
      <td>108</td>
    </tr>
    <tr>
      <th>116</th>
      <td>A positively thrilling combination of ethnogra...</td>
      <td>3</td>
      <td>152</td>
    </tr>
    <tr>
      <th>117</th>
      <td>A positively thrilling combination of ethnogra...</td>
      <td>4</td>
      <td>150</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df_train_1[df_train_1.phrase_len &gt; <span class="hljs-number">100</span>].loc[<span class="hljs-number">0</span>].Phrase<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&#39;A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .&#39;
</code></pre>
<h2 id="1-4-åˆ›å»ºè´Ÿé¢å’Œæ­£é¢ç”µå½±è¯„è®ºçš„è¯äº‘"><a href="#1-4-åˆ›å»ºè´Ÿé¢å’Œæ­£é¢ç”µå½±è¯„è®ºçš„è¯äº‘" class="headerlink" title="1.4 åˆ›å»ºè´Ÿé¢å’Œæ­£é¢ç”µå½±è¯„è®ºçš„è¯äº‘"></a><a id='1.4'>1.4 åˆ›å»ºè´Ÿé¢å’Œæ­£é¢ç”µå½±è¯„è®ºçš„è¯äº‘</a></h2><h3 id="Word-Cloud"><a href="#Word-Cloud" class="headerlink" title="Word Cloud"></a>Word Cloud</h3><p>wordcloud æ˜¯æ–‡æœ¬æ–‡ä»¶é›†åˆä¸­å¸¸ç”¨è¯çš„å›¾å½¢è¡¨ç¤ºã€‚è¿™å¼ å›¾ç‰‡ä¸­æ¯ä¸ªè¯çš„é«˜åº¦æ˜¯è¯¥è¯åœ¨æ•´ä¸ªæ–‡æœ¬ä¸­å‡ºç°é¢‘ç‡çš„æŒ‡æ ‡ã€‚åœ¨è¿›è¡Œæ–‡æœ¬åˆ†ææ—¶ï¼Œæ­¤ç±»å›¾è¡¨éå¸¸æœ‰ç”¨ã€‚</p>
<h2 id="1-4-1-ç­›é€‰å‡ºæ­£é¢å’Œè´Ÿé¢çš„å½±è¯„"><a href="#1-4-1-ç­›é€‰å‡ºæ­£é¢å’Œè´Ÿé¢çš„å½±è¯„" class="headerlink" title="1.4.1 ç­›é€‰å‡ºæ­£é¢å’Œè´Ÿé¢çš„å½±è¯„"></a><a id='1.4.1'>1.4.1 ç­›é€‰å‡ºæ­£é¢å’Œè´Ÿé¢çš„å½±è¯„</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">neg_phrases = df_train_1[df_train_1.Sentiment == <span class="hljs-number">0</span>]<br>neg_words = []<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> neg_phrases.Phrase:<br>    neg_words.append(t)<br>neg_words[:<span class="hljs-number">4</span>]<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">[&#39;would have a hard time sitting through this one&#39;,
 &#39;have a hard time sitting through this one&#39;,
 &#39;Aggressive self-glorification and a manipulative whitewash&#39;,
 &#39;self-glorification and a manipulative whitewash&#39;]
</code></pre>
<p>**pandas.Series.str.cat ** : ä½¿ç”¨ç»™å®šçš„åˆ†éš”ç¬¦è¿æ¥ç³»åˆ—&#x2F;ç´¢å¼•ä¸­çš„å­—ç¬¦ä¸²ã€‚è¿™é‡Œæˆ‘ä»¬ç»™ä¸€ä¸ªç©ºæ ¼ä½œä¸ºåˆ†éš”ç¬¦ï¼Œå› æ­¤ï¼Œå®ƒå°†è¿æ¥æ¯ä¸ªç´¢å¼•ä¸­ç”±ç©ºæ ¼åˆ†éš”çš„æ‰€æœ‰å­—ç¬¦ä¸²ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">neg_text = pd.Series(neg_words).<span class="hljs-built_in">str</span>.cat(sep=<span class="hljs-string">&#x27; &#x27;</span>)<br>neg_text[:<span class="hljs-number">100</span>]<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&#39;would have a hard time sitting through this one have a hard time sitting through this one Aggressive&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> neg_phrases.Phrase[:<span class="hljs-number">300</span>]:<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;good&#x27;</span> <span class="hljs-keyword">in</span> t:<br>        <span class="hljs-built_in">print</span>(t)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">&#39;s not a particularly good film
covers huge , heavy topics in a bland , surfacey way that does n&#39;t offer any insight into why , for instance , good things happen to bad people .
huge , heavy topics in a bland , surfacey way that does n&#39;t offer any insight into why , for instance , good things happen to bad people
a bland , surfacey way that does n&#39;t offer any insight into why , for instance , good things happen to bad people
</code></pre>
<p>æ‰€ä»¥ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆæ¸…æ¥šåœ°çœ‹åˆ°ï¼Œå³ä½¿æ–‡æœ¬åŒ…å«â€œå¥½â€è¿™æ ·çš„è¯ï¼Œä¹Ÿæ˜¯ä¸€ç§è´Ÿé¢æƒ…ç»ªï¼Œå› ä¸ºå®ƒè¡¨æ˜è¿™éƒ¨ç”µå½±ä¸æ˜¯ä¸€éƒ¨å¥½ç”µå½±ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">pos_phrases = df_train_1[df_train_1.Sentiment == <span class="hljs-number">4</span>] <span class="hljs-comment">## 4 is positive sentiment</span><br>pos_string = []<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> pos_phrases.Phrase:<br>    pos_string.append(t)<br>pos_text = pd.Series(pos_string).<span class="hljs-built_in">str</span>.cat(sep=<span class="hljs-string">&#x27; &#x27;</span>)<br>pos_text[:<span class="hljs-number">100</span>]<br>    <br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&#39;This quiet , introspective and entertaining independent is worth seeking . quiet , introspective and&#39;
</code></pre>
<h2 id="1-4-2-è´Ÿé¢åˆ†ç±»å½±è¯„çš„è¯äº‘"><a href="#1-4-2-è´Ÿé¢åˆ†ç±»å½±è¯„çš„è¯äº‘" class="headerlink" title="1.4.2 è´Ÿé¢åˆ†ç±»å½±è¯„çš„è¯äº‘"></a><a id='1.4.2'>1.4.2 è´Ÿé¢åˆ†ç±»å½±è¯„çš„è¯äº‘</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> wordcloud <span class="hljs-keyword">import</span> WordCloud<br>wordcloud = WordCloud(width=<span class="hljs-number">1600</span>, height=<span class="hljs-number">800</span>, max_font_size=<span class="hljs-number">200</span>).generate(neg_text)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.imshow(wordcloud, interpolation=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>plt.axis(<span class="hljs-string">&quot;off&quot;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/wm153z.png" srcset="/img/loading.gif" lazyload alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>ä¸€äº›å¤§çš„è¯å¯ä»¥è§£é‡Šå¾—ç›¸å½“ä¸­æ€§ï¼Œä¾‹å¦‚â€œfilmâ€ã€â€œmoiveâ€ç­‰ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€äº›è¾ƒå°çš„è¯åœ¨è´Ÿé¢ç”µå½±è¯„è®ºä¸­æ˜¯æœ‰æ„ä¹‰çš„ï¼Œä¾‹å¦‚â€œbad movieâ€ã€â€œdullâ€ ã€â€œboringâ€ç­‰ã€‚</p>
<p>ç„¶è€Œï¼Œåœ¨å¯¹è¿™éƒ¨ç”µå½±çš„è´Ÿé¢åˆ†ç±»æƒ…ç»ªä¸­ï¼Œä¹Ÿæœ‰ä¸€äº›åƒâ€œå¥½â€è¿™æ ·çš„è¯ã€‚è®©æˆ‘ä»¬æ›´æ·±å…¥åœ°äº†è§£è¿™äº›å•è¯&#x2F;æ–‡æœ¬ï¼š</p>
<h2 id="1-4-3-æ­£åˆ†ç±»å½±è¯„çš„è¯äº‘"><a href="#1-4-3-æ­£åˆ†ç±»å½±è¯„çš„è¯äº‘" class="headerlink" title="1.4.3 æ­£åˆ†ç±»å½±è¯„çš„è¯äº‘"></a><a id='1.4.3'>1.4.3 æ­£åˆ†ç±»å½±è¯„çš„è¯äº‘</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">wordcloud = WordCloud(width=<span class="hljs-number">1600</span>, height=<span class="hljs-number">800</span>, max_font_size=<span class="hljs-number">200</span>).generate(pos_text)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.imshow(wordcloud, interpolation=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>


<p><img src="https://ptpimg.me/mqvx0x.png" srcset="/img/loading.gif" lazyload alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>æˆ‘å†æ¬¡çœ‹åˆ°ä¸€äº›å¤§å°ºå¯¸çš„ä¸­æ€§è¯ï¼Œâ€œmovieâ€ï¼Œâ€œfilmâ€ï¼Œä½†åƒâ€œgoodâ€ï¼Œâ€œnestâ€ï¼Œâ€œfascinatingâ€è¿™æ ·çš„æ­£é¢è¯ä¹Ÿå¾ˆçªå‡ºã€‚</p>
<h2 id="1-5-æ‰€æœ‰5ä¸ªæƒ…æ„Ÿç±»åˆ«çš„æ€»è¯é¢‘"><a href="#1-5-æ‰€æœ‰5ä¸ªæƒ…æ„Ÿç±»åˆ«çš„æ€»è¯é¢‘" class="headerlink" title="1.5 æ‰€æœ‰5ä¸ªæƒ…æ„Ÿç±»åˆ«çš„æ€»è¯é¢‘"></a><a id='1.5'>1.5 æ‰€æœ‰5ä¸ªæƒ…æ„Ÿç±»åˆ«çš„æ€»è¯é¢‘</a></h2><p>æˆ‘ä»¬éœ€è¦ Term Frequency æ•°æ®æ¥æŸ¥çœ‹ç”µå½±è¯„è®ºä¸­ä½¿ç”¨äº†å“ªäº›è¯ä»¥åŠä½¿ç”¨äº†å¤šå°‘æ¬¡ã€‚è®©æˆ‘ä»¬ç»§ç»­ä½¿ç”¨ CountVectorizer æ¥è®¡ç®—è¯é¢‘ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>cvector = CountVectorizer(min_df = <span class="hljs-number">0.0</span>, max_df = <span class="hljs-number">1.0</span>, ngram_range=(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>))<br>cvector.fit(df_train_1.Phrase)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">CountVectorizer(min_df=0.0, ngram_range=(1, 2))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">len</span>(cvector.get_feature_names())<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">94644
</code></pre>
<p>çœ‹èµ·æ¥ count vectorizer å·²ç»ä»è¯­æ–™åº“ä¸­æå–äº† 94644 ä¸ªå•è¯ã€‚å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å—è·å–æ¯ä¸ªç±»çš„è¯é¢‘ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">All_matrix=[]<br>All_words=[]<br>All_labels=[<span class="hljs-string">&#x27;negative&#x27;</span>,<span class="hljs-string">&#x27;some-negative&#x27;</span>,<span class="hljs-string">&#x27;neutral&#x27;</span>,<span class="hljs-string">&#x27;some-positive&#x27;</span>,<span class="hljs-string">&#x27;positive&#x27;</span>]<br>neg_matrix = cvector.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">0</span>].Phrase)<br>term_freq_df= pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>([(word, neg_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvector.vocabulary_.items()], key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;negative&#x27;</span>])<br>term_freq_df=term_freq_df.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>):<br>    All_matrix.append(cvector.transform(df_train_1[df_train_1.Sentiment == i].Phrase))<br>    All_words.append(All_matrix[i-<span class="hljs-number">1</span>].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>))<br>    aa=pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>([(word,All_words[i-<span class="hljs-number">1</span>][<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvector.vocabulary_.items()], key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,All_labels[i]])<br>    <br>    term_freq_df=term_freq_df.join(aa.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>),how=<span class="hljs-string">&#x27;left&#x27;</span>,lsuffix=<span class="hljs-string">&#x27;_A&#x27;</span>)<br><br>    <br><br>term_freq_df[<span class="hljs-string">&#x27;total&#x27;</span>] = term_freq_df[<span class="hljs-string">&#x27;negative&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-negative&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;neutral&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-positive&#x27;</span>] +  term_freq_df[<span class="hljs-string">&#x27;positive&#x27;</span>] <br>term_freq_df.sort_values(by=<span class="hljs-string">&#x27;total&#x27;</span>, ascending=<span class="hljs-literal">False</span>).head(<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>negative</th>
      <th>some-negative</th>
      <th>neutral</th>
      <th>some-positive</th>
      <th>positive</th>
      <th>total</th>
    </tr>
    <tr>
      <th>Terms</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>the</th>
      <td>3462</td>
      <td>10885</td>
      <td>20619</td>
      <td>12459</td>
      <td>4208</td>
      <td>51633</td>
    </tr>
    <tr>
      <th>of</th>
      <td>2277</td>
      <td>6660</td>
      <td>12287</td>
      <td>8405</td>
      <td>3073</td>
      <td>32702</td>
    </tr>
    <tr>
      <th>and</th>
      <td>2549</td>
      <td>6204</td>
      <td>10241</td>
      <td>9180</td>
      <td>4003</td>
      <td>32177</td>
    </tr>
    <tr>
      <th>to</th>
      <td>1916</td>
      <td>5571</td>
      <td>8295</td>
      <td>5411</td>
      <td>1568</td>
      <td>22761</td>
    </tr>
    <tr>
      <th>in</th>
      <td>1038</td>
      <td>2965</td>
      <td>5562</td>
      <td>3365</td>
      <td>1067</td>
      <td>13997</td>
    </tr>
    <tr>
      <th>is</th>
      <td>1372</td>
      <td>3362</td>
      <td>3703</td>
      <td>3489</td>
      <td>1550</td>
      <td>13476</td>
    </tr>
    <tr>
      <th>that</th>
      <td>1139</td>
      <td>2982</td>
      <td>3677</td>
      <td>3280</td>
      <td>1260</td>
      <td>12338</td>
    </tr>
    <tr>
      <th>it</th>
      <td>1086</td>
      <td>3067</td>
      <td>3791</td>
      <td>2927</td>
      <td>863</td>
      <td>11734</td>
    </tr>
    <tr>
      <th>as</th>
      <td>757</td>
      <td>2184</td>
      <td>2941</td>
      <td>2037</td>
      <td>732</td>
      <td>8651</td>
    </tr>
    <tr>
      <th>with</th>
      <td>452</td>
      <td>1533</td>
      <td>2471</td>
      <td>2365</td>
      <td>929</td>
      <td>7750</td>
    </tr>
  </tbody>
</table>
</div>



<p>æˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°ï¼Œåƒâ€œtheâ€ã€â€œinâ€ã€â€œitâ€ç­‰è¯çš„é¢‘ç‡è¦é«˜å¾—å¤šï¼Œå®ƒä»¬å¯¹å½±è¯„çš„æƒ…ç»ªæ²¡æœ‰ä»»ä½•æ„ä¹‰ã€‚å¦ä¸€æ–¹é¢ï¼Œè¯¸å¦‚â€œæ‚²è§‚å¯ç¬‘â€ä¹‹ç±»çš„è¯å®ƒä»¬åœ¨æ–‡æ¡£ä¸­çš„å‡ºç°é¢‘ç‡éå¸¸ä½ï¼Œä½†ä¼¼ä¹ä¸ç”µå½±çš„æƒ…ç»ªæœ‰å¾ˆå¤§å…³ç³»ã€‚</p>
<h2 id="1-6-ç”µå½±è¯„è®ºåˆ†è¯å±•ç¤º"><a href="#1-6-ç”µå½±è¯„è®ºåˆ†è¯å±•ç¤º" class="headerlink" title="1.6 ç”µå½±è¯„è®ºåˆ†è¯å±•ç¤º"></a><a id='1.6'>1.6 ç”µå½±è¯„è®ºåˆ†è¯å±•ç¤º</a></h2><p>Next, letâ€™s explore about how different the tokens in two different classes(positive, negative).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>cvec = CountVectorizer(stop_words=<span class="hljs-string">&#x27;english&#x27;</span>,max_features=<span class="hljs-number">10000</span>)<br>cvec.fit(df_train_1.Phrase)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">CountVectorizer(max_features=10000, stop_words=&#39;english&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python">neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">0</span>].Phrase)<br>som_neg_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">1</span>].Phrase)<br>neu_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">2</span>].Phrase)<br>som_pos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">3</span>].Phrase)<br>pos_matrix = cvec.transform(df_train_1[df_train_1.Sentiment == <span class="hljs-number">4</span>].Phrase)<br><br>neg_words = neg_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>neg_words_freq = [(word, neg_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>neg_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(neg_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;negative&#x27;</span>])<br><br>neg_tf_df = neg_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br><br>som_neg_words = som_neg_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>som_neg_words_freq = [(word, som_neg_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>som_neg_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(som_neg_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;some-negative&#x27;</span>])<br>som_neg_tf_df = som_neg_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>neu_words = neu_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>neu_words_freq = [(word, neu_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>neu_words_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(neu_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;neutral&#x27;</span>])<br>neu_words_tf_df = neu_words_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>som_pos_words = som_pos_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>som_pos_words_freq = [(word, som_pos_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>som_pos_words_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(som_pos_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;some-positive&#x27;</span>])<br>som_pos_words_tf_df = som_pos_words_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>pos_words = pos_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>)<br>pos_words_freq = [(word, pos_words[<span class="hljs-number">0</span>, idx]) <span class="hljs-keyword">for</span> word, idx <span class="hljs-keyword">in</span> cvec.vocabulary_.items()]<br>pos_words_tf = pd.DataFrame(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">sorted</span>(pos_words_freq, key = <span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)),columns=[<span class="hljs-string">&#x27;Terms&#x27;</span>,<span class="hljs-string">&#x27;positive&#x27;</span>])<br>pos_words_tf_df = pos_words_tf.set_index(<span class="hljs-string">&#x27;Terms&#x27;</span>)<br><br>term_freq_df = pd.concat([neg_tf_df,som_neg_tf_df,neu_words_tf_df,som_pos_words_tf_df,pos_words_tf_df],axis=<span class="hljs-number">1</span>)<br><br>term_freq_df[<span class="hljs-string">&#x27;total&#x27;</span>] = term_freq_df[<span class="hljs-string">&#x27;negative&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-negative&#x27;</span>] \<br>                                 + term_freq_df[<span class="hljs-string">&#x27;neutral&#x27;</span>] + term_freq_df[<span class="hljs-string">&#x27;some-positive&#x27;</span>] \<br>                                 +  term_freq_df[<span class="hljs-string">&#x27;positive&#x27;</span>] <br>        <br>term_freq_df.sort_values(by=<span class="hljs-string">&#x27;total&#x27;</span>, ascending=<span class="hljs-literal">False</span>).head(<span class="hljs-number">15</span>)<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>negative</th>
      <th>some-negative</th>
      <th>neutral</th>
      <th>some-positive</th>
      <th>positive</th>
      <th>total</th>
    </tr>
    <tr>
      <th>Terms</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>film</th>
      <td>480</td>
      <td>1281</td>
      <td>2175</td>
      <td>1848</td>
      <td>949</td>
      <td>6733</td>
    </tr>
    <tr>
      <th>movie</th>
      <td>793</td>
      <td>1463</td>
      <td>2054</td>
      <td>1344</td>
      <td>587</td>
      <td>6241</td>
    </tr>
    <tr>
      <th>like</th>
      <td>332</td>
      <td>942</td>
      <td>1167</td>
      <td>599</td>
      <td>150</td>
      <td>3190</td>
    </tr>
    <tr>
      <th>story</th>
      <td>153</td>
      <td>532</td>
      <td>954</td>
      <td>664</td>
      <td>236</td>
      <td>2539</td>
    </tr>
    <tr>
      <th>rrb</th>
      <td>131</td>
      <td>498</td>
      <td>1112</td>
      <td>551</td>
      <td>146</td>
      <td>2438</td>
    </tr>
    <tr>
      <th>good</th>
      <td>100</td>
      <td>334</td>
      <td>519</td>
      <td>974</td>
      <td>334</td>
      <td>2261</td>
    </tr>
    <tr>
      <th>lrb</th>
      <td>119</td>
      <td>452</td>
      <td>878</td>
      <td>512</td>
      <td>137</td>
      <td>2098</td>
    </tr>
    <tr>
      <th>time</th>
      <td>153</td>
      <td>420</td>
      <td>752</td>
      <td>464</td>
      <td>130</td>
      <td>1919</td>
    </tr>
    <tr>
      <th>characters</th>
      <td>167</td>
      <td>455</td>
      <td>614</td>
      <td>497</td>
      <td>149</td>
      <td>1882</td>
    </tr>
    <tr>
      <th>comedy</th>
      <td>174</td>
      <td>341</td>
      <td>578</td>
      <td>475</td>
      <td>245</td>
      <td>1813</td>
    </tr>
    <tr>
      <th>just</th>
      <td>216</td>
      <td>598</td>
      <td>550</td>
      <td>282</td>
      <td>82</td>
      <td>1728</td>
    </tr>
    <tr>
      <th>life</th>
      <td>77</td>
      <td>200</td>
      <td>729</td>
      <td>544</td>
      <td>168</td>
      <td>1718</td>
    </tr>
    <tr>
      <th>does</th>
      <td>135</td>
      <td>566</td>
      <td>519</td>
      <td>375</td>
      <td>79</td>
      <td>1674</td>
    </tr>
    <tr>
      <th>little</th>
      <td>109</td>
      <td>492</td>
      <td>580</td>
      <td>339</td>
      <td>85</td>
      <td>1605</td>
    </tr>
    <tr>
      <th>funny</th>
      <td>73</td>
      <td>257</td>
      <td>267</td>
      <td>639</td>
      <td>347</td>
      <td>1583</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="1-6-1-è´Ÿé¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯"><a href="#1-6-1-è´Ÿé¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯" class="headerlink" title="1.6.1 è´Ÿé¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯"></a><a id='1.6.1'>1.6.1 è´Ÿé¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">y_pos = np.arange(<span class="hljs-number">50</span>)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.bar(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;negative&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;negative&#x27;</span>][:<span class="hljs-number">50</span>], align=<span class="hljs-string">&#x27;center&#x27;</span>, alpha=<span class="hljs-number">0.5</span>)<br>plt.xticks(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;negative&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;negative&#x27;</span>][:<span class="hljs-number">50</span>].index,rotation=<span class="hljs-string">&#x27;vertical&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Frequency&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Top 50 negative tokens&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Top 50 tokens in negative movie reviews&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Top 50 tokens in negative movie reviews&#39;)
</code></pre>
<p><img src="https://ptpimg.me/yw0h81.png" srcset="/img/loading.gif" lazyload alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€äº›è´Ÿé¢è¯ï¼Œå¦‚â€œåâ€ã€â€œæœ€å·®â€ã€â€œæ²‰é—·â€æ˜¯ä¸€äº›é«˜é¢‘è¯ã€‚ä½†æ˜¯ï¼Œå­˜åœ¨æœ‰åƒâ€œç”µå½±â€ã€â€œç”µå½±â€ã€â€œåˆ†é’Ÿâ€è¿™æ ·çš„ä¸­æ€§è¯æ”¯é…é¢‘ç‡å›¾ã€‚</p>
<p>æˆ‘ä»¬å†çœ‹ä¸€ä¸‹æ¡å½¢å›¾ä¸Šçš„å‰ 50 ä¸ªæ­£é¢æ ‡è®°</p>
<h2 id="1-6-2-æ­£é¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯"><a href="#1-6-2-æ­£é¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯" class="headerlink" title="1.6.2 æ­£é¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯"></a><a id='1.6.2'>1.6.2 æ­£é¢å½±è¯„ä¸­æœ€å¸¸ç”¨çš„50ä¸ªè¯</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">y_pos = np.arange(<span class="hljs-number">50</span>)<br>plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">10</span>))<br>plt.bar(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;positive&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;positive&#x27;</span>][:<span class="hljs-number">50</span>], align=<span class="hljs-string">&#x27;center&#x27;</span>, alpha=<span class="hljs-number">0.5</span>)<br>plt.xticks(y_pos, term_freq_df.sort_values(by=<span class="hljs-string">&#x27;positive&#x27;</span>, ascending=<span class="hljs-literal">False</span>)[<span class="hljs-string">&#x27;positive&#x27;</span>][:<span class="hljs-number">50</span>].index,rotation=<span class="hljs-string">&#x27;vertical&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Frequency&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Top 50 positive tokens&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Top 50 tokens in positive movie reviews&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Top 50 tokens in positive movie reviews&#39;)
</code></pre>
<p><img src="https://ptpimg.me/e5x807.png" srcset="/img/loading.gif" lazyload alt="[å¤–é“¾å›¾ç‰‡è½¬å­˜å¤±è´¥,æºç«™å¯èƒ½æœ‰é˜²ç›—é“¾æœºåˆ¶,å»ºè®®å°†å›¾ç‰‡ä¿å­˜ä¸‹æ¥ç›´æ¥ä¸Šä¼ (img-HLxcm1VK-1640793547488)(sentiment-analysis-countvectorizer-tf-idf_files/sentiment-analysis-countvectorizer-tf-idf_51_1.png)]"></p>
<p>Once again, there are some neutral words like â€œfilmâ€, â€œmovieâ€, are quite high up in the rank.</p>
<h2 id="2-ä¼ ç»Ÿçš„ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹"><a href="#2-ä¼ ç»Ÿçš„ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹" class="headerlink" title="2. ä¼ ç»Ÿçš„ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹"></a><a id='2'>2. ä¼ ç»Ÿçš„ç›‘ç£æœºå™¨å­¦ä¹ æ¨¡å‹</a></h2><h2 id="2-1-ç‰¹å¾å·¥ç¨‹"><a href="#2-1-ç‰¹å¾å·¥ç¨‹" class="headerlink" title="2.1 ç‰¹å¾å·¥ç¨‹"></a><a id='2.1'>2.1 ç‰¹å¾å·¥ç¨‹</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">phrase = np.array(df_train_1[<span class="hljs-string">&#x27;Pï¬hrase&#x27;</span>])<br>sentiments = np.array(df_train_1[<span class="hljs-string">&#x27;Sentiment&#x27;</span>])<br><span class="hljs-comment"># build train and test datasets</span><br><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split    <br>phrase_train, phrase_test, sentiments_train, sentiments_test = train_test_split(phrase, sentiments, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure>

<p>Next, we will try to see how different are the tokens in 4 different classes(positive,some positive,neutral, some negative, negative). </p>
<h2 id="2-2-CountVectorizer-TF-IDF-çš„å®ç°"><a href="#2-2-CountVectorizer-TF-IDF-çš„å®ç°" class="headerlink" title="2.2 CountVectorizer &amp; TF-IDF çš„å®ç°"></a><a id='2.2'>2.2 CountVectorizer &amp; TF-IDF çš„å®ç°</h2><h2 id="2-2-1-CountVectorizer"><a href="#2-2-1-CountVectorizer" class="headerlink" title="2.2.1 CountVectorizer"></a><a id='2.2.1'>2.2.1 CountVectorizer</a></h2><p>ä¼—æ‰€å‘¨çŸ¥ï¼Œæ‰€æœ‰æœºå™¨å­¦ä¹ ç®—æ³•éƒ½æ“…é•¿æ•°å­—ï¼›æˆ‘ä»¬å¿…é¡»åœ¨ä¸ä¸¢å¤±å¤§é‡ä¿¡æ¯çš„æƒ…å†µä¸‹å°†æ–‡æœ¬æ•°æ®æå–æˆ–è½¬æ¢ä¸ºæ•°å­—ã€‚è¿›è¡Œè¿™ç§è½¬æ¢çš„ä¸€ç§æ–¹æ³•æ˜¯è¯è¢‹ (BOW)ï¼Œå®ƒä¸ºæ¯ä¸ªè¯æä¾›ä¸€ä¸ªæ•°å­—ï¼Œä½†æ•ˆç‡éå¸¸ä½ã€‚å› æ­¤ï¼Œä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡CountVectorizerï¼šå®ƒè®¡ç®—æ–‡æ¡£ä¸­çš„å•è¯æ•°ï¼Œå³å°†æ–‡æœ¬æ–‡æ¡£é›†åˆè½¬æ¢ä¸ºæ–‡æ¡£ä¸­æ¯ä¸ªå•è¯å‡ºç°æ¬¡æ•°çš„çŸ©é˜µã€‚ </p>
<p>ä¾‹å¦‚ï¼šå¦‚æœæˆ‘ä»¬æœ‰å¦‚ä¸‹ 3 ä¸ªæ–‡æœ¬æ–‡æ¡£çš„é›†åˆï¼Œé‚£ä¹ˆ CountVectorizer ä¼šå°†å…¶è½¬æ¢ä¸ºæ–‡æ¡£ä¸­æ¯ä¸ªå•è¯å‡ºç°çš„å•ç‹¬è®¡æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">cv1 = CountVectorizer()<br>x_traincv = cv1.fit_transform([<span class="hljs-string">&quot;Hi How are you How are you doing&quot;</span>,<span class="hljs-string">&quot;Hi what&#x27;s up&quot;</span>,<span class="hljs-string">&quot;Wow that&#x27;s awesome&quot;</span>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">x_traincv_df = pd.DataFrame(x_traincv.toarray(),columns=<span class="hljs-built_in">list</span>(cv1.get_feature_names()))<br>x_traincv_df<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">/Users/gawaintan/miniforge3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>are</th>
      <th>awesome</th>
      <th>doing</th>
      <th>hi</th>
      <th>how</th>
      <th>that</th>
      <th>up</th>
      <th>what</th>
      <th>wow</th>
      <th>you</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>ç°åœ¨ï¼Œåœ¨ CountVectorizer çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨è®¡ç®—æ–‡æ¡£ä¸­çš„å•è¯æ•°é‡ï¼Œå¾ˆå¤šæ—¶å€™ï¼Œâ€œareâ€ã€â€œyouâ€ã€â€œhiâ€ç­‰å•è¯çš„æ•°é‡éå¸¸å¤§ï¼Œè¿™å°†æ”¯é…æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ ç®—æ³•çš„ç»“æœã€‚</p>
<h2 id="2-2-2-TF-IDF-ä¸-CountVectorizer-æœ‰ä½•ä¸åŒï¼Ÿ"><a href="#2-2-2-TF-IDF-ä¸-CountVectorizer-æœ‰ä½•ä¸åŒï¼Ÿ" class="headerlink" title="2.2.2 TF-IDF ä¸ CountVectorizer æœ‰ä½•ä¸åŒï¼Ÿ"></a><a id='2.2.2'>2.2.2 TF-IDF ä¸ CountVectorizer æœ‰ä½•ä¸åŒï¼Ÿ</a></h2><p>å› æ­¤ï¼ŒTF-IDFï¼ˆä»£è¡¨Term-Frequency-Inverse-Document Frequencyï¼‰é™ä½äº†å‡ ä¹æ‰€æœ‰æ–‡æ¡£ä¸­å‡ºç°çš„å¸¸è§è¯çš„æƒé‡ï¼Œå¹¶æ›´åŠ é‡è§†å‡ºç°åœ¨æ–‡æ¡£å­é›†ä¸­çš„è¯ã€‚TF-IDF çš„å·¥ä½œåŸç†æ˜¯é€šè¿‡åˆ†é…è¾ƒä½çš„æƒé‡æ¥æƒ©ç½šè¿™äº›å¸¸ç”¨è¯ï¼ŒåŒæ—¶é‡è§†ç‰¹å®šæ–‡æ¡£ä¸­çš„ä¸€äº›ç¨€æœ‰è¯ã€‚</p>
<h2 id="2-2-3-CountVectorizerå‚æ•°è®¾ç½®"><a href="#2-2-3-CountVectorizerå‚æ•°è®¾ç½®" class="headerlink" title="2.2.3 CountVectorizerå‚æ•°è®¾ç½®"></a><a id='2.2.3'>2.2.3 CountVectorizerå‚æ•°è®¾ç½®</a></h2><p>å¯¹äº CountVectorizer è¿™ä¸€æ¬¡ï¼Œåœç”¨è¯ä¸ä¼šæœ‰å¤ªå¤§å¸®åŠ©ï¼Œå› ä¸ºç›¸åŒçš„é«˜é¢‘è¯ï¼Œä¾‹å¦‚â€œtheâ€ã€â€œtoâ€ï¼Œåœ¨ä¸¤ä¸ªç±»ä¸­çš„å‡ºç°é¢‘ç‡ç›¸åŒã€‚å¦‚æœè¿™äº›åœç”¨è¯æ”¯é…ä¸¤ä¸ªç±»ï¼Œæˆ‘å°†æ— æ³•è·å¾—æœ‰æ„ä¹‰çš„ç»“æœã€‚å› æ­¤ï¼Œæˆ‘å†³å®šåˆ é™¤åœç”¨è¯ï¼Œå¹¶ä¸”è¿˜å°†ä½¿ç”¨ countvectorizer å°† max_features é™åˆ¶ä¸º 10,000ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer, TfidfVectorizer<br><br><span class="hljs-comment">## Build Bag-Of-Words on train phrases</span><br>cv = CountVectorizer(stop_words=<span class="hljs-string">&#x27;english&#x27;</span>,max_features=<span class="hljs-number">10000</span>)<br>cv_train_features = cv.fit_transform(phrase_train)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># build TFIDF features on train reviews</span><br>tv = TfidfVectorizer(min_df=<span class="hljs-number">0.0</span>, max_df=<span class="hljs-number">1.0</span>, ngram_range=(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),<br>                     sublinear_tf=<span class="hljs-literal">True</span>)<br>tv_train_features = tv.fit_transform(phrase_train)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># transform test reviews into features</span><br>cv_test_features = cv.transform(phrase_test)<br>tv_test_features = tv.transform(phrase_test)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;BOW model:&gt; Train features shape:&#x27;</span>, cv_train_features.shape, <span class="hljs-string">&#x27; Test features shape:&#x27;</span>, cv_test_features.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;TFIDF model:&gt; Train features shape:&#x27;</span>, tv_train_features.shape, <span class="hljs-string">&#x27; Test features shape:&#x27;</span>, tv_test_features.shape)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">BOW model:&gt; Train features shape: (124848, 10000)  Test features shape: (31212, 10000)
TFIDF model:&gt; Train features shape: (124848, 93697)  Test features shape: (31212, 93697)
</code></pre>
<h2 id="2-3-æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œæ€§èƒ½è¯„ä¼°"><a href="#2-3-æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œæ€§èƒ½è¯„ä¼°" class="headerlink" title="2.3 æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œæ€§èƒ½è¯„ä¼°"></a><a id='2.3'>2.3 æ¨¡å‹è®­ç»ƒã€é¢„æµ‹å’Œæ€§èƒ½è¯„ä¼°</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">####Evaluation metrics</span><br><br><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder<br><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> clone<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> label_binarize<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> interp<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve, auc <br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_metrics</span>(<span class="hljs-params">true_labels, predicted_labels</span>):<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.accuracy_score(true_labels, <br>                                               predicted_labels),<br>                        <span class="hljs-number">4</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Precision:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.precision_score(true_labels, <br>                                               predicted_labels,<br>                                               average=<span class="hljs-string">&#x27;weighted&#x27;</span>),<br>                        <span class="hljs-number">4</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Recall:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.recall_score(true_labels, <br>                                               predicted_labels,<br>                                               average=<span class="hljs-string">&#x27;weighted&#x27;</span>),<br>                        <span class="hljs-number">4</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;F1 Score:&#x27;</span>, np.<span class="hljs-built_in">round</span>(<br>                        metrics.f1_score(true_labels, <br>                                               predicted_labels,<br>                                               average=<span class="hljs-string">&#x27;weighted&#x27;</span>),<br>                        <span class="hljs-number">4</span>))<br>                        <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_predict_model</span>(<span class="hljs-params">classifier, </span><br><span class="hljs-params">                        train_features, train_labels, </span><br><span class="hljs-params">                        test_features, test_labels</span>):<br>    <span class="hljs-comment"># build model    </span><br>    classifier.fit(train_features, train_labels)<br>    <span class="hljs-comment"># predict using model</span><br>    predictions = classifier.predict(test_features) <br>    <span class="hljs-keyword">return</span> predictions    <br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_confusion_matrix</span>(<span class="hljs-params">true_labels, predicted_labels, classes=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]</span>):<br>    <br>    total_classes = <span class="hljs-built_in">len</span>(classes)<br>    level_labels = [total_classes*[<span class="hljs-number">0</span>], <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(total_classes))]<br><br>    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, <br>                                  labels=classes)<br>    cm_frame = pd.DataFrame(data=cm, <br>                            columns=pd.MultiIndex(levels=[[<span class="hljs-string">&#x27;Predicted:&#x27;</span>], classes], <br>                                                  codes=level_labels), <br>                            index=pd.MultiIndex(levels=[[<span class="hljs-string">&#x27;Actual:&#x27;</span>], classes], <br>                                                codes=level_labels)) <br>    <span class="hljs-built_in">print</span>(cm_frame) <br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_classification_report</span>(<span class="hljs-params">true_labels, predicted_labels, classes=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]</span>):<br><br>    report = metrics.classification_report(y_true=true_labels, <br>                                           y_pred=predicted_labels, <br>                                           labels=classes) <br>    <span class="hljs-built_in">print</span>(report)<br>    <br>    <br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_model_performance_metrics</span>(<span class="hljs-params">true_labels, predicted_labels, classes=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Model Performance metrics:&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span>*<span class="hljs-number">30</span>)<br>    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nModel Classification report:&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span>*<span class="hljs-number">30</span>)<br>    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, <br>                                  classes=classes)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nPrediction Confusion Matrix:&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span>*<span class="hljs-number">30</span>)<br>    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, <br>                             classes=classes)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_model_decision_surface</span>(<span class="hljs-params">clf, train_features, train_labels,</span><br><span class="hljs-params">                                plot_step=<span class="hljs-number">0.02</span>, cmap=plt.cm.RdYlBu,</span><br><span class="hljs-params">                                markers=<span class="hljs-literal">None</span>, alphas=<span class="hljs-literal">None</span>, colors=<span class="hljs-literal">None</span></span>):<br>    <br>    <span class="hljs-keyword">if</span> train_features.shape[<span class="hljs-number">1</span>] != <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;X_train should have exactly 2 columnns!&quot;</span>)<br>    <br>    x_min, x_max = train_features[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">min</span>() - plot_step, train_features[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>() + plot_step<br>    y_min, y_max = train_features[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">min</span>() - plot_step, train_features[:, <span class="hljs-number">1</span>].<span class="hljs-built_in">max</span>() + plot_step<br>    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),<br>                         np.arange(y_min, y_max, plot_step))<br><br>    clf_est = clone(clf)<br>    clf_est.fit(train_features,train_labels)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf_est, <span class="hljs-string">&#x27;predict_proba&#x27;</span>):<br>        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">else</span>:<br>        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    <br>    Z = Z.reshape(xx.shape)<br>    cs = plt.contourf(xx, yy, Z, cmap=cmap)<br>    <br>    le = LabelEncoder()<br>    y_enc = le.fit_transform(train_labels)<br>    n_classes = <span class="hljs-built_in">len</span>(le.classes_)<br>    plot_colors = <span class="hljs-string">&#x27;&#x27;</span>.join(colors) <span class="hljs-keyword">if</span> colors <span class="hljs-keyword">else</span> [<span class="hljs-literal">None</span>] * n_classes<br>    label_names = le.classes_<br>    markers = markers <span class="hljs-keyword">if</span> markers <span class="hljs-keyword">else</span> [<span class="hljs-literal">None</span>] * n_classes<br>    alphas = alphas <span class="hljs-keyword">if</span> alphas <span class="hljs-keyword">else</span> [<span class="hljs-literal">None</span>] * n_classes<br>    <span class="hljs-keyword">for</span> i, color <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(n_classes), plot_colors):<br>        idx = np.where(y_enc == i)<br>        plt.scatter(train_features[idx, <span class="hljs-number">0</span>], train_features[idx, <span class="hljs-number">1</span>], c=color,<br>                    label=label_names[i], cmap=cmap, edgecolors=<span class="hljs-string">&#x27;black&#x27;</span>, <br>                    marker=markers[i], alpha=alphas[i])<br>    plt.legend()<br>    plt.show()<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_model_roc_curve</span>(<span class="hljs-params">clf, features, true_labels, label_encoder=<span class="hljs-literal">None</span>, class_names=<span class="hljs-literal">None</span></span>):<br>    <br>    <span class="hljs-comment">## Compute ROC curve and ROC area for each class</span><br>    fpr = <span class="hljs-built_in">dict</span>()<br>    tpr = <span class="hljs-built_in">dict</span>()<br>    roc_auc = <span class="hljs-built_in">dict</span>()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;classes_&#x27;</span>):<br>        class_labels = clf.classes_<br>    <span class="hljs-keyword">elif</span> label_encoder:<br>        class_labels = label_encoder.classes_<br>    <span class="hljs-keyword">elif</span> class_names:<br>        class_labels = class_names<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Unable to derive prediction classes, please specify class_names!&#x27;</span>)<br>    n_classes = <span class="hljs-built_in">len</span>(class_labels)<br>    y_test = label_binarize(true_labels, classes=class_labels)<br>    <span class="hljs-keyword">if</span> n_classes == <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;predict_proba&#x27;</span>):<br>            prob = clf.predict_proba(features)<br>            y_score = prob[:, prob.shape[<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>] <br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;decision_function&#x27;</span>):<br>            prob = clf.decision_function(features)<br>            y_score = prob[:, prob.shape[<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> AttributeError(<span class="hljs-string">&quot;Estimator doesn&#x27;t have a probability or confidence scoring system!&quot;</span>)<br>        <br>        fpr, tpr, _ = roc_curve(y_test, y_score)      <br>        roc_auc = auc(fpr, tpr)<br>        plt.plot(fpr, tpr, label=<span class="hljs-string">&#x27;ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br>                                 <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(roc_auc),<br>                 linewidth=<span class="hljs-number">2.5</span>)<br>        <br>    <span class="hljs-keyword">elif</span> n_classes &gt; <span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;predict_proba&#x27;</span>):<br>            y_score = clf.predict_proba(features)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">hasattr</span>(clf, <span class="hljs-string">&#x27;decision_function&#x27;</span>):<br>            y_score = clf.decision_function(features)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> AttributeError(<span class="hljs-string">&quot;Estimator doesn&#x27;t have a probability or confidence scoring system!&quot;</span>)<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_classes):<br>            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])<br>            roc_auc[i] = auc(fpr[i], tpr[i])<br><br>        <span class="hljs-comment">## Compute micro-average ROC curve and ROC area</span><br>        fpr[<span class="hljs-string">&quot;micro&quot;</span>], tpr[<span class="hljs-string">&quot;micro&quot;</span>], _ = roc_curve(y_test.ravel(), y_score.ravel())<br>        roc_auc[<span class="hljs-string">&quot;micro&quot;</span>] = auc(fpr[<span class="hljs-string">&quot;micro&quot;</span>], tpr[<span class="hljs-string">&quot;micro&quot;</span>])<br><br>        <span class="hljs-comment">## Compute macro-average ROC curve and ROC area</span><br>        <span class="hljs-comment"># First aggregate all false positive rates</span><br>        all_fpr = np.unique(np.concatenate([fpr[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_classes)]))<br>        <span class="hljs-comment"># Then interpolate all ROC curves at this points</span><br>        mean_tpr = np.zeros_like(all_fpr)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_classes):<br>            mean_tpr += interp(all_fpr, fpr[i], tpr[i])<br>        <span class="hljs-comment"># Finally average it and compute AUC</span><br>        mean_tpr /= n_classes<br>        fpr[<span class="hljs-string">&quot;macro&quot;</span>] = all_fpr<br>        tpr[<span class="hljs-string">&quot;macro&quot;</span>] = mean_tpr<br>        roc_auc[<span class="hljs-string">&quot;macro&quot;</span>] = auc(fpr[<span class="hljs-string">&quot;macro&quot;</span>], tpr[<span class="hljs-string">&quot;macro&quot;</span>])<br><br>        <span class="hljs-comment">## Plot ROC curves</span><br>        plt.figure(figsize=(<span class="hljs-number">6</span>, <span class="hljs-number">4</span>))<br>        plt.plot(fpr[<span class="hljs-string">&quot;micro&quot;</span>], tpr[<span class="hljs-string">&quot;micro&quot;</span>],<br>                 label=<span class="hljs-string">&#x27;micro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br>                       <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(roc_auc[<span class="hljs-string">&quot;micro&quot;</span>]), linewidth=<span class="hljs-number">3</span>)<br><br>        plt.plot(fpr[<span class="hljs-string">&quot;macro&quot;</span>], tpr[<span class="hljs-string">&quot;macro&quot;</span>],<br>                 label=<span class="hljs-string">&#x27;macro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span><br>                       <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(roc_auc[<span class="hljs-string">&quot;macro&quot;</span>]), linewidth=<span class="hljs-number">3</span>)<br><br>        <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(class_labels):<br>            plt.plot(fpr[i], tpr[i], label=<span class="hljs-string">&#x27;ROC curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span><br>                                           <span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-built_in">format</span>(label, roc_auc[i]), <br>                     linewidth=<span class="hljs-number">2</span>, linestyle=<span class="hljs-string">&#x27;:&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Number of classes should be atleast 2 or more&#x27;</span>)<br>        <br>    plt.plot([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;k--&#x27;</span>)<br>    plt.xlim([<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>])<br>    plt.ylim([<span class="hljs-number">0.0</span>, <span class="hljs-number">1.05</span>])<br>    plt.xlabel(<span class="hljs-string">&#x27;False Positive Rate&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;True Positive Rate&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Receiver Operating Characteristic (ROC) Curve&#x27;</span>)<br>    plt.legend(loc=<span class="hljs-string">&quot;lower right&quot;</span>)<br>    plt.show()<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier, LogisticRegression<br><br>lr = LogisticRegression(penalty=<span class="hljs-string">&#x27;l2&#x27;</span>, max_iter=<span class="hljs-number">100</span>, C=<span class="hljs-number">1</span>)<br>sgd = SGDClassifier(loss=<span class="hljs-string">&#x27;hinge&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-3-1-CountVectorizer-ä¸Šçš„é€»è¾‘å›å½’æ¨¡å‹"><a href="#2-3-1-CountVectorizer-ä¸Šçš„é€»è¾‘å›å½’æ¨¡å‹" class="headerlink" title="2.3.1 CountVectorizer ä¸Šçš„é€»è¾‘å›å½’æ¨¡å‹"></a><a id='2.3.1'>2.3.1 CountVectorizer ä¸Šçš„é€»è¾‘å›å½’æ¨¡å‹</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Logistic Regression model on BOW features</span><br>lr_bow_predictions = train_predict_model(classifier=lr, <br>                                             train_features=cv_train_features, train_labels=sentiments_train,<br>                                             test_features=cv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_bow_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br>                                    <br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.6369
Precision: 0.6177
Recall: 0.6369
F1 Score: 0.6132

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.55      0.28      0.37      1426
           1       0.53      0.36      0.43      5428
           2       0.68      0.87      0.77     15995
           3       0.57      0.45      0.50      6603
           4       0.56      0.34      0.42      1760

    accuracy                           0.64     31212
   macro avg       0.58      0.46      0.50     31212
weighted avg       0.62      0.64      0.61     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        393   626    349    53    5
        1        251  1967   2936   255   19
        2         57   862  13982  1031   63
        3         15   236   3023  2941  388
        4          1    23    253   888  595
</code></pre>
<h2 id="2-3-2-åŸºäº-TF-IDF-ç‰¹å¾çš„é€»è¾‘å›å½’æ¨¡å‹"><a href="#2-3-2-åŸºäº-TF-IDF-ç‰¹å¾çš„é€»è¾‘å›å½’æ¨¡å‹" class="headerlink" title="2.3.2 åŸºäº TF-IDF ç‰¹å¾çš„é€»è¾‘å›å½’æ¨¡å‹"></a><a id='2.3.2'>2.3.2 åŸºäº TF-IDF ç‰¹å¾çš„é€»è¾‘å›å½’æ¨¡å‹</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Logistic Regression model on TF-IDF features</span><br>lr_tfidf_predictions = train_predict_model(classifier=lr, <br>                                               train_features=tv_train_features, train_labels=sentiments_train,<br>                                               test_features=tv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=lr_tfidf_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.6455
Precision: 0.6314
Recall: 0.6455
F1 Score: 0.6189

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.60      0.22      0.32      1426
           1       0.56      0.38      0.45      5428
           2       0.67      0.89      0.77     15995
           3       0.60      0.47      0.53      6603
           4       0.60      0.29      0.39      1760

    accuracy                           0.65     31212
   macro avg       0.61      0.45      0.49     31212
weighted avg       0.63      0.65      0.62     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        312   681    408    22    3
        1        177  2051   3066   125    9
        2         29   793  14193   944   36
        3          2   109   3115  3088  289
        4          0     9    281   966  504
</code></pre>
<h2 id="2-3-3-åŸºäºCountvectorizerçš„SGDæ¨¡å‹"><a href="#2-3-3-åŸºäºCountvectorizerçš„SGDæ¨¡å‹" class="headerlink" title="2.3.3 åŸºäºCountvectorizerçš„SGDæ¨¡å‹"></a><a id='2.3.3'>2.3.3 åŸºäºCountvectorizerçš„SGDæ¨¡å‹</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SGD model on Countvectorizer</span><br>sgd_bow_predictions = train_predict_model(classifier=sgd, <br>                                             train_features=cv_train_features, train_labels=sentiments_train,<br>                                             test_features=cv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_bow_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.5988
Precision: 0.5776
Recall: 0.5988
F1 Score: 0.5455

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.52      0.23      0.32      1426
           1       0.54      0.19      0.28      5428
           2       0.62      0.93      0.74     15995
           3       0.54      0.30      0.38      6603
           4       0.52      0.29      0.37      1760

    accuracy                           0.60     31212
   macro avg       0.55      0.39      0.42     31212
weighted avg       0.58      0.60      0.55     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        332   392    646    49    7
        1        234  1025   3909   230   30
        2         56   371  14874   637   57
        3         18   106   4156  1956  367
        4          4    15    502   735  504
</code></pre>
<h2 id="2-3-4-åŸºäºTF-IDFçš„SGDæ¨¡å‹"><a href="#2-3-4-åŸºäºTF-IDFçš„SGDæ¨¡å‹" class="headerlink" title="2.3.4 åŸºäºTF-IDFçš„SGDæ¨¡å‹"></a><a id='2.3.4'>2.3.4 åŸºäºTF-IDFçš„SGDæ¨¡å‹</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SGD model on TF-IDF</span><br>sgd_tfidf_predictions = train_predict_model(classifier=sgd, <br>                                                train_features=tv_train_features, train_labels=sentiments_train,<br>                                                test_features=tv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=sgd_tfidf_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.5594
Precision: 0.5543
Recall: 0.5594
F1 Score: 0.4666

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.60      0.11      0.18      1426
           1       0.52      0.09      0.16      5428
           2       0.56      0.97      0.71     15995
           3       0.55      0.16      0.25      6603
           4       0.59      0.15      0.24      1760

    accuracy                           0.56     31212
   macro avg       0.56      0.30      0.31     31212
weighted avg       0.55      0.56      0.47     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                       
                   0    1      2     3    4
Actual: 0        152  241   1020    13    0
        1         83  512   4759    67    7
        2         17  193  15447   315   23
        3          2   38   5328  1085  150
        4          0    2    993   502  263
</code></pre>
<h2 id="2-3-5-åŸºäºTF-IDFçš„éšæœºæ£®æ—æ¨¡å‹"><a href="#2-3-5-åŸºäºTF-IDFçš„éšæœºæ£®æ—æ¨¡å‹" class="headerlink" title="2.3.5 åŸºäºTF-IDFçš„éšæœºæ£®æ—æ¨¡å‹"></a><a id='2.3.5'>2.3.5 åŸºäºTF-IDFçš„éšæœºæ£®æ—æ¨¡å‹</a></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br>rfc = RandomForestClassifier(n_jobs=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># RandomForest model on TF-IDF</span><br>rfc_tfidf_predictions = train_predict_model(classifier=rfc, <br>                                                train_features=tv_train_features, train_labels=sentiments_train,<br>                                                test_features=tv_test_features, test_labels=sentiments_test)<br>display_model_performance_metrics(true_labels=sentiments_test, predicted_labels=rfc_tfidf_predictions,<br>                                      classes=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Model Performance metrics:
------------------------------
Accuracy: 0.6423
Precision: 0.6267
Recall: 0.6423
F1 Score: 0.6274

Model Classification report:
------------------------------
              precision    recall  f1-score   support

           0       0.47      0.36      0.41      1426
           1       0.56      0.42      0.48      5428
           2       0.70      0.84      0.76     15995
           3       0.58      0.46      0.51      6603
           4       0.50      0.40      0.45      1760

    accuracy                           0.64     31212
   macro avg       0.56      0.50      0.52     31212
weighted avg       0.63      0.64      0.63     31212


Prediction Confusion Matrix:
------------------------------
          Predicted:                        
                   0     1      2     3    4
Actual: 0        520   605    283    17    1
        1        465  2281   2539   133   10
        2        101  1094  13479  1258   63
        3          8   115   2793  3057  630
        4          2     6    217   825  710
</code></pre>
<p><strong>åŸºäºTF-IDFçš„é€»è¾‘å›å½’æ¨¡å‹ä¼˜äºå…¶ä»–æœºå™¨å­¦ä¹ ç®—æ³•</strong>. </p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/ml/" class="print-no-link">#ml</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>æœºå™¨å­¦ä¹ -æ–‡æœ¬å¤„ç†ä¹‹ç”µå½±è¯„è®ºå¤šåˆ†ç±»æƒ…æ„Ÿåˆ†æ</div>
      <div>https://gawain12.github.io/2022/09/02/motionanalys/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>Gawain</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2022å¹´9æœˆ2æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/11/07/StanfordCars/" title="æ–¯å¦ç¦æ±½è½¦è¯†åˆ«">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">æ–¯å¦ç¦æ±½è½¦è¯†åˆ«</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/05/11/PT%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93/" title="PTæœåŠ¡å™¨å·¥å…·">
                        <span class="hidden-mobile">PTæœåŠ¡å™¨å·¥å…·</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'Gawain12/comment-utterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
</body>
</html>
